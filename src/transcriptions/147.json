{
  "text": " Bene e benvenuti su Geekbar, nuova settimana, nuova settimana e nuovo episodio qua sul nostro bar per gli sviluppatori. Iniziamo già malissimo stasera, le energie sono al limite e a fianco a me ho un taco che è il mio pranzo ok? E appena arrivate del mio pranzo questo vi fa un po' capire in che condizioni sono, è stata una giornata di fuoco al lavoro ma per fortuna non sono solo, ho con me Leo e Luca, ciao ragazzi com'è? Ciao bene ma scusa una domanda il tuo pranzo o la cena? Il pranzo. L'ultima volta che hai preso un taco in puntata hai detto che non era andata troppo bene. Eh sì la digestione è un po' lenta, è per quello che è. E' parcheggiato. Un po' spostproduzione poi leviamo tutti i suoni molestici che ci sono. Sì io adoro i taco ma hanno una digestione waterfall, è un po' insomma tutto dire. Voi come state Luca e Leo? Vai Leo. Io sto bene, stiamo lavorando molto e non posso dire molto però abbiamo delle release da fare nei prossimi mesi. Tutto bene. Io tutte le volte che chiedo qualcosa a Leo fa sempre riferimento all'NDA, allora quando è che venite in puntata e ci raccontate profondamente che cosa state facendo? Sono sotto NDA e non lo posso dire. Anche la data non puoi dire. Tu Luca? Va beh ok. Non si può dire niente. Tu Luca? Io pure sì sì tutto bene, tanto lavoro, ho cambiato lavoro da qualche mese quindi cose nuove, tanti strumenti nuove, tante cose da studiare, tante cose da gestire, quindi sono abbastanza in burnout. Grazie. Io sto fremendo in realtà, io sto fremendo ragazzi perché abbiamo un ospite super speciale, un amico di Gitbar, abbiamo già bevuto qualche birra insieme a Code Motion, ci prepariamo per farlo nei prossimi eventi dove andremo a incontrarci ma prima di presentarlo in realtà, e questo mi fa fremere sulla sedia, dobbiamo ricordare i nostri contatti. Siamo la gitbar.it o etbrenrepo, sono i modi canonici per contattarci. E poi ovviamente c'è il gruppo Telegram, basta cercare Gitbar Podcast e vedrete fuori un gruppo che ha conto attualmente 1181 membri, sottolineo membri e quindi niente, venite vi aspettiamo per la prima birra è gratis e la seconda... membri e membre. Come si dice membrae? Membr. Membre, ok. Io ragazzi non potete immaginare quanto faccio degli strafalcioni giganti, specie coi clienti americani che sono super presi da questa cosa dell'inclusività, forse anche in modo così plateale, e io faccio una gas dopo l'altra. Ma parentesi a parte presentiamo l'ospite che abbiamo di nuovo qua un amico di Gitbar, abbiamo... proviamo a fare il serio. Benvenuti su Gitbar, il podcast dedicato al mondo dei full stack developer, i mezzo artigiani, i mezzo artisti che ogni giorno infilano le mani nel fango per creare nel modo più efficiente possibile quei prodotti digitali che quotidianamente usiamo. Abbiamo un conferenziere internazionale, l'autore di uno dei libri se non il libro di riferimento per Node.js, abbiamo un amico di Gitbar nonché un serverless hero con noi, Luciano Mammino. Ciao Luciano! Grazie per la fantastica intro, adesso mi sento proprio l'impostor syndrome a mille. In realtà sarebbe Luciano che dovrebbe presentare il podcast Gitbar, è un piccolo podcast italiano dove parla di programmazione. Che questo è vero. Esatto, ciao Luciano come va? Tutto bene, tutto bene, è stata una lunga giornata quindi potrei dire cose strane però magari quella è la parte divertente. Ma sei nel posto giusto, so che hai preso di corsa un treno, hai fatto di tutto per essere qua e per questo ti ringraziamo. La prima domanda che voglio farti Luciano è, noi ci siamo sentiti un anno e mezzo fa più o meno qua su Gitbar, poi ci siamo visti un po' dopo, siamo visti a Code Emotion, abbiamo mangiato insieme, ma cosa bolle in pentola in quest'ultimo periodo? La stai combinando? Nella mia vita personale lavorativa o in generale? A livello code related, IT related. Ma diciamo che non è cambiato tantissimo dall'ultima volta che ci siamo sentiti, nel senso che lavoro ancora per Fortiorem che è un'azienda di consulenza specializzata su AWS e continuo con questo ruolo che è una sorta di ibrido tra full stack web development e cloud architect e quindi diciamo che continuo un po' a imparare tutto quello che c'è da sapere sul cloud, AWS, migrazioni eccetera. Non so se è un buon riassunto ma insomma questo è a grandi linee quello che ho fatto nell'ultimo anno e mezzo. Mi ti faccio una domanda perché questa è una curiosità. Trovi delle difficoltà a sposare la parte da sviluppatore con la parte di cloud architect? Cioè talvolta è come indossare due cappelli, due berretti no? Come fai a fare, se serve farlo, context switching e a gestire queste due personalità che talvolta sono anche in antitesi no? Bella domanda, non so se mi sono mai posto il problema da questo punto di vista. Forse ho una personalità che è molto... A me piace molto spaziare, andare a vedere il problema a 360 gradi piuttosto che a concentrarmi in particolar modo su un aspetto specifico. Poi come esperienza personale ho più di 10 anni di sviluppo full stack quindi quella è una cosa su cui mi sento abbastanza tranquillo. Tutta la parte cloud è un po' più in divenire, poi ci sono sempre tantissime innovazioni e in più c'è il fatto che il metodo con cui Fortiorem lavora forse è un po' particolare. Nel senso che noi cerchiamo di, benché si parte sempre da un'analisi che è più da cloud architect, quindi di capire quali sono le esigenze, capire se l'architettura è quella corretta. Fatto quello poi passiamo molto a una fase operativa in cui diventiamo una sorta di estensione del team del nostro cliente e quindi andiamo proprio a fare pairing col team dell'azienda con cui lavoriamo e in quel senso facciamo un po' di tutto. Facciamo dalla parte di agile, scrum, eccetera, alla parte proprio di sviluppo pure per programming con gli sviluppatori dell'azienda. Quindi è una sorta di secondo me inserimento molto naturale dal questo è l'obiettivo, definiamo insieme la strategia, una volta consolidata quella strategia cerchiamo proprio di metterla in pratica in modo operativo. Quindi non vedo molto un conflitto tra queste due personalità come le definite tu, però forse dipende proprio molto dal modo in cui lavoriamo noi come azienda. Proprio in funzione di questo immagino che il metodo con cui lavorate non è molto lontano dal metodo con il quale lavoriamo noi e quello che ti chiedo è quando, essendo comunque un'azienda di consulenza come hai detto, quando vieni integrato nel team del cliente e in qualche modo hai un ruolo anche da evangelist, da educatore, perché se sei un consulente o se un prestatore d'opera alla consulenza più bè c'era, oppure devi portare un improvement al team, devi portare metodologie, devi portare pragmatismo, devi portare una serie di competenze. Quali sono, nella tua esperienza ormai lunga anche con Fortiorem, quali sono i modi che hai trovato funzionali per integrarti e trasferire la conoscenza pur rimanendo un consulente? Ok, non so se ho mai fatto una riflessione approfondita su questa cosa, diciamo che nella quotidianità di tutti i giorni ci sono varie cose che si fanno e forse non ci si dà troppo peso. In generale credo che ci siano varie tecniche che valgono secondo me, a prescindere che nel caso in cui tu sia un consulente esterno se proprio sei una persona che lavora per quell'azienda, ovvero che se tu propone un cambiamento troppo drammatico dall'oggi al domani è difficile riuscire a ottenere consensi nel senso più lato, ma anche quando c'hai una situazione assolutamente aperta di un team che vuole abbracciare l'innovazione, è disposto a fare la qualsiasi cosa per innovare, se viene fatto il passo più lungo della gamma è sempre un po' difficile riuscire ad arrivare all'obiettivo. Quindi preferisco un po' l'approccio incrementale in cui si parte un po' da quelle che sono le conoscenze attuali del team e si aggiungono degli elementi un po' alla volta e pian piano si arriva a fare innovazione. Giusto per farti un esempio pratico, mi è capitato il caso di un cliente che doveva fare una migrazione un po' classica da on-premise a cloud, semplicemente non perché la volevano fare così per sport, ma perché avevano problemi di scalabilità abbastanza seri, avevano bisogno di quell'elasticità che potevano trovare solo sul cloud e nonostante il loro caso d'uso secondo me fosse stato un caso d'uso perfetto per utilizzare serverless, alla fine abbiamo preferito fare una migrazione becera proprio da virtual machine a virtual machine e mettere solo dei load balancer di fronte al loro deployment con degli autoscaling group perché quello era il modello mentale più vicino a quello che il team già conosceva ed il fatto di dover andare ad abbracciare il cloud e capire cosa fossero gli autoscaling group, come andare a creare delle AMI e tutta quella roba leggera, un overload cognitivo non banale e quindi abbiamo detto ok prendetevi questo, questo vi risolve il problema nel medio termine, nel lungo termine poi una volta che avete capito AWS, avete capito le basi del cloud potete cominciare a esplorare, magari spostate dei worker su delle lambda con SQS e pian in piano cominciate a integrare quel tipo di conoscenza, quindi se fossimo andati da 0 a 100 su serverless sarebbe stato figo però probabilmente sarebbe stato un passo più lungo della gamba per il team e magari ci sarebbero stati, cioè magari come consulente avremmo dovuto fare il 99% del lavoro noi e poi andare a dare in gestione al cliente una roba che magari loro non avevano del tutto capito e non sarebbero stati in grado di gestire la solita. E questo ne dimostra anche il fatto dell'approccio che hai col cliente, cioè il levitare l'effetto lock-in a tutti i costi, cioè il essere un catalizzatore di successo piuttosto che essere una rondella della macchina, questa secondo me è una di quelle cose che quando si parla di consulenza è necessario mettere il focus, la puntata di oggi non è sulla consulenza anche perché non abbiamo Carmine con noi a sparare le bold opinion, ma è invece su un'altra tematica che hai citato che è il mondo serverless. Il mondo serverless 2014, 2015, 2023, di anni ne sono passati parecchi. Come si è evoluto lungo tutto questo quasi dieci anni? Allora parto subito con la opinione conflittuale che forse ti tirerà fuori gli argomenti di discussioni interessanti perché ultimamente sto avendo un po' una delusione da serverless, quindi vorrei portare questo tipo di opinione, nel senso che quando è stata rilasciata lambda, credo forse proprio 2014, aveva un po' questa promessa di dire finalmente abbiamo trovato una strazione che a livello di business vi fa concentrare quanto più possibile sui problemi di business, quindi scrivete la minor quantità di codice possibile per risolvere un problema di business, boom, produzione, non vi dovete preoccupare quasi di niente. Che forse all'inizio c'era una abbastanza vicina a questo tipo di concetto e poi all'atto pratico quello che è successo passando dal quasi dieci anni dopo, sono passati nove anni, in realtà se prendiamo, io parlo in particolar modo di AWS lambda e di contesto AWS, quello che hanno fatto non è stato altro che aggiungere feature su feature su feature su, e per feature parlo proprio di configurabilità, dimensioni in cui si può configurare una lambda, e all'atto pratico oggi è forse più complesso andare a mettere in piedi una lambda di quanto lo era nove anni fa, perché c'è una matrice di configurazione infinita e bisogna veramente andare a capire cosa vuol dire ogni singolo parametro configurazione per mettere in piedi qualcosa di decente. Quindi per assurdo è un po' un paradosso, nel senso che siamo partiti con quell'ideale di diamo un servizio quanto più manage possibile in modo che tu scrivi con una strazione semplicissima il codice, risolvi un problema, deploy, fine, tutto il resto se lo avete il cloud provider, e siamo arrivati al fatto che ovviamente gli utenti hanno avuto sempre delle richieste molto più specifiche, e AWS ha quella filosofia di customer first, quindi se abbastanza clienti chiedono una cosa AWS la fa, e all'atto pratico siamo arrivati a una sorta di astrazione che non è più un'astrazione perché puoi configurare lambda in mille modi diversi, e se tu ti stai approcciando a lambda oggi per la prima volta può essere un po' diciamo una cosa che fa un po' paura perché dici ok mi hanno promesso un'esperienza molto semplice, all'atto pratico non ho idea di dove iniziare perché c'è talmente tanta roba da configurare che effettivamente è difficile capire da dove iniziare, volevo portare questa opinione un po' conflittuale che la promessa di serverless secondo me è andata un po' a decadere negli anni. Come il discorso del per esempio parlando di lambda, della quantità di memoria che allochi per ogni lambda che in realtà influisce anche sulla potenza di calcolo della lambda stessa, quindi te puoi decidere di dare più memoria e quindi più potenza per ridurre il tempo di esecuzione, dato che la lambda la paghi al millisecondo, quando vai a deploiare devi fare delle prove per capire se la tua applicazione, cioè se paghi meno aumentando la potenza e diminuendo il tempo di utilizzo, oppure tenendo un tempo di utilizzo più lungo, eppure come hai detto te all'inizio dicevano te metti la funzione e viene eseguita e non ti devi preoccupare della scalabilità. Su questo voglio aggiungere una cosa perché qua su Github abbiamo un episodio proprio su questo topic che registrammo un po' di tempo fa con Alex Casalboni, proprio sul dimensionamento, aveva fatto dei lavori, era uscito con un tool che si occupava proprio del dimensionamento delle lambda, quindi ve lo metto nelle note dell'episodio e lo andiamo a recuperare. Quello che però è interessante è quello che ha detto Leo, perché comunque noi non abbiamo solo un problema di configurabilità in termini di integrazione con servizi terzi, ma anche la stessa funzione serverless ha una certa complessità intrinseca, la stessa architettura anche solo del concetto serverless ha una certa complessità sua, naturale. Hai parlato prima di configurabilità, si può dire configurabilità in italiano? Male che va di un neologismo. Volevo chiederti, hai degli esempi, dei casi di uso particolari che evidenzino questo tipo di complessità che va a crescere proprio data dal fatto che possiamo utilizzarle anche per farci il caffè? Oddio, un esempio particolare non so se mi viene in mente così su due piedi, però in generale quando io parlo di configurabilità non parlo solo diciamo delle opzioni che hai in termini proprio di i parametri che puoi andare a configurare, ma anche di tutti i limiti quelli che sono imposti dal runtime che ti da la lambda. Esempio banale, non puoi avere un payload credo più di 5 megabyte, né puoi restituire una risposta che sia più di 5 megabyte. In più il modello non è streaming ma è semplicemente richiesta risposta e c'hai dei json in entrata e in uscita, quindi banalmente già questo ti ha precluso tutta una serie di casi d'uso che magari a latto pratico ne potresti aver bisogno. Banalmente devo fare un upload di un video, non lo puoi fare direttamente con lambda ma devi utilizzare qualche strumento diverso proprio perché quello ti va a prendere un limite specifico delle lambda. Poi come abbiamo detto, come ha detto Leonardo, ci sono questi problemi del tipo che il dimensionamento delle lambda è fatto in questo modo proporzionale in cui più aumenti la memoria più aumenta la CPU, questo probabilmente per un discorso interno di come vengono dimensionate le lambda e a lato pratico questa è una leaky abstraction, nel senso che una decisione tecnica di AWS può influire sull'esperienza che l'utente ha e limita le scelte dell'utente. Altri esempi banali, ci sono dei limiti su quante lambda concorrenti possono esistere in una regione, in un account in un determinato momento, potresti incorrere in un problema nel quale se hai tantissime lambda, in un determinato momento una lambda non può partire perché non c'è abbastanza capacità in quell'account e quella regione e quello ti può portare a altre soluzioni anche un po' paradossali del tipo ok allora riservo questa lambda e la tengo sempre lì pronta a partire, il che significa che tu un oggetto che è stato pensato per essere super scalabile on demand e ti costa pure relativamente tanto se pensi che lo tieni sempre lì ad eseguire, ti ritrovi quasi costretto a doverlo tenere sempre lì attivo semplicemente per riservare quella concorrenza che sennò potrebbe essere rubata da altre lambda. Quindi ci sono tutta una serie di dettagli tecnici che adesso sto pure un po' estremizzando perché a lato pratico se non si arriva a una certa scala questi problemi non sono neanche dei problemi così così forti però è vero pure che se vai a costruire un'architettura complessa quella promessa di serverless che ti dava meno rogne tecniche in realtà diventa sempre più debole. Posso farti però una provocazione basata su un tuo blog post recentissimo dove spiegavi qualcosa relativo a S3, gli upload, le signature e quant'altro. Nel tuo ragionamento, almeno quello che hai fatto adesso, forse non stiamo, ed è un problema che ho anch'io, forse non stiamo rischiando di perdere di vista quella che è la vera utilità, quello che è il motivo per cui dovremmo utilizzare le lambda. Hai detto bene, se io riservo una lambda vuol dire che o non ho capito una cipa di come funzionano le lambda oppure ho pensato di utilizzare una chiave inglese anche per mettere i chiodi nel muro e questo ci sta quando c'è un team complesso, quando gli devi fare una formazione ed è difficile insegnargli o fare una certa pipeline per il deploy o per l'uso di Fargate o per l'uso di Kubernetes o per altre cose, quindi ci sta. Però il problema non viene per esempio dal utilizzare uno strumento che non è pensato per quello in un contesto specifico e te lo dico perché vengo con l'esperienza che mi arriva da mia moglie dove in alcune pipeline di big data ho visto usare le lambda e ho detto no amico mio forse in questo caso non è lo strumento giusto delle lambda utilizzate e accese per un sacco di tempo che comunque venivano richiamate in modo che si riduce il cold start, delle cose un po' tricky. Concordo assolutamente e da una parte secondo me va pure fatta la chiarezza su cosa noi intendiamo per serverless perché ci stiamo concentrando molto su lambda ma lambda è solo diciamo una parte di quello che viene definito serverless, però sono perfettamente d'accordo che lambda in sé come astrazione di compute non è adeguata per tutti i casi d'uso e spesso si fa quest'errore di andare a dire voglio essere serverless first o serverless 100% quindi qualsiasi caso d'uso lo devo risolvere con le lambda e lì poi ti ritrovi a dover fare tutta una serie di cose che magari riesci a risolvere il problema però ti ritrovi a fare qualcosa che non è assolutamente ottimale per quel tipo di applicazione. Hai detto un'altra cosa interessante che andremo ad analizzare dopo che tutto l'ecosistema serverless quindi non solo lambda però ho visto un dittino muoversi da Luca volevi dire qualcosa? No certo stavo pensando alla difficoltà di non inserire pioli tondi in buchi quadrati come come mi piace dire però anche questo vuol dire dover comunque studiare molto approfonditamente quello che è l'ecosistema serverless quello che AWS offre o quello che google cloud platform offre e così via e quindi di nuovo viene un po' meno quella promessa che dice devi pensare soltanto al tuo domino, alla tua business logic. Questo lo sto vivendo proprio nella mia pelle proprio perché io comunque c'ho anche un caso d'uso semplice però anche solo proprio perché voglio evitare di usare lo strumento sbagliato nel posto sbagliato io attualmente non sto pensando alla business logic sto pensando a dove infilare i pioli sostanzialmente e quindi no niente appunto speravo sto cercando risposte le troverò in questa puntata credo anche per questo. Io, Leo volevi dire qualcosa? Volevo non so provare a introdurre un argomento o dire una cosa che mi passa per la testa allora il serverless, l'architettura serverless funziona molto bene nei momenti in cui uno non conosce la diciamo ha dei picchi non lo so di traffico e quindi non vuole stare a scalare manualmente e lascia fare tutto a AWS ma se un business conosce esattamente il traffico il numero di utenti non ha questi picchi tipo black friday eccetera serverless aiuta è funzionale o a quel punto perde la maggior parte del suo vantaggio perché una frase che ho sentito dire un po' di tempo fa in un podcast è enterprises don't use serverless cioè le enterprise le grandi big molloc che sanno esattamente qual è il loro traffico non usano il serverless perché conoscono esattamente le risorse di cui hanno bisogno in quel caso il fatto di non dover gestire i server che non vuol dire attaccare la spina o cambiare il disco andiamo qualche livello sotto ho perso la domanda nel senso come posso dire se uno conosce esattamente le capacità di cui ha bisogno ha bisogno di serverless o gli basta prendere un on-premise con quelle capacità di cui conosce le dimensioni no questa è un'ottima domanda che spesso è un qualcosa di cui discutiamo anche con i nostri clienti e non è mai diciamo una decisione binaria ovvia o si serve le siano perché secondo me bisogna un po chiarire quali sono i vantaggi di serverless nel senso che non sempre un vantaggio di costo come magari se fatta molta enfasi soprattutto all'inizio del di questo fenomeno serverless diceva è però se metti tutto su serverless paghi sempre pochi centesimi piuttosto che magari pagare centinaia o migliaia di dollari al mese che può essere vero ma secondo me non è una diciamo un effetto necessario dell'utilizzare serverless quello dipende molto al caso d'uso e per assurdo serverless potrebbe anche costarti di più se vai a vedere il puro costo del compute appunto c'è tra l'altro un articolo del del sito di Fortiorem che magari poi cerco il link ve lo passo qui che fa proprio un'analisi molto dettagliata su un caso d'uso in cui la necessità di compiut è ben nota e lui confronta a parità di compute se faccio una cosa su isi tu quindi virtual machine pure su rispetto fargate quindi dockerizzazione rispetto lambda ogni volta che tu vai a aumentare il livello d'astrazione quindi in ordine isi tu fargate e lambda c'è un aumento di costo di 20 per quindi sostanzialmente lambda ti va a costare 400 volte di più di isi tu quindi di virtual machine a parità proprio di capacità di compute quindi se tu riuscissi ad ottimare assolutamente l'utilizzo a ottimizzare assolutamente l'utilizzo di isi tu risparmi parecchio rispetto a lambda con un utilizzo costante chiaramente però secondo me quella è una visione parziale del costo perché in realtà va fatto una visione un po' più completa andando a includere quello che viene chiamato il total cost of ownership nel senso che una cosa è il costo proprio del compute in sé ovvero cpu che gira e paghi per quella cpu una cosa è il costo umano di andare a pensare come faccio a mettere in piedi una virtual machine e mantenerna nel tempo come faccio a mettere in piedi una lambda e mantenerna nel tempo e bisogna ricordarsi che quando metti in piedi una virtual machine devi pensare a tutta una serie di cose che con lambda non devi pensare nel senso devi pensare a non solo il dimensionamento ma anche che sistema operativo utilizzo come faccio a tenere l'aggiornato tutto lo stack software da andare a installare come tenere l'aggiornato patch di sicurezza eccetera e quindi diventa un lavoro molto più grande di quello di una lambda in cui benché abbiamo detto che non è al 100% vero in teoria pensa a scrivere una funzione e quella funzione gira poi può relici sono tutta una serie di parametri da configurare ma rispetto a una macchina virtuale la superficie di configurazione è molto più bassa e quindi il costo umano di dover andare a gestire una lambda è più basso di quello di dover andare a gestire una virtual machine quindi secondo me va fatto più questo tipo di analisi cioè non solo l'analisi di costo cpu chiamiamolo così ma non è più completa di ok ma se deve avere una persona dedicata che mi tiene in piedi questa virtual machine ed è una virtual machine critica magari sono 50.000 euro l'anno che sta spendendo così e non ti rendi conto che lei sta spendendo perché è una virtual machine rispetto a una lambda forse sto un po esagerando ma voglio anche approfondire questo tipo di discorso no no era proprio il punto che che tendevo io cioè avere qualcosa da gestire ci devi mettere anche il costo della persona che lo gestisce e magari per la persona che non è economica no? magari per la persona deve trovare quindi non è che uno deve prendere appunto la posizione binaria uno o l'altro però ci sono diciamo dei costi nascosti che uno non vede perché magari il devop ce l'ha già e non considera quel costo all'interno del costo 10.2. Eh però questa anche era una mia domanda ma possiamo fare a meno veramente di un devop di un caro vecchio sistemista? Cioè credo che per qualcosa per qualcosa anche solo per per gestire le cose di ufficio boh alla fine un cavolo di servizio ti serve su una virtual machine forse forse alla fine qualcuno ti serve che fa che faccia quel lavoro e a quel momento già che la ralla è molto elevata quindi già che lo paghi poi tra virgolette sfruttarlo al 100% dandogli più lavoro quindi più virtual machine da aggiornare e quant'altro. Cioè mi chiedevo questo perché a me un sistemista proprio mi manca attualmente non ce l'ho ma proprio mi manca perché non per tutto c'è un servizio e non per tutto e non sempre ho il tempo le capacità e le conoscenze per studiare qual è il servizio che che mi serve allora dovrei fare consiglio dovrei chiedere a dovrei fare chiedere una consulenza e comunque quei soldi lo stesso in un modo o nell'altro vanno via. Posso dire una cosa io adesso mi trovo a lavorare in un progetto che potremmo definire enterprise no? Quindi con una grande azienda con decine di devops ingegner o sre chiamiamoli come ci pare insomma ormai i ruoli sono quasi più delle tipologie delle persone quindi diventa difficile però insomma con parecchia gente che scrive dalla mattina alla sera a terra forma e vive dentro cloud watch e sistemi di monitoring vari ed eventuali. E' una cosa un pattern che ho trovato non solo in questa grande grande multinazionale ma anche in altre società piuttosto grandi e nonostante i costi una virata verso i servizi managed e questo un po' è in controtendenza a quello che ha scritto DDD qualche qualche giorno fa no? Parlando dei costi di AWS e insomma del suo flame. Però pur con una forte presenza di utilizziamo il termine old school di sistemisti o di DDD e cavolo si opta per una serie di servizi managed per capirci le app sono deploiate con se siamo in ambito azur app service o se devo fare una qualche qualche feature qualche funzione qualche qualche azione automatizzare qualcosa si usano le serverless functions piuttosto che pur avendo le risorse in house piuttosto che insomma non si dice piuttosto che ma freghiamocene piuttosto che insomma tirare in house ottenere in house un'architettura che diventa ancora più complessa di quello che è. Allora mi chiedo e lo chiedo a Luciano specialmente forse è cambiato anche il modo con con l'avvento di serverless in una visione un po' più ampia no? Quindi compresa la visione del database serverless e dei container serverless della storage dei file fondamentalmente serverless come S3 è cambiato proprio il modo che siccome tu sei anche un full stack developer il modo in cui pensiamo il software? Si concordo assolutamente secondo me andiamo con questo con questo tipo di osservazione ad avvicinarci di più a quello che sono il vantaggio di serverless nonostante abbiamo detto che la promessa di serverless non è che sia stata così mantenuta negli anni però secondo me continua un po' ad esserci della verità in quella promessa di serverless nel senso che serverless ci porta molto di più ad essere agili quando si parla di mettere in piedi una cosa nuova. Esempio banale quando diciamo in un mondo tradizionale on premise bisognava mettere in piedi un qualsiasi nuovo servizio dalla cosa più banale immaginiamo che ne so una web book che deve rispondere ad un evento c'era veramente tanto lavoro di burocrazia da fare bisognava andare dall IT dal tizio dell'IT e dire sai dove è una macchina in cui posso mettere in piedi questa cosa mi crei il certificato mi serve un dominio queste queste altre passavano due tre quattro settimane prima di poter avere l'ambiente su cui andare a rilasciare magari 15 righe di codice. Secondo me serverless è in generale tutto questo mondo di servizi più managed come possiamo pure pensare che ne so DynamoDB per quanto non è una strazione che mi faccia impazzire è vero pure se tu devi pensare a mettere in piedi un RDS che già RDS c'è tutta una serie di roba managed o piuttosto addirittura farti il tuo postgres da zero rispetto a creare una tabella su DynamoDB DynamoDB ci metti 0,5 minuti a far partire un'istanza RDS che già appunto c'è tanto managed ci vuole almeno mezz'ora quindi secondo me è più quello il tipo di ragionamento in un mondo che è sempre più agile sempre più dinamico in cui le aziende devono riuscire a sperimentare e mettere in piedi i servizi in modo quanto più veloce possibile lì secondo me la promessa di serverless e di questi servizi managed diventa un po' più importante benché secondo me la strazione perfetta ancora non si è raggiunta. Però io sono uno stronzo e tu lo sai bene no? E adesso arriva la prima domanda cattiva alla quale io in realtà non so dare risposta è una domanda che mi pongo sempre ma sono bloccato là e dico sì vabbè abbiamo detto che in qualche modo il mondo serverless l'ecosistema serverless al di là del provider proprio in modo astratto più generale sta in qualche modo cambiando il modo che abbiamo di vedere il software perché fondamentalmente quello che noi facevamo quando scrivere scrivevamo il codice erano due cose la nostra applicazione aveva due importanti funzioni forse sto riducendo un po' ma secondo me i due le due grandi responsabilità di qualunque tipo di applicazione scritta sono eseguire business logic quindi logica specifica collegata al business di contesto e avere una sorta di glue code che metteva insieme una serie di elementi e lato codice si occupava dell'orchestrazione di queste componenti quindi la connessione al database piuttosto che la connessione al sistema di caching il redis della situazione. L'ecosistema serverless ha un po' spostato purgato tutto il concetto di glue code fuori dal concetto di applicazione o perlomeno questa è la tendenza no? A questo punto il focus è sulla logica di business che ha come concetto principale rannare workflow se insieme al glue code purghiamo anche il crude della situazione rimangono veramente i workflow che sono delle funzioni e là il concetto fitta one to one proprio col concetto di computazione serverless. Nel contesto però c'è tutta un'altra orchestra di servizi serverless che ha solvono problemi diversi e c'è tutto il mondo dell'orchestrazione parliamo di AWS in ambiente AWS con cloud formation o lo strumento della situazione che si occupa proprio di scriverti questo glue code spostando le responsabilità tutte sull'infrastruttura per cui a questo punto la vera ownership del team di sviluppo rimane la logica di business e dico la logica di business purgando anche il crude perché AWS ha tutta una serie di sistemi che semplificano anche le azioni di create, delete e quant'altro all'interno di una certa data source. Per cui la mia domanda è posto che tutto questo è fighissimo perché ti riduce ai minimi termini il time to market riduce il numero di sistemi stiche tutti lì dentro. A livello sviluppatore ha senso a questo punto preoccuparsi della ownership della propria applicazione? Quanta complessità vedi su tool o quanto vedi funzionare dei tool cloud agnostic che in qualche modo astragano questo tipo di dipendenza? Ok porti un bel argomento quindi cerco di risponderti un po' in ordine e sperando di darsi una risposta sensata. Da una parte mi viene in mente ad esempio il discorso step functions basato su quello che hai detto ovvero che su AWS uno strumento ti permette di creare anche in modo visuale esiste pure un editor visuale tra l'altro l'ultima release pure fatta abbastanza bene per gli standard di AWS che ti permette proprio di dire quasi con logica no code o comunque low code voglio combinare tutta una serie di step fare degli if fare dei retry fare delle azioni in parallelo e poi effettivamente andare a creare dei workflow pure abbastanza complessi con una quantità di codice veramente minimale e soprattutto facendo rigirare su un ambiente che è totalmente managed in cui non ti devi preoccupare del fatto che non ci fosse se la capacità o che non riesce a scalare o altri problemi di natura puramente infrastrutturale. Quindi assolutamente vero il fatto che c'è molto una tendenza a cercare di darti quanta più roba as a service possibile e tra l'altro proprio parlando step function una delle cose che hanno introdotto anche abbastanza recente credo sia a meno di un anno è il fatto che ad esempio l'SDK di AWS quindi tutte le chiamate che ti permettono di invocare tutti gli altri servizi di AWS adesso sono disponibili nelle step function come step nativi quindi in tutta una serie di circostanze non devi neanche andarti a scrivere una lambda per dire voglio chiamare quest'altro servizio ma semplicemente c'è il blocchettino che dice vabbè i dati che sono venuti fuori da qui metti direttamente su DynamoDB oppure leggi da DynamoDB fai questo filtro e poi manda i dati da un'altra parte e tutta questa cosa è estremamente managed nel senso che magari non è scritto una riga di codice per quello intendo codice business logic però d'altra parte c'è una tendenza che forse viene un po' sottovalutata che è forse pure una buona pratica ma forse ne viene sottovalutata l'importanza che tutto quello che fai in modo visuale o comunque manage o comunque generato con tutta una serie di tool alla fine se lo devi fare in modo enterprise è tutto infrastructure as code che da qualche parte devi scrivere quindi secondo me si sta shiftando molto il fatto che una volta scriviamo tutto un sacco di business logic che non era necessariamente business nel senso funzionale al business ma era più funzionale all'infrastruttura però la scrive sottoforma di codice adesso tutto quello lo stiamo delegando al cloud provider però in qualche modo al cloud provider dobbiamo dire come mettere insieme tutti questi pezzi e quello diventa tutta infrastructure as code che da una parte bisogna imparare tutti gli strumenti dall'altra è comunque codice benché non codice logico ma più codice di diciamo dichiarativo insomma più di configurazione che però va comunque messo su repository va mantenuto vanno fatte le CICD basate su quel codice vanno fatti i test eccetera eccetera quindi non so se sto andando per una tangente invece di rispondere alla tua domanda ma questo è quello che mi viene in mente ma scusate ti tiro in ballo un'altra un'altra cosa che di cui sto cercando una risposta in tutto questo i test come vengono fatti perché tralasciando i unit test quindi quando riesci a testare i singoli componenti le singole funzioni con tutte le best practice del caso però poi come fai a testare tutto tutto insieme come fai a testare il tutto il giro tutto il workflow che bisogna seguire che strategia ci si può adottare o si deve adottare con AWS o in generale sì tra l'altro mi sono appena ricordato che non ho risposto alla domanda riguardo la cloud abstraction quindi magari dei servizi che riescono a strarre il fatto che tu possa essere su AWS piuttosto che azure piuttosto che su google quindi cercherò di rispondere anche includendo questo o ne riparliamo dopo però in generale quello del testing è uno dei temi sui quali secondo me ad oggi cioè ci sono varie pratiche però secondo non c'è una pratica che è quella che su cui tutti diciamo sono d'accordo che sia il modo migliore di fare i test e di test parla in senso molto lato cioè banalmente non parliamo di test automatizzati ma del fatto che tu hai scritto una riga di codice aggiuntiva e prima di deploiarla a qualche parte ti chiedi ma funziona fa quello che deve fare come la testo anche manualmente cioè non voglio necessariamente scrivere un test automatizzato ma banalmente voglio eseguire questo codice che ho cambiato nella mia macchina locale per vedere se effettivamente fa quello che io penso che debba fare e banalmente questo è un tema che su cui ci sono 50 anni di storia nel senso da quando esiste l'informatica si scrivono cose locale le esegui vedi se funzionano poi puoi anche scrivere test automatizzati ma è sempre stata quasi una cosa ovvia il fatto di poter eseguire le cose locale a meno che magari facciamo un mega passi indietro quando c'erano i mainframe dovevi mandare il job però va beh dimentichiamoci magari quella fase iniziale della storia dell'informatica e pensiamo magari anni un po' più recenti da sistemi operativi un po' più moderni e secondo me con serverless si va un po' a perdere quel tipo di abilità di eseguire le cose localmente nel senso che più deleghiamo cose al cloud provider più ci troviamo ad avere meno roba che scriviamo noi che effettivamente possiamo eseguire nel nostro ambiente locale perché per quando il cloud provider o terzi ti possono dare degli strumenti per simulare quello che andrà a fare il cloud provider comunque spesso sono delle simulazioni e comunque chiaramente non puoi eseguire un intero cloud provider nella tua macchina quindi ti ritroverai ad avere delle astrazioni che non necessariamente vanno a compaciare al 100% con quello che poi ti troverai in produzione come ambiente di esecuzione quindi ci sono tutta una serie di approcci anche un po' ibridi che sto vedendo nel senso che c'è chi ancora apprezza il fatto di poter eseguire qualcosa localmente benché il livello di fidelità con l'ambiente finale è sempre più distante quindi magari accetti che l'ambiente locale non è perfetto rispetto a quello che avrai su AWS o su un altro cloud provider però comunque una prima astrazione mi permette di vedere se il mio codice più o meno fa quello che deve fare dopodiché sto vedendo che c'è una tendenza a cercare di ridurre quanto più possibile i tempi di deployment e far sì che l'ambiente cloud diventa il tuo ambiente di sviluppo chiaramente non stiamo parlando di rilasciare di continuo in produzione ma di avere un ambiente cloud di sviluppo che è molto più simile all'ambiente che avrai in produzione e il problema a quel punto dipende quanto riesci a aggiornare quel codice in cloud velocemente così da avere un feedback loop che più vicino possibile a quello di eseguire tutto localmente e ad oggi secondo me non c'è una soluzione perfetta benché se andiamo a vedere alcuni nuovi tool che hanno inserito all'interno di SAM o CDK cercano in qualche modo di farti rilasciare il codice o addirittura di sincronizzartelo quasi come se fosse un watch live in modo più veloce possibile in modo che riduci quel tipo di feedback loop e quello è un altro approccio l'altro approccio ancora è quello di creare appunto dei test automatizzati che prima di fare un rilascio in produzione effettivamente stanno testando tutto quello che tu hai fatto in un ambiente che è totalmente uguale a quello che avrai in produzione e ti danno un feedback sì tutti i test sono passati allora procedo con il rilascio in produzione oppure no e secondo me non c'è una pratica perfetta ribadisco questo l'insieme di tutte queste pratiche ti può dare un buon livello di fiducia nel fatto che se tu fai una modifica poi quando andrai a portare in produzione non hai sorprese particolari e giusto per inserirmi nel discorso di cloud abstraction tutto questo è molto cloud specifica ad oggi nel senso noi andiamo a utilizzare step function piuttosto che lambda piuttosto che dynamo db piuttosto che sqs oss e nesso questi servizi che diciamo sono tra l'altro da quelli più base che un po' tutti utilizzano sqs sono fondamentalmente diversi se vai a utilizzare gli equivalenti su azure o su google proprio a livello di api quindi banalmente voler utilizzare una abstrazione e sì magari ne esistono ma praticamente ti vai a a portare il tuo problema un minimo comune denominatore di funzionalità che tutti supportano e ti stai perdendo i vantaggi specifici ogni cloud provider quindi forse un discorso che da una parte sconsiglierei dall'altra possiamo pure andare a parlare di kubernetes di tutto quel tipo di abstrazione lì che un po' cerca di risolvere quel problema di un ambiente un po' più universale che è più semplice da emulare localmente ed è anche un po' più uniforme quando poi lo andiamo a portare in produzione sul cloud spero di aver risposto senza dire cosa no no no hai risposto benissimo che secondo me quello che evidenziate è importante cioè per diventare cloud agnostic andiamo a costruire una un ulteriore livello d'astrazione sopra una serie di livelli d'astrazione che alla fine diventa astrale all'astratto per cui si può con tool come kubernetes in modo più pragmatico eliminiamo una serie di livelli d'astrazione creandone uno unico o comunque un quasi layer unico d'astrazione. La ricerca del cloud agnostic è più una cosa che i dev o i devops cercano perché dice io vorrei deployare questo su AWS e poi domani senza cambiare nulla voglio deploiarlo su google cloud però nel frattempo amazon e google fanno in modo che questa cosa non sia possibile perché loro vogliono il lock in quindi io quando avevo negli ultimi mesi in near form sono passato a fare il devops avevo sentito di questa terra fanno detto posso deployare tutto dove mi pare e no sei su AWS fai la lambda e fai la mia game, sei su google fai altre cose e ti perdi i vantaggi quindi devi scrivere sempre due volte il codice però è chiaro che amazon ha tutto l'interesse per marketizzare i propri vantaggi e fare in modo che siamo diversi da quelli di google perché poi dopo deve essere più difficile nella loro ottica per il cliente spostarsi su google perché se no non ci sarebbe business quindi è un po' una lotta un po' ibari. Devo dire che spostando un po' il focus se dovessi fermarmi e pensare al serverless oggi credo che molto del boost è stato anche dato dall'apparire nel mercato di tutto ciò che riguarda il gem stack quindi city stati, ship building, ridurre al minimo la logica di business, non far girare tutto il sito ma solo quello che veramente serve quindi ridurre computazione da quel punto di vista, spostare molta computazione che andava prima nei nostri backend monolitici a build time quindi da un'altra parte il trend della computazione serverless ci ha portato in modo positivo anche a ottimizzare energia diciamola anche qua però nel contempo più creiamo nuovi livelli di astrazione più ci allontaniamo da quello che in realtà è fisicamente quello che facciamo e questo ha un certo effetto anche se ci connettiamo a un ragionamento o a un concetto di tipo ambientale cioè il fatto di essere così lontano dal ferro probabilmente ci fa perdere consapevolezza di quello che è il consumo energetico un altro elemento che ci fa perdere consapevolezza del consumo energetico è il gratis. Adesso signori di AWS per favore chiudete le orecchie non sto parlando con voi quindi lasciate quello che c'è come vi prego ma quanto il free tier è stato trigger meccanismo di successo di questi servizi serverless e quanto in realtà lo stesso free tier ha triggerato ha stimolato il misuso l'uso sbagliato di questi strumenti. Ah però scusa una parentesi che ho sentito oggi su continuous delivery che salutiamo che chat gpt spendono 3 milioni di dollari al giorno di data center. Sì vabbè ma c'è microsoft che pagala quindi. Quindi mi ripeti la domanda e me la so persa in quest'ultima osservazione. No l'impatto che ha avuto il concetto di free tier nell'adozione dei servizi serverless è l'impatto che ha avuto lo stesso free tier nel misuso l'uso sbagliato di questi servizi. E' una bella domanda non so se è una cosa che potrebbe essere facile da calcolare io poi ho un'opinione molto pro free tier nel senso che anzi vorrei che AWS facesse di più nel senso rendesse più semplice per chi magari uno studente universitario che non si può permettere di avere una carta di credito di essere in grado comunque di provare a utilizzare questi servizi e imparare e ad oggi secondo me AWS da questo punto di vista non fa un ottimo lavoro. Capisco il tuo punto di vista nel senso che è vero che c'è molto la logica del free molto la logica di buttare online tanto costa poco e a volte ci ritroviamo a mettere in piedi roba che effettivamente o è fatta male nel senso che non è abbastanza ottimizzata o non è neanche necessaria tanto costa poco tanto è gratis quindi nessuno si preoccupa. Però d'altro canto va pure osservato il fatto e questo l'hai detto pure tu che serverless come paradigma è un po' più eco friendly dei paradigmi un po' più tradizionali cloud o anche on premise nel senso che tipicamente quando vai a mettere in piedi una macchina virtuale o cloud on premise che sia devi sempre dargli molto più buffer di quello che ti serve perché non riesce a scalare in modo così dinamico quindi all'atto pratico magari tu c'hai una macchina che consuma teoricamente 100 quando ti serve due e quel 100 magari lo raggiunge una volta al mese in un picco ben preciso quindi stai pagando per un mese 100 tutti i giorni quando magari quel 100 ti serve un'ora al mese. Con serverless riesce un po' quella curva di utilizzo a ottimizzarla e questo teoricamente dovrebbe dare un modello un po' più eco sostenibile ora tutti i cloud provider quando si parla di eco sostenibilità secondo noi fanno un po' di fuffa cioè è difficile avere delle metriche chiare perché poi magari dovrebbero tirare fuori tutta una serie di dettagli tecnici che non vogliono tirare fuori però per fortuna questo discorso dell'eco sostenibilità sta diventando un tema sempre più importante al punto che non so se sapete che AWS ha questi pillar del well architected framework di recente hanno proprio introdotto un pillar che è quello che cerca di capire qual è l'impatto da un punto di vista ambientale delle soluzioni cloud e come cercare di ottimizzare anche da quel punto di vista. Discorso che secondo me andrebbe su cui andrebbe fatta più enfasi su cui andrebbero sviluppati più strumenti su cui andrebbe fatta più trasparenza però secondo me è già un buon passo avanti il fatto che se ne parli sempre di più e che diventi un argomento sempre più importante sia per aziende piccole tanto quanto per aziende più grandi. Sei on mute. Sì stavo cercando il pulsante ve l'ho detto ormai sono bollito tra l'altro hai citato la cosa interessante del well architected framework che devo dire che ho scoperto solo stamattina ed è una figata pazzesca e all'interno del well architected framework c'è ho trovato un documento o comunque un gruppo di documenti che era il serverless application lens che è un documento che in qualche modo tra le varie cose che fa evidenzia anche delle topologie di architettura serverless e delle best practice per la creazione di architetture specifiche. Ad oggi secondo te quali sono se dovessi portare sul tavolo tre casi d'uso dove veramente il serverless in senso ampio e quindi non solo lambda dà il meglio di sé. Quali sono i casi dove veramente dici sei fatto proprio per questo? Guarda ne parlavo proprio di recente con un amico che mi ha chiesto una serie di opinioni lui doveva sviluppare un nuovo progetto all'interno della propria azienda e si chiedeva mi conviene andare a provare un approccio serverless perché magari un qualcosa che andando avanti con la tecnologia e con l'adattazione cloud tutti si sposteranno su quel tipo di approccio e quindi naturalmente devo andare a finire lì o posso tenere un approccio più tradizionale e ovviamente non è che c'è una risposta binaria sì o no c'è il fantastico depends con cui risponde a tutte le domande da consulente. Però l'irraggionamento secondo me che è poi interessante che è venuto fuori a quel tipo di conversazione è sempre il fatto di ma il tuo team che tipo di competenze ha e quanto vuole imparare roba nuova e ovviamente tutto ciò correlato al fatto quale sono le tue deadline che tipo di prodotto stai costruendo e che tempistiche hai per andare sul mercato con questo nuovo prodotto quindi di nuovo non c'è una risposta semplice ma devi andare a osservare tutto questo tipo di cose e cercare di capire quali sono le leve che ha a disposizione alla fine e tirare fuori una strategia pratica. E in quel caso una delle osservazioni che abbiamo notato è se vuoi provare serverless perché è una cosa che i tuoi sviluppatori vogliono provare perché c'è anche un po' di hype e loro si sentono che se non hanno fatto un po' di serverless magari stanno vendo roba obsoleta e non non gli piace. Uno dei casi che secondo me ideali è quello di quando devi andare a fare background processing e quindi sostanzialmente c'è magari un'applicazione fatta in modo tradizionale facciamo finto un web server ad esempio c'è il tuo container o virtual machine che sia gira un processo 24 ore su 24 arrivano richieste risponde se però c'è tutta una serie di roba che deve essere fatto in background non lo so mandare le mail mandare le notifiche ridimensionare immagini o quello che sia il fatto di andare a utilizzare strumenti come sqs e lambda per fare questo tipo di lavoro secondo me uno dei casi d'uso più ideali perché ti leva una marea di complessità infinita e effettivamente secondo me sqs e lambda sono proprio ottimizzati per quel tipo di caso d'uso quindi quello è forse uno dei primissimi casi d'uso che consiglierei a chi vuole iniziare a utilizzare lambda se c'è quel tipo di problema inizia a spostare quel tipo di computazione su sqs e lambda e lì comincia a esplorare che vuol dire scrivere una lambda che vuol dire collegarla sqs che vuol dire il fatto che le lambda scalano in modo dinamico in base a quanti dati stanno su sqs e così via quindi quello è un tipo di architettura chiamiamolo non lo so background processing processing asincrono non ti so dire se c'è un nome più più adeguato altri casi molto comuni sono quello di fare api con api gateway lambda lì secondo me può andare bene in tutta una serie di casi ma non va generalizzato lo uso sempre per tutto perché appunto come diciamo all'inizio della puntata se banalmente deve fare l'upload di un file non è la soluzione migliore farlo con api gateway lambda molto probabilmente non è una buona soluzione per niente quindi le piase con l'essere dopo aver letto il post di luciano ok anche quello lo metteremo nei link grazie della pubblicità però banalmente se ad esempio devi fare un webbook cioè c'è un evento che t'arriva da qualche altro servizio e vuoi avere un end point che riceve quell'evento e fa qualcosa fare una lambda è semplicissimo piuttosto che andare a mettere in piedi un web server tradizionale quindi anche lì si parla comunque di end point http però dipende il caso d'uso può essere ideale farlo con lambda piuttosto che magari non sempre così ideale è un altro caso d'uso che se non è uno molto interessante su cui c'è secondo me tanto che vedremo negli anni futuri è quello del big data e anche tu l'hai menzionato quasi come un caso in antitesi per il serverless ti dirò che ho lavorato con un cliente tra l'altro è uno dei casi d'uso secondo me più interessanti su cui ho lavorato in cui abbiamo costruito una pipeline che riesce a calcolare veramente terabyte di dati ed è quasi tutta costruita su serverless e lì il vantaggio è che ci sono tutta una serie di workflow che in base a come vengono configurati c'hai uno spike iniziale di computazione e quindi se dovessi far partire delle virtual machine o anche dei container il tempo iniziale di bootstrap è talmente alto che a far partire le lambda benché alla fine la computazione ti costa di più però il cliente riesce a avere una risposta nel minor tempo possibile per loro quella è la cosa più importante quindi pure lì ci sono dei trade off interessanti per cui benché anch'io sono abbastanza d'accordo nel dire che se devi fare big data e magari ti servono delle macchine belle grosse che girano sempre nel 99% dei casi quella è la soluzione corretta ci possono essere le variazioni di quel tipo di problema in cui magari serverless risulta essere la cosa più ideale proprio per quella caratteristica che ha di scalare molto velocemente da 0 a 100 non so se ho risposto sì sì tra l'altro aggiungo una piccola parentesi la mia critica particolare era verso lambda nel mondo big data tu hai tirato fuori un caso d'uso che funziona ma io ci tengo anche a evidenziare che AWS visto che stiamo parlando di AWS ha tutta un'altra serie di servizi serverless per il mondo dei big data uno dei quali è per esempio Athena che è già pensato strutturato e ragiona in un'ottica un po' più diversa quindi il mio esempio di serverless function era correlato al fatto di usare probabilmente uno strumento nel caso che avevo visto io era utilizzare uno strumento per il quale magari non fittava al 100% volevo chiederti anche un'altra cosa interessante in realtà che riguarda proprio al concetto sempre di serverless function e riguarda nel fatto che proprio nella parola no quando si parla di computazione serverless si ragiona in termini di funzione no però nel contempo ti trovi degli strumenti che ti buttano un Laravel dentro una serverless function come reagisci davanti a questo tipo di uso è un misuso o è un caso d'uso che ha anche senso? Io sono all'estate abbastanza contrario anche magari Laravel è un caso estremo ma anche Express che è molto più lightweight non lo metterei dentro una lambda per fare web server perché secondo me lì c'è proprio un problema di astrazioni che non matchano al 100% nel senso che se tu prendi questo tipo di web framework tradizionali sono pensati per girare con una socket TCP che ti gestisce questa connessione HTTP ti arriva una richiesta manda una risposta su questa connessione e il web framework è proprio in controllo di questa connessione può decidere di fare streaming di tagliare questa richiesta a metà fare tutta una serie di cose che nel paradigma lambda non esistono perché l'astrazione sta dopo cioè nel paradigma lambda c'è un evento e una risposta e entrambi sono dei json che vengono totalmente bufferizzati in entrate e uscite non c'è nessun tipo di connessione permanente quindi quello che ci sono degli adapter che trovi per l'arabel per express che ti permettono di far sì che questi eventi vengono convertiti in diciamo richieste risposte finte per dal punto di vista del framework però quello fa sì che tutta una serie di cose poi magari non funziona come tu ti aspetteresti banalmente torniamo sempre al discorso dell'app lodo del download quindi casi d'uso un po più streaming non non funzioneranno quando tu li utilizzi nel contesto di diciamo una un deployment di express dentro una lambda se tu vai a utilizzare quelle funzioni di streaming non possono mai funzionare come funzionerebbero normalmente in un web server quindi secondo me il rischio è sì magari per il 90 per cento dei casi d'uso non vedi la differenza però ci sono un 10 per cento di casi d'uso in cui non funziona proprio e alla fin della fiera ti ritrovi a dover pagare il costo di una strazione che non so che vantaggio ti dà magari l'unico vantaggio che puoi avere la familiarità con quello strumento ma lo stai andando a calare in un contesto che non segue al 100 per cento le regole per cui quello strumento è stato pensato quindi io continuo sempre a sconsigliare quel tipo di approccio poi è vero pure ci possono essere delle condizioni molto particolari in cui dici vabbè ma c'è questo codice in express già scritto è una cosa piccola la prendo e la tiro in una lambda perché comunque voglio andare a fare delle lambda nel breve medio periodo può essere un trade off accettabile se sai esattamente a cosa puoi andare incontro ma non lo farei insomma come best practice anche perché come scorciatoia diciamo anche perché i tempi di boot della lambda e dt express dentro la lambda vogliono dire soldi no? Esatto quindi stai andando a pagare quel tipo di astrazione per non credo avere un tipo di vantaggio pratico se non quello che si se magari già ce l'hai scritta così non devi riscriverla in un altro modo. Certo ma hai detto prima no che in realtà anzi abbiamo detto che in realtà c'è tutto il mondo tutta la parte di glue code si è spostata talvolta si sposta verso l'architettura l'infrastruttura e tra i servizi di AWS c'è sempre un servizio serverless che ha catturato la mia attenzione e che è Upsync che è GraphQL as a service che mettiamola così. Quando Luciano potrebbe scegliere cioè quali sono le condizioni per le quali tu saresti tentato di andare verso una soluzione gestita come Upsync e quando invece preferiresti tirarti su il tuo buon appollo che ti chiama i tuoi microservizi davanti magari a un API gateway della situazione? Allora su questo argomento sono piuttosto ignorante quindi ti do una risposta molto vaga nel senso che ho praticamente quasi mai fatto GraphQL in produzione ho solo fatto così dei giochini per per conto mio personale quindi non ti saprei dire quanto Upsync effettivamente a livello proprio di feature è in pari con un Apollo Server mi aspetto conoscendo AWS che non lo sia nel senso che un Apollo Server magari ti da molta più flessibilità rispetto ad Upsync e quindi forse il trade off è sempre un po' lo stesso quello di dire ma quanta voglia c'ho tempo risorse di andarmi a gestire io un container che sia o una macchina virtuale rispetto con qualcosa che dico vabbè quando arriva a sta chiamata parte sta lambda che già ho scritto e basta e non mi interessa pensare al sistema operativo alle librerie eccetera quindi forse fare questo tipo di ragionamento e dipende dalla complessità del tipo di applicazione che stiamo andando a scrivere e il tipo di feature che mi servono magari posso decidere vale la pena andare a pagare quel costo aggiuntivo di manutenzione dell'infrastruttura piuttosto che andare a utilizzare un servizio managed come Upsync ma ripeto non conoscendo benissimo i dettagli di della tecnologia specifica quello che ho detto potrebbe avere più o meno senso. No io ritornando ad Upsync tipo ha catturato la mia attenzione perché è uno strumento che fa praticamente buona parte di quello che il nostro buon amico Carmine chiamerebbe il crudino della chiesa su GraphQL nel senso che si interfaccia e proprio come buona parte dei prodotti AWS pensato per interfacciarsi con gli altri servizi di AWS quindi si ti può chiamare una lambda che possiamo vedere in modo un po' con la zappa come un microservizio ma ti può anche chiamare l'open search della situazione che è l'omologo di Elasticsearch as a service o puoi andare a scrivere roba su Dynamo o su Aurora anche questi magari serverless e qua io dico vabbè a questo punto credimi il po' di lavoro scimmiesco di due sviluppatori te lo sei tirato via perché anche questo dobbiamo dire quindi cioè spostando una parte di responsabilità nell'infrastruttura stiamo anche andando verso un approccio un pelino più no code o siccome usiamo infrastructure as a code potremmo dire un po' codeless no? Nel senso scrivere un terraform è sicuramente più conciso poi insomma terraform è abbastanza verboso però scrivere un terraform è sicuramente più conciso che fare il servizio GraphQL e i crude a mano nel contempo però ho ne approfittato per introdurre tutto il concetto di database serverless su questi quindi Aurora serverless Dynamo hai già anticipato che hai qualche strong opinion su Dynamo qual è però la tua visione nel concetto generale no di data storage in termini di dati di questo tipo? Sì diciamo la mia strong opinion rispetto a Dynamo è il fatto che viene un po' venduto come database general purpose quando secondo me lo è relativamente nel senso che è un ottimo database quando già sai esattamente tutti gli access pattern ai dati e di conseguenza in quel caso puoi andare a ottimizzare proprio la struttura del database per quegli access pattern e c'hai tutta una serie di vantaggi cioè sicuramente un database molto efficiente già distribuito il livello di manutenzione minimo però non è un database molto dinamico nel senso che se l'indomani a livello di business ti rendi conto che hai sbagliato qualcosa o ti serve un campo in più o devi modificare un workflow buon divertimento a fare una migrazione dei dati perché non esiste neanche il concetto di migrazione dei dati cioè ti devi andare a fare tutto tu da solo e mi è capitato di dover fare questa cosa DynamoDB e la complessità è assurda cioè quello che tu faresti con un sequel che dici alter table aggiungi un nuovo campo e questo campo deve avere il valore del campo precedente moltiplicato per due che è una query che ci metti due secondi a scriverla a farla in DynamoDB ci perdi le settimane solo a capire come orchestrare un workflow che ti fa lo scan di tutto e ti aggiorna tutti tutti i record quindi cioè vanno vanno tenute in considerazione queste cose secondo me a livello di marketing non viene venduto DynamoDB con questo tipo di prospettiva ma viene venduto come vabbè se fai serverless usi DynamoDB di default e puoi fare tutto addirittura che non è necessariamente vero. Mi ricordi io ho lavorato poco con DynamoDB ma mentre mi documentavo avevo letto che c'erano anche dei pattern di single table cioè te metti tutte le date nella singola tabella e poi lavori solo sui filtri sui dati che ci sono che per uno che viene da un database anche documentale ma se no è skew head dice va bene gli utenti li mettono nella tabella utenti i prodotti nella tabella prodotti invece lì metti tutto insieme e fai dei filtri per tirare fuori dallo stesso bucket questa cosa che è un po' difficile da intuire. Non concordo assolutamente c'è un libro intero di Alex Debrie che tra l'altro consiglio perché è un ottimo libro solo per capire come applicare questo tipo di mentalità quindi non è una cosa così ovvia cioè non è una cosa che di default ti viene da andare a impostare un database in questo modo e questo tipo di approccio a mia opinione ma forse mi riservo pure il fatto di non aver capito al 100% quello che Alex voleva comunicare con questo suo libro sì magari ti dà un po' di libertà in più nel data modeling di evolvere quel data modeling man mano che scopri dei nuovi requisiti o deve implementare le nuove funzionalità ma comunque secondo me parte da un presupposto in cui hai già molto più chiaro di quello che avresti magari con un approccio SQL tradizionale quali sono gli access pattern rispetto a appunto confrontando il modello SQL col modello no SQL secondo me la differenza chiave è proprio quella che il modello SQL è pensato per dire tu mi dici quali sono i dati io mi vedo tutto il resto e se vuoi cambiare le cose hai tutti gli strumenti per farlo e ti cerco di diminuire al massimo la duplicazione dei dati il modello no SQL è proprio diametralmente opposto cioè io ti ottimizzo per degli access pattern specifici se ne vuoi altri duplica i dati e quelli sono ottimizzati pure e questa non è una cosa che viene comunicata bene a livello di marketing cioè viene più che altro detto se fai serverless devi usare DynamoDB se fai applicazioni tradizionali che girano su virtual machine puoi usare SQL quando secondo me questa cosa non è cioè l'uno non escude necessariamente l'altro. Eppure sembra strano sai perché quello che dici non fa non fa una piega sono tipo d'accordo al 200 per cento però nella zona B del mio cervello mi è ritornato in mente un mantra che era il mantra ed è il mantra di tutto il movimento no SQL no? Cioè tutto ciò che riguarda SQL possiamo vederlo con SQL e no SQL sono delle parole di marketing noi potremmo dire schema on write per tutto il mondo di SQL e schema on read per tutto il mondo no SQL che però è una cosa che fa conflige in qualche modo con quello che hai appena detto e sul quale sono d'accordo tra l'altro cioè se io voglio accedere ai dati in modo in modo in modo anche efficiente non deve aver già pensato al motivo per cui voglio accedere questa cosa nella mia testa sta prendendo a schiaffi col concetto di schema on read perché in realtà nella definizione implicita no di schema on read sto dicendo esattamente il contrario cioè definisco lo schema dei dati quando vado a leggerli adesso io non chiedo a nessuno di dare una risposta a questa piccola pazzia però ecco vi chiedo e chiedo anche a tutti gli ascoltati di fermarsi un attimo a riflettere su questa contraddizione perché probabilmente c'è una contraddizione anche nel modo nel quale noi vediamo queste tecnologie no? Cosa ne dite? Secondo me c'è pure un'altra dimensione da esplorare che forse viene sempre un po' messa in secondo piano che è quella proprio dell'architettura di questi due diversi diciamo tipologie di database in genere quando prendi SQL si parla sempre o quasi sempre del database monolitico che ti dà tutta una serie di caratteristiche e proprio perché è monolitico tutto sta in un unico server può fare tutta una serie di cose quando si parla di NoSQL si pensa già a database distribuiti che quindi devono capire già come partizionare i dati e come conseguenza di ciò ci hanno pure tutta una serie di limitazioni aggiuntive e quindi magari si tente di più alla duplicazione dei dati perché quella è diciamo la soluzione più semplice al problema o a diminuire le capacità di query perché anche quello ti permette di fare tutta una serie di cose in più dal punto di vista della distribuzione dei dati e quando fai una query di andare a interrogare più nodi e riaggregare risultati quindi quella secondo me è una cosa che viene sempre messo un po' in secondo piano perché raramente si va a guardare l'architettura del database e si pensa più dal punto di vista utente qual è il linguaggio di query e quali sono le capacità che hai però secondo me se ci andiamo a leggere ad esempio il paper di DynamoDB che poi quello che ha pure ispirato Cassandra si capisce anche il perché DynamoDB o Cassandra che sia siano molto più limitate a un punto di vista di gestione dei dati di quanto sia il classico database SQL monolitico in cui non hai il problema di dover distribuire dati e aggregare le query. Senza neanche aprire il capitolo transazioni perché a quel punto veramente la diversità si acuisce e questo dimostra un fatto importante che in buona parte delle nostre applicazioni noi utilizziamo un tool perché il contesto ci spinge, il marketing ci spinge, quando magari fermarci un attimo e leggere un libro che per me è quasi più importante della Bibbia tipo Data Intensive Applications che secondo me è veramente un viaggio, cioè a me ha aiutato proprio a sviluppare quel tipo di consapevolezza che spesso dimentico ma comunque mi ha aiutato a costruirla per capire che talvolta la scelta non è sul motore di query che utilizziamo solo su come andiamo a prendere i dati o a salvare i dati ma quello che ci sta sotto probabilmente potrà tornarci indietro come un boomerang in un secondo momento. Io guardavo l'orologio, cioè sembra che abbiamo appena iniziato a registrare, ci stiamo giusto riscaldando ed è tipo passata un'ora e venti, quindi io chiedo rapidamente a Luca e a Leo se hanno qualche domanda per Luciano. No, non adesso. No, ma come al solito mi verranno sotto la doccia domani, poi sarà troppo tardi, pazienza lo troverò nel gruppo forse. Io a questo punto vorrei chiedere a Luciano, anzi andare insieme a Luciano, Luca e Leo nel momento tipico e topico del nostro podcast, il momento il Paese dei Balocchi, il momento in cui i guest e gli host condividono con noi un tool, un libro, un video, una ricetta, qualcosa che abbia in qualche modo colpito particolarmente la loro attenzione. Quindi la prima domanda va verso Luciano. Luciano c'è qualcosa che vuoi condividere con la nostra community? E conducono il Paese dei Balocchi. Ah, il Paese dei Balocchi. Allora faccio un velocissimo recap innanzitutto dei link che abbiamo promesso di dare e che poi spero verranno inseriti in questa sezione. Uno era il post di Owen Schanachy, il CTO di Fortiorem riguardo al prezzo, il confronto di prezzo tra EC2, Fargate e Lambda e quello secondo me è un post ottimo a qualche anno ma secondo me ad oggi è ancora molto rilevante. L'altro è quel caso d'uso che avevo menzionato riguardo a fare big data con serverless ed è un caso d'uso con cui è stato fatto anche un articolo che è stato pubblicato proprio sul blog di AWS quindi spero che vogliate linkare anche quel blog post per far capire perché in quel caso particolare secondo me Lambda ha più senso di altre soluzioni nonostante stiamo parlando di big data. E un'altra cosa che vorrei menzionare, questo forse è il mio link aggiuntivo, è il fatto che ultimamente mi sto un po' dilettando con Rust, ne avevamo parlato pure un po' prima della live e quindi ho provato anche un po' a esplorare il discorso di posso scrivere una Lambda in Rust e quali sono i vantaggi e gli svantaggi e la complessità del caso e da una parte ho trovato questo articolo che bilinco di una società che si chiama Scanner che è proprio un how to, cioè come fare a fare la prima Lambda, quali sono gli strumenti ed è fatto molto bene, dall'altro è un argomento che parleremo nella prossima puntata del podcast di AWSbytes che è un podcast che gestisco insieme a Owen Shanaghi di Fortiorem e appunto parleremo proprio di vantaggi e svantaggi e come fare a scrivere la prima Lambda in Rust quindi vi mando pure come riferimento a vedere questa puntata di AWSbytes. E tra l'altro anche la puntata, anche il link di AWSbytes lo mettiamo nelle note dell'episodio. Leo, Luca cosa avete da condividere con noi? Allora io ho due cose velocissime che non centrano nulla con l'argomento come al solito, la prima è un videogioco che ho sentito come balocco su digitalia che si chiama Vampire Survivors, è un survivor game, uno dei giochi con il più alto rilascio di endorfine che abbia mai trovato, c'è su Steam, c'è anche la versione mobile, è stato fatto da un italiano ed è il gioco su Steam fatto da un italiano con più successo, un successo improvviso, vi invito anche a leggere le interviste che sono state fatte, molto divertente, non vi dico nulla, andate a provarlo. E l'altro è una serie TV che si chiama Kaleidoscope che si trova su Netflix che ha una cosa particolare perché in pratica gli episodi sono stati fatti per essere visti nell'ordine in cui uno vuole, sono ordinati dall'1 all'8 mi pare la prima stagione, però sono identificati con dei colori, in pratica parla di una grossa rapina che deve essere fatta, però a seconda di come uno vede l'ordine degli episodi, prende diverse angolazioni, ho visto due episodi, il pilot, il primo, il secondo è un flashback di 24 anni prima, quindi più o meno ho capito che viene preso lo stesso argomento da diversi punti del tempo e mi sembra interessante, condivido queste due cose, troverete i link nell'episodio. Io balocco anche un'app, un'app per mobile, sapete che mi dedico agli scacchi ogni tanto, sto cercando di imparare a superare un livello quanto meno decente, a parte ovviamente il blasonato c'è il scom, c'è il Dr. Wolf che è un vecchio che ti insegna a giocare a scacchi e ti spiega le mosse, ti fa fare proprio un percorso, ti dice guarda in questa partita scoprirò il mio re, vedi se riesci a farmi scaccomato in questo modo, oppure farò un errore nel mezzo che ti consentirà di fare un fork, prova a far quello, insomma ha un approccio divertente che sta, spero, credo, funzionando. Io per adesso non ho ancora fatto partite perché ho l'ansia della prestazione e della sindrome dell'impostore, però sto aumentando il mio livello almeno virtuale contro il computer, perché se poi una partita ho fatto effettivamente ha funzionato parecchio, ho fatto alcune mosse che erano… ero veramente orgoglioso delle mosse che avevo fatto. Il secondo balocco è un piccolo libricino che probabilmente ho già baloccato ma me lo trovavo davanti adesso, ho detto perché no, si chiama Mentire con le statistiche di Darrell Huff, lo si trova anche in italiano, appunto insegna come mentire con le statistiche in questo caso per difenderti da chi cerca di rifilarti statistiche vere ma false, quindi statistiche basate su dati veri ma presentati in modo che ti sembrano quello che in realtà non sono. C'è quel famoso esempio che era il film di Nicolas Cage correlato alle morti per annegamento in piscina? Sì anche quello ma anche come proprio vengono banalmente disegnati i grafici prendendo come origine non lo zero ma il punto più alto oppure quando si gioca con le proporzioni sui volumi invece che sulle aree, insomma tante cose di questo tipo oppure anche quando ti presentano dati, i sondaggi omettendo la base campione e quindi ti spiega proprio su esempi reali, su esempi di giornali negli ultimi anni, in realtà negli ultimi decenni, ti apre gli occhi e ti fa leggere la realtà in modo diverso, la realtà che ti vogliono appropinare in modo diverso. Comunque era carina l'introduzione che hai fatto quando hai detto serve per difendersi, sembrava un po' il disclaimer che c'è in buona parte degli scriptini, degli script kiddies che dice questo script è fatto solo a scopo educativo, non utilizzatelo! Quante volte l'abbiamo visto? Quante volte l'abbiamo scritto? Questo repository è fatto solo a scopo educativo e magari sono una roba per utilizzare le API di Grammarly che non sono pubbliche, però è solo a scopo educativo, cito Grammarly non a caso perché io tipo con le API sono un paio d'anni che le uso e finalmente ce le hanno aperte. E allora proprio così introduco il mio balocco, vi devo dire una cosa, in una settimana e mezzo questo è il quinto episodio che registriamo, quindi potrei essere a corto di balocchi ma ne ho tre! Il primo è Grammarly, se non l'avete provato provatelo, se siete delle capre con l'inglese, amici miei siete come me, utilizzatelo perché aiuta tantissimo. La cosa veramente figa di Grammarly è che hanno rilasciato da poco le API, quindi se fate un'iscrizione subscribe pagante che costa attorno ai centinaio di euro l'anno, quindi poco meno di 10 euro al mese, veramente poco per quello che ti da, cioè ti evita di fare figure di merda fondamentalmente, è molto utile e la cosa figa è che vi dà tipo c'è un SDK che vi dà anche il componente React che ha già la correzione grammaticale di Grammarly e la cosa è parecchio figa perché la potete potete fare il vostro text editor che è un po' quello che sto provando a fare io nel mio poco tempo libero, specifico per il vostro caso d'uso. Questo è il primo balocco, il secondo balocco colgo l'occasione insomma dell'introduzione che ha fatto Luciano su Rust per dire che io sono abbastanza tonto e quindi sto leggendo per la seconda volta Rust in Action, lo sto rileggendo perché secondo me è uno di quei libri che se lo si legge tutto ad un fiatto va riletto una seconda volta con molta più calma e magari prendendo lo stimolo da là e andando al Rust book per andare poi più a fondo su alcuni concetti e sono ricapitato su un esempio, un blocco di codice sul quale ero andato molto veloce sopra che era la creazione di un grafico di Mandelbrot o Mandelbrot non so come si pronuncia però vedere quell'immagine mi ha riapperto un cassettino e sono andato nella libreria a cercare il libro in questione e il libro è Abbas e Euclide di Pier Giorgio Odifreddi che spiega proprio anche tra i vari concetti che spiega c'è proprio il concetto di Mandelbrot e di quant'altro quindi sono riandato a leggere il capitolino il paragraffetto di Abbas e Euclide di Odifreddi se non l'avete letto leggetelo giusto per fare una passeggiata in concetti che perlomeno io non avevo alcune idee di cosa potessero essere li vedevo come delle robe astruse e Odifreddi nonostante abbia tanti limiti non mi stia troppo simpatico in cui il libro veramente è riuscito a esprimere concetti abbastanza complessi in modo molto molto semplice e questo può essere un insegnamento anche in quello che facciamo all'interno del podcast. Ultimo balocco è una roba strana dico strana non so ancora se figa o meno perché oggi nella chat aziendale un collega che cito per nome che penso ci stia sentendo Matteo Pietro ha condiviso un link a un nuovo linguaggio di programmazione o almeno così pare abbastanza nuovo visto che ne esce praticamente una settimana si chiama wing ed è un linguaggio di programmazione che in qualche modo si propone di essere un linguaggio pensato per il cloud si sposa abbastanza bene con l'episodio di oggi in realtà perché ci sono tutta una serie di metodi di funzionalità che triggerano attivano delle AWS lambda fanno fanno delle robe la cosa veramente particolare che ho visto nell'esempio non ci ho dedicato troppo tempo però c'è una cosa che ha catturato la mia attenzione è che in mezzo al codice di infrastruttura immaginiamolo come il codice cdk c'è una puntata registrata con leo qualche eone fa dove parlavamo di cdk per immaginatelo come del codice cdk che è una sorta di cloud formation in typescript ma dove dentro c'è anche della business logic questa cosa mi ha mandato tipo in buffer overflow e non riesco a capire se è una roba fighissima o schifosissima per cui ditemelo voi insomma nel gruppo telegram senza dubbio ha senso anche solo per farci questo tipo di domanda buttarci un occhio. Come sempre ragazzi io non so perché vengo sempre messo in mezzo in questa cosa probabilmente perché sono l'unico che non si vergogna a parlare di soldi ma non vedo perché vergognarsi è una cosa così bella parlare di soldi perché i soldi sono veramente la cosa più bella del mondo quindi donate perché dobbiamo fare cena da massimo bottura con i vostri soldi quindi è una cosa molto importante e siamo molto poveri quindi donate copiosamente veramente in tantissimi mi raccomando dateci i vostri soldi e noi ne faremo l'uso più responsabile che se ne possa fare ovvero metterli su delle crypto uscite da mezz'ora. è il momento di ringraziare i nostri donatori questa settimana abbiamo il primo donatore del 2023 che ringraziamo e tra l'altro è anche anonimo anche se noi sappiamo chi è quindi sappiamo chi sei scherzo grazie per gli interessanti contenuti che ci regalate grazie a te caro anonimo anche perché sei il primo donatore di questo nuovo anno che abbiamo aperto con una decisione anche abbastanza forte che è stata quella di rimuovere le pubblicità quindi adesso insomma è tutto sul nostro groppone vi ricordo che se volete sostenerci e non volete fare una donazione diretta che potete comunque fare andando nel sito www.gitbar.it potete tranquillamente cliccare su uno dei link che trovate all'interno delle note degli episodi o che puntano ad amazon in quel caso si setta una sessione che se non mi sbaglio dura per 30 giorni e pochi centesimi dei vostri acquisti andranno anche al nostro supporto grazie di cuore e grazie anonimo Eccoci qua sono le 10 le 22 e 43 e siamo ancora tutti in piedi belli arzilli Bell'arzillo sarebbe... non so che cosa sta succedendo Io morire di sonno però vabbè Luciano grazie grazie mille per essere venuti a trovarci ricordiamo rapidamente i tuoi contatti Allora innanzitutto grazie a voi perché è sempre un piacere imparo sempre tantissimo quindi grazie i miei contatti mi trovate su twitter come loige o mi trovate su github come lmammino e mi trovate anche su linkedin poi ultimamente mi sto dilettando un po' su twitch a fare dei live stream ogni tanto quindi se vi piace rust e vi piace vedere come io faccio finta di capire rust ma in realtà poi mi scontro col compilatore e finiamo a litigare mi trovate su twitch sempre come loige e niente questi penso siano un po' tutti i miei contatti E in libreria con note.js design pattern dai che ti ci devi comprare la casa al mare quella sì sì grazie metti pure il link anzi mando pure quello che tra l'altro è una delle pietre miliari non so se l'ho già detto per la programmazione per chiunque abbia sviluppato un odd un'occhiata deve averla data a quel libro non piratato però compratelo bene leo luca luciano grazie davvero di questa serata super figa è stato veramente un piacere ecco riavervi tutti e tre qua sono senza parole cosa devo fare adesso ragazzi luca leo aiutatemi vi prego i contatti ecco ecco i contatti dimenticamo mi raccomando questa parte la taglio perché tipo sono andato davvero in buffero per flusso c'è un annulpo intera no è il bello della diretta giusto prima di chiudere una piccola cosa mi raccomando se avete un device apple andate su itunes stellinateci metteteci in cuoricino lasciateci una recensione questo fa in modo di in qualche modo continuare a preservare la nostra posizione all'interno delle classifiche di itunes e quindi riuscire a raggiungere nuove orecchie vi ricordiamo rapidamente i nostri contatti info che sono a github.it e il gruppo telegram che trovate cercando github telegram e cliccando sul primo risultato a occhi chiusi perché faremo noi detto questo io ringrazio nuovamente luciano per essere venuto a trovarci ormai tu lo sai no? github è un po' anche casa tua quindi quando hai qualcosa di nuovo quando il compilatore di rust ti dice qualcosa di interessante ecco vieni da noi a raccontarcelo perché insomma github è il circolo degli sviluppatori dove hai la tessera è tra l'altro una delle prime ms quindi ti aspettiamo per il momento il compilatore di rust mi dice solo vai a zappare quindi quando cambieremo questa storia magari arriverò a parlare di rust e devo dire ringraziamo che non ci sono le emoji se no la frustrazione salirebbe ancora di più detto questo io vi do appuntamento alla prossima settimana ciao ciao ciao ciao ciao git bar il circolo dei full stack developer una volta a settimana ci troviamo davanti a due birre e con brain repo parliamo di linguaggi e tecniche di sviluppo web di metodologie ed strumenti immancabili nella cassetta degli attrezzi dei full stack dev",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0,
      "end": 5.44,
      "text": " Bene e benvenuti su Geekbar, nuova settimana, nuova settimana e nuovo episodio",
      "tokens": [
        27702,
        308,
        3271,
        553,
        29161,
        459,
        2876,
        916,
        5356,
        11,
        3822,
        27924,
        5584,
        36497,
        11,
        3822,
        27924,
        5584,
        36497,
        308,
        49348,
        39200,
        1004
      ],
      "temperature": 0,
      "avg_logprob": -0.29547629868688663,
      "compression_ratio": 1.5791666666666666,
      "no_speech_prob": 0.06274671852588654
    },
    {
      "id": 1,
      "seek": 0,
      "start": 5.44,
      "end": 11.08,
      "text": " qua sul nostro bar per gli sviluppatori. Iniziamo già malissimo stasera, le",
      "tokens": [
        24159,
        17603,
        35779,
        2159,
        680,
        17161,
        17342,
        388,
        10504,
        39842,
        13,
        682,
        590,
        7415,
        30469,
        2806,
        34966,
        342,
        296,
        1663,
        11,
        476
      ],
      "temperature": 0,
      "avg_logprob": -0.29547629868688663,
      "compression_ratio": 1.5791666666666666,
      "no_speech_prob": 0.06274671852588654
    },
    {
      "id": 2,
      "seek": 0,
      "start": 11.08,
      "end": 18.76,
      "text": " energie sono al limite e a fianco a me ho un taco che è il mio pranzo",
      "tokens": [
        2043,
        9997,
        9259,
        419,
        39946,
        308,
        257,
        49513,
        1291,
        257,
        385,
        1106,
        517,
        34101,
        947,
        4873,
        1930,
        29908,
        582,
        3910,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.29547629868688663,
      "compression_ratio": 1.5791666666666666,
      "no_speech_prob": 0.06274671852588654
    },
    {
      "id": 3,
      "seek": 0,
      "start": 18.76,
      "end": 23.52,
      "text": " ok? E appena arrivate del mio pranzo questo vi fa un po' capire in che",
      "tokens": [
        3133,
        30,
        462,
        724,
        4118,
        3399,
        19083,
        1103,
        29908,
        582,
        3910,
        78,
        10263,
        1932,
        2050,
        517,
        714,
        6,
        1410,
        621,
        294,
        947
      ],
      "temperature": 0,
      "avg_logprob": -0.29547629868688663,
      "compression_ratio": 1.5791666666666666,
      "no_speech_prob": 0.06274671852588654
    },
    {
      "id": 4,
      "seek": 0,
      "start": 23.52,
      "end": 29.72,
      "text": " condizioni sono, è stata una giornata di fuoco al lavoro ma per fortuna non sono",
      "tokens": [
        2224,
        590,
        15273,
        9259,
        11,
        4873,
        49554,
        2002,
        36937,
        3274,
        1026,
        8536,
        11198,
        419,
        42060,
        463,
        680,
        5009,
        5051,
        2107,
        9259
      ],
      "temperature": 0,
      "avg_logprob": -0.29547629868688663,
      "compression_ratio": 1.5791666666666666,
      "no_speech_prob": 0.06274671852588654
    },
    {
      "id": 5,
      "seek": 2972,
      "start": 29.72,
      "end": 37.08,
      "text": " solo, ho con me Leo e Luca, ciao ragazzi com'è? Ciao bene ma scusa una domanda",
      "tokens": [
        6944,
        11,
        1106,
        416,
        385,
        19344,
        308,
        42076,
        11,
        42860,
        17539,
        33910,
        395,
        6,
        1462,
        30,
        28473,
        2537,
        463,
        795,
        20318,
        2002,
        3285,
        5575
      ],
      "temperature": 0,
      "avg_logprob": -0.39863029791384325,
      "compression_ratio": 1.4242424242424243,
      "no_speech_prob": 0.00003169313640682958
    },
    {
      "id": 6,
      "seek": 2972,
      "start": 37.08,
      "end": 43.04,
      "text": " il tuo pranzo o la cena? Il pranzo. L'ultima volta che hai preso un taco in",
      "tokens": [
        1930,
        45352,
        582,
        3910,
        78,
        277,
        635,
        41777,
        30,
        4416,
        582,
        3910,
        78,
        13,
        441,
        6,
        723,
        4775,
        18765,
        947,
        21822,
        1183,
        78,
        517,
        34101,
        294
      ],
      "temperature": 0,
      "avg_logprob": -0.39863029791384325,
      "compression_ratio": 1.4242424242424243,
      "no_speech_prob": 0.00003169313640682958
    },
    {
      "id": 7,
      "seek": 2972,
      "start": 43.04,
      "end": 48.599999999999994,
      "text": " puntata hai detto che non era andata troppo bene. Eh sì la digestione è un po'",
      "tokens": [
        18212,
        3274,
        21822,
        41031,
        947,
        2107,
        4249,
        293,
        3274,
        4495,
        27000,
        2537,
        13,
        9663,
        49267,
        635,
        13884,
        5328,
        4873,
        517,
        714,
        6
      ],
      "temperature": 0,
      "avg_logprob": -0.39863029791384325,
      "compression_ratio": 1.4242424242424243,
      "no_speech_prob": 0.00003169313640682958
    },
    {
      "id": 8,
      "seek": 2972,
      "start": 48.599999999999994,
      "end": 55.519999999999996,
      "text": " lenta, è per quello che è. E' parcheggiato.",
      "tokens": [
        287,
        8938,
        11,
        4873,
        680,
        22813,
        947,
        4873,
        13,
        462,
        6,
        35765,
        1146,
        7834,
        2513,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.39863029791384325,
      "compression_ratio": 1.4242424242424243,
      "no_speech_prob": 0.00003169313640682958
    },
    {
      "id": 9,
      "seek": 5552,
      "start": 55.52,
      "end": 62.2,
      "text": " Un po' spostproduzione poi leviamo tutti i suoni molestici che ci sono. Sì io adoro i taco ma",
      "tokens": [
        1156,
        714,
        6,
        637,
        555,
        14314,
        19706,
        19260,
        20445,
        7415,
        19822,
        741,
        459,
        17049,
        8015,
        377,
        8787,
        947,
        6983,
        9259,
        13,
        318,
        4749,
        19785,
        614,
        10780,
        741,
        34101,
        463
      ],
      "temperature": 0,
      "avg_logprob": -0.43291473388671875,
      "compression_ratio": 1.4080459770114941,
      "no_speech_prob": 0.000002769396814983338
    },
    {
      "id": 10,
      "seek": 5552,
      "start": 62.2,
      "end": 69.68,
      "text": " hanno una digestione waterfall, è un po' insomma tutto dire. Voi come",
      "tokens": [
        26595,
        2002,
        13884,
        5328,
        27848,
        11,
        4873,
        517,
        714,
        6,
        1028,
        30243,
        23048,
        1264,
        13,
        691,
        4869,
        808
      ],
      "temperature": 0,
      "avg_logprob": -0.43291473388671875,
      "compression_ratio": 1.4080459770114941,
      "no_speech_prob": 0.000002769396814983338
    },
    {
      "id": 11,
      "seek": 5552,
      "start": 69.68,
      "end": 80.88,
      "text": " state Luca e Leo? Vai Leo. Io sto bene, stiamo lavorando molto e non posso dire",
      "tokens": [
        1785,
        42076,
        308,
        19344,
        30,
        24206,
        19344,
        13,
        19239,
        22784,
        2537,
        11,
        342,
        7415,
        29241,
        1806,
        16394,
        308,
        2107,
        22501,
        1264
      ],
      "temperature": 0,
      "avg_logprob": -0.43291473388671875,
      "compression_ratio": 1.4080459770114941,
      "no_speech_prob": 0.000002769396814983338
    },
    {
      "id": 12,
      "seek": 8088,
      "start": 80.88,
      "end": 89,
      "text": " molto però abbiamo delle release da fare nei prossimi mesi. Tutto bene. Io tutte le",
      "tokens": [
        16394,
        12673,
        22815,
        16485,
        4374,
        1120,
        11994,
        34517,
        48794,
        10121,
        3813,
        72,
        13,
        18392,
        1353,
        2537,
        13,
        19239,
        38632,
        476
      ],
      "temperature": 0,
      "avg_logprob": -0.283960192391042,
      "compression_ratio": 1.4593301435406698,
      "no_speech_prob": 7.338169893955637e-7
    },
    {
      "id": 13,
      "seek": 8088,
      "start": 89,
      "end": 96.16,
      "text": " volte che chiedo qualcosa a Leo fa sempre riferimento all'NDA, allora",
      "tokens": [
        37801,
        947,
        417,
        36035,
        42400,
        257,
        19344,
        2050,
        9553,
        367,
        9361,
        10030,
        439,
        6,
        45,
        7509,
        11,
        44141
      ],
      "temperature": 0,
      "avg_logprob": -0.283960192391042,
      "compression_ratio": 1.4593301435406698,
      "no_speech_prob": 7.338169893955637e-7
    },
    {
      "id": 14,
      "seek": 8088,
      "start": 96.16,
      "end": 101.12,
      "text": " quando è che venite in puntata e ci raccontate profondamente che cosa state",
      "tokens": [
        7770,
        4873,
        947,
        6138,
        642,
        294,
        18212,
        3274,
        308,
        6983,
        4129,
        9000,
        473,
        1740,
        684,
        3439,
        947,
        10163,
        1785
      ],
      "temperature": 0,
      "avg_logprob": -0.283960192391042,
      "compression_ratio": 1.4593301435406698,
      "no_speech_prob": 7.338169893955637e-7
    },
    {
      "id": 15,
      "seek": 8088,
      "start": 101.12,
      "end": 107.56,
      "text": " facendo? Sono sotto NDA e non lo posso dire. Anche la data non puoi dire.",
      "tokens": [
        1915,
        3999,
        30,
        48344,
        43754,
        426,
        7509,
        308,
        2107,
        450,
        22501,
        1264,
        13,
        1107,
        1876,
        635,
        1412,
        2107,
        2362,
        4869,
        1264,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.283960192391042,
      "compression_ratio": 1.4593301435406698,
      "no_speech_prob": 7.338169893955637e-7
    },
    {
      "id": 16,
      "seek": 10756,
      "start": 107.56,
      "end": 111.8,
      "text": " Tu Luca?",
      "tokens": [
        7836,
        42076,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.4963927205403646,
      "compression_ratio": 1.5298013245033113,
      "no_speech_prob": 9.329487937748127e-8
    },
    {
      "id": 17,
      "seek": 10756,
      "start": 111.96000000000001,
      "end": 119.24000000000001,
      "text": " Va beh ok. Non si può dire niente. Tu Luca? Io pure sì sì tutto bene,",
      "tokens": [
        16822,
        1540,
        3133,
        13,
        8774,
        1511,
        26526,
        1264,
        297,
        8413,
        13,
        7836,
        42076,
        30,
        19239,
        6075,
        49267,
        49267,
        23048,
        2537,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.4963927205403646,
      "compression_ratio": 1.5298013245033113,
      "no_speech_prob": 9.329487937748127e-8
    },
    {
      "id": 18,
      "seek": 10756,
      "start": 119.24000000000001,
      "end": 127.08,
      "text": " tanto lavoro, ho cambiato lavoro da qualche mese quindi cose nuove, tanti",
      "tokens": [
        10331,
        42060,
        11,
        1106,
        19569,
        2513,
        42060,
        1120,
        38737,
        275,
        1130,
        15727,
        30261,
        3822,
        1682,
        11,
        256,
        11520
      ],
      "temperature": 0,
      "avg_logprob": -0.4963927205403646,
      "compression_ratio": 1.5298013245033113,
      "no_speech_prob": 9.329487937748127e-8
    },
    {
      "id": 19,
      "seek": 10756,
      "start": 127.08,
      "end": 130.6,
      "text": " strumenti nuove, tante cose da studiare, tante cose da gestire, quindi sono",
      "tokens": [
        1056,
        2206,
        72,
        3822,
        1682,
        11,
        256,
        2879,
        30261,
        1120,
        972,
        72,
        543,
        11,
        256,
        2879,
        30261,
        1120,
        7219,
        621,
        11,
        15727,
        9259
      ],
      "temperature": 0,
      "avg_logprob": -0.4963927205403646,
      "compression_ratio": 1.5298013245033113,
      "no_speech_prob": 9.329487937748127e-8
    },
    {
      "id": 20,
      "seek": 13060,
      "start": 130.6,
      "end": 139.12,
      "text": " abbastanza in burnout. Grazie. Io sto fremendo in realtà, io sto fremendo ragazzi",
      "tokens": [
        16903,
        525,
        20030,
        294,
        44841,
        13,
        8985,
        3283,
        13,
        19239,
        22784,
        2130,
        76,
        3999,
        294,
        47512,
        11,
        19785,
        22784,
        2130,
        76,
        3999,
        17539,
        33910
      ],
      "temperature": 0,
      "avg_logprob": -0.26314235945879405,
      "compression_ratio": 1.5916666666666666,
      "no_speech_prob": 3.15610634515906e-7
    },
    {
      "id": 21,
      "seek": 13060,
      "start": 139.12,
      "end": 144.4,
      "text": " perché abbiamo un ospite super speciale, un amico di Gitbar, abbiamo già bevuto",
      "tokens": [
        14303,
        22815,
        517,
        3003,
        79,
        642,
        1687,
        2121,
        68,
        11,
        517,
        669,
        2789,
        1026,
        460,
        270,
        5356,
        11,
        22815,
        30469,
        312,
        85,
        8262
      ],
      "temperature": 0,
      "avg_logprob": -0.26314235945879405,
      "compression_ratio": 1.5916666666666666,
      "no_speech_prob": 3.15610634515906e-7
    },
    {
      "id": 22,
      "seek": 13060,
      "start": 144.4,
      "end": 148.68,
      "text": " qualche birra insieme a Code Motion, ci prepariamo per farlo nei prossimi",
      "tokens": [
        38737,
        1904,
        424,
        1028,
        44940,
        257,
        15549,
        27771,
        11,
        6983,
        8231,
        7415,
        680,
        1400,
        752,
        34517,
        48794,
        10121
      ],
      "temperature": 0,
      "avg_logprob": -0.26314235945879405,
      "compression_ratio": 1.5916666666666666,
      "no_speech_prob": 3.15610634515906e-7
    },
    {
      "id": 23,
      "seek": 13060,
      "start": 148.68,
      "end": 153.44,
      "text": " eventi dove andremo a incontrarci ma prima di presentarlo in realtà, e questo",
      "tokens": [
        2280,
        72,
        23287,
        293,
        44172,
        257,
        834,
        896,
        5352,
        537,
        463,
        19507,
        1026,
        1974,
        19457,
        294,
        47512,
        11,
        308,
        10263
      ],
      "temperature": 0,
      "avg_logprob": -0.26314235945879405,
      "compression_ratio": 1.5916666666666666,
      "no_speech_prob": 3.15610634515906e-7
    },
    {
      "id": 24,
      "seek": 13060,
      "start": 153.44,
      "end": 158.68,
      "text": " mi fa fremere sulla sedia, dobbiamo ricordare i nostri contatti.",
      "tokens": [
        2752,
        2050,
        2130,
        76,
        323,
        33625,
        9643,
        654,
        11,
        360,
        6692,
        7415,
        21040,
        765,
        543,
        741,
        10397,
        470,
        660,
        21515,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.26314235945879405,
      "compression_ratio": 1.5916666666666666,
      "no_speech_prob": 3.15610634515906e-7
    },
    {
      "id": 25,
      "seek": 15868,
      "start": 158.68,
      "end": 166.44,
      "text": " Siamo la gitbar.it o etbrenrepo, sono i modi canonici per contattarci.",
      "tokens": [
        318,
        7415,
        635,
        18331,
        5356,
        13,
        270,
        277,
        1030,
        65,
        1095,
        265,
        2259,
        11,
        9259,
        741,
        1072,
        72,
        21985,
        8787,
        680,
        660,
        1591,
        289,
        537,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.44668833414713544,
      "compression_ratio": 1.4532019704433496,
      "no_speech_prob": 3.205820178209251e-7
    },
    {
      "id": 26,
      "seek": 15868,
      "start": 166.44,
      "end": 173,
      "text": " E poi ovviamente c'è il gruppo Telegram, basta cercare Gitbar Podcast",
      "tokens": [
        462,
        19260,
        14187,
        23347,
        269,
        6,
        1462,
        1930,
        47477,
        78,
        14889,
        1342,
        11,
        45282,
        10146,
        5685,
        16939,
        5356,
        29972
      ],
      "temperature": 0,
      "avg_logprob": -0.44668833414713544,
      "compression_ratio": 1.4532019704433496,
      "no_speech_prob": 3.205820178209251e-7
    },
    {
      "id": 27,
      "seek": 15868,
      "start": 173,
      "end": 180.76000000000002,
      "text": " e vedrete fuori un gruppo che ha conto attualmente 1181 membri, sottolineo",
      "tokens": [
        308,
        14267,
        7600,
        8536,
        7386,
        517,
        47477,
        78,
        947,
        324,
        660,
        78,
        951,
        901,
        4082,
        2975,
        32875,
        27942,
        470,
        11,
        262,
        1521,
        18773,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.44668833414713544,
      "compression_ratio": 1.4532019704433496,
      "no_speech_prob": 3.205820178209251e-7
    },
    {
      "id": 28,
      "seek": 15868,
      "start": 180.76000000000002,
      "end": 186.44,
      "text": " membri e quindi niente, venite vi aspettiamo per la prima birra è gratis e la",
      "tokens": [
        27942,
        470,
        308,
        15727,
        297,
        8413,
        11,
        6138,
        642,
        1932,
        16817,
        3093,
        7415,
        680,
        635,
        19507,
        1904,
        424,
        4873,
        10158,
        271,
        308,
        635
      ],
      "temperature": 0,
      "avg_logprob": -0.44668833414713544,
      "compression_ratio": 1.4532019704433496,
      "no_speech_prob": 3.205820178209251e-7
    },
    {
      "id": 29,
      "seek": 18644,
      "start": 186.44,
      "end": 192.72,
      "text": " seconda... membri e membre.",
      "tokens": [
        1150,
        64,
        485,
        27942,
        470,
        308,
        1334,
        2672,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.4343969061019573,
      "compression_ratio": 1.4322916666666667,
      "no_speech_prob": 3.828814953976689e-8
    },
    {
      "id": 30,
      "seek": 18644,
      "start": 192.72,
      "end": 197.92,
      "text": " Come si dice membrae? Membr.",
      "tokens": [
        2492,
        1511,
        10313,
        1334,
        6198,
        68,
        30,
        8731,
        1443,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.4343969061019573,
      "compression_ratio": 1.4322916666666667,
      "no_speech_prob": 3.828814953976689e-8
    },
    {
      "id": 31,
      "seek": 18644,
      "start": 197.92,
      "end": 204.28,
      "text": " Membre, ok. Io ragazzi non potete immaginare quanto faccio degli",
      "tokens": [
        8731,
        2672,
        11,
        3133,
        13,
        19239,
        17539,
        33910,
        2107,
        1847,
        3498,
        3397,
        559,
        259,
        543,
        17820,
        1915,
        8529,
        32079
      ],
      "temperature": 0,
      "avg_logprob": -0.4343969061019573,
      "compression_ratio": 1.4322916666666667,
      "no_speech_prob": 3.828814953976689e-8
    },
    {
      "id": 32,
      "seek": 18644,
      "start": 204.28,
      "end": 209.68,
      "text": " strafalcioni giganti, specie coi clienti americani che sono super presi",
      "tokens": [
        2148,
        36474,
        10015,
        72,
        8741,
        11520,
        11,
        1608,
        414,
        598,
        72,
        6423,
        72,
        16116,
        299,
        3782,
        947,
        9259,
        1687,
        1183,
        72
      ],
      "temperature": 0,
      "avg_logprob": -0.4343969061019573,
      "compression_ratio": 1.4322916666666667,
      "no_speech_prob": 3.828814953976689e-8
    },
    {
      "id": 33,
      "seek": 18644,
      "start": 209.68,
      "end": 215.12,
      "text": " da questa cosa dell'inclusività, forse anche in modo così plateale, e io faccio",
      "tokens": [
        1120,
        16540,
        10163,
        19781,
        6,
        4647,
        3063,
        592,
        12445,
        11,
        337,
        405,
        11585,
        294,
        16664,
        23278,
        5924,
        1220,
        11,
        308,
        19785,
        1915,
        8529
      ],
      "temperature": 0,
      "avg_logprob": -0.4343969061019573,
      "compression_ratio": 1.4322916666666667,
      "no_speech_prob": 3.828814953976689e-8
    },
    {
      "id": 34,
      "seek": 21512,
      "start": 215.12,
      "end": 221.32,
      "text": " una gas dopo l'altra. Ma parentesi a parte presentiamo l'ospite che abbiamo",
      "tokens": [
        2002,
        4211,
        35196,
        287,
        6,
        38865,
        13,
        4042,
        2596,
        21181,
        257,
        6975,
        1974,
        7415,
        287,
        6,
        2763,
        642,
        947,
        22815
      ],
      "temperature": 0,
      "avg_logprob": -0.3366129057747977,
      "compression_ratio": 1.603305785123967,
      "no_speech_prob": 1.0145351225787635e-8
    },
    {
      "id": 35,
      "seek": 21512,
      "start": 221.32,
      "end": 228.76,
      "text": " di nuovo qua un amico di Gitbar, abbiamo... proviamo a fare il serio.",
      "tokens": [
        1026,
        49348,
        24159,
        517,
        669,
        2789,
        1026,
        16939,
        5356,
        11,
        22815,
        485,
        1439,
        7415,
        257,
        11994,
        1930,
        49531,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.3366129057747977,
      "compression_ratio": 1.603305785123967,
      "no_speech_prob": 1.0145351225787635e-8
    },
    {
      "id": 36,
      "seek": 21512,
      "start": 229,
      "end": 234.72,
      "text": " Benvenuti su Gitbar, il podcast dedicato al mondo dei full stack developer, i mezzo",
      "tokens": [
        3964,
        553,
        29161,
        459,
        16939,
        5356,
        11,
        1930,
        7367,
        37071,
        2513,
        419,
        40499,
        13874,
        1577,
        8630,
        10754,
        11,
        741,
        28966,
        4765
      ],
      "temperature": 0,
      "avg_logprob": -0.3366129057747977,
      "compression_ratio": 1.603305785123967,
      "no_speech_prob": 1.0145351225787635e-8
    },
    {
      "id": 37,
      "seek": 21512,
      "start": 234.72,
      "end": 239.44,
      "text": " artigiani, i mezzo artisti che ogni giorno infilano le mani nel fango per creare",
      "tokens": [
        1523,
        328,
        21309,
        11,
        741,
        28966,
        4765,
        5748,
        72,
        947,
        33189,
        42202,
        1536,
        388,
        3730,
        476,
        587,
        72,
        15373,
        283,
        17150,
        680,
        1197,
        543
      ],
      "temperature": 0,
      "avg_logprob": -0.3366129057747977,
      "compression_ratio": 1.603305785123967,
      "no_speech_prob": 1.0145351225787635e-8
    },
    {
      "id": 38,
      "seek": 21512,
      "start": 239.44,
      "end": 243.48000000000002,
      "text": " nel modo più efficiente possibile quei prodotti digitali che quotidianamente",
      "tokens": [
        15373,
        16664,
        10589,
        7148,
        68,
        50184,
        631,
        72,
        15792,
        37514,
        4562,
        72,
        947,
        9641,
        34681,
        3439
      ],
      "temperature": 0,
      "avg_logprob": -0.3366129057747977,
      "compression_ratio": 1.603305785123967,
      "no_speech_prob": 1.0145351225787635e-8
    },
    {
      "id": 39,
      "seek": 24348,
      "start": 243.48,
      "end": 245.48,
      "text": " usiamo.",
      "tokens": [
        505,
        7415,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2705281972885132,
      "compression_ratio": 1.2682926829268293,
      "no_speech_prob": 4.338610892773431e-8
    },
    {
      "id": 40,
      "seek": 24348,
      "start": 252.67999999999998,
      "end": 262.24,
      "text": " Abbiamo un conferenziere internazionale, l'autore di uno dei libri se non il",
      "tokens": [
        32673,
        7415,
        517,
        13765,
        268,
        3992,
        323,
        728,
        629,
        89,
        313,
        1220,
        11,
        287,
        6,
        1375,
        418,
        1026,
        8526,
        13874,
        22854,
        470,
        369,
        2107,
        1930
      ],
      "temperature": 0,
      "avg_logprob": -0.2705281972885132,
      "compression_ratio": 1.2682926829268293,
      "no_speech_prob": 4.338610892773431e-8
    },
    {
      "id": 41,
      "seek": 24348,
      "start": 262.24,
      "end": 269.03999999999996,
      "text": " libro di riferimento per Node.js, abbiamo un amico di Gitbar nonché un",
      "tokens": [
        29354,
        1026,
        367,
        9361,
        10030,
        680,
        38640,
        13,
        25530,
        11,
        22815,
        517,
        669,
        2789,
        1026,
        16939,
        5356,
        2107,
        11131,
        517
      ],
      "temperature": 0,
      "avg_logprob": -0.2705281972885132,
      "compression_ratio": 1.2682926829268293,
      "no_speech_prob": 4.338610892773431e-8
    },
    {
      "id": 42,
      "seek": 26904,
      "start": 269.04,
      "end": 278.04,
      "text": " serverless hero con noi, Luciano Mammino. Ciao Luciano!",
      "tokens": [
        7154,
        1832,
        5316,
        416,
        22447,
        11,
        37309,
        3730,
        19899,
        2367,
        78,
        13,
        28473,
        37309,
        3730,
        0
      ],
      "temperature": 0,
      "avg_logprob": -0.4337221519234254,
      "compression_ratio": 1.4792626728110598,
      "no_speech_prob": 4.2470202288313885e-7
    },
    {
      "id": 43,
      "seek": 26904,
      "start": 278.04,
      "end": 283.52000000000004,
      "text": " Grazie per la fantastica intro, adesso mi sento proprio l'impostor syndrome a mille.",
      "tokens": [
        8985,
        3283,
        680,
        635,
        30665,
        2262,
        12897,
        11,
        39552,
        2752,
        2279,
        78,
        28203,
        287,
        6,
        8814,
        555,
        284,
        19371,
        257,
        1728,
        68,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.4337221519234254,
      "compression_ratio": 1.4792626728110598,
      "no_speech_prob": 4.2470202288313885e-7
    },
    {
      "id": 44,
      "seek": 26904,
      "start": 283.52000000000004,
      "end": 288.16,
      "text": " In realtà sarebbe Luciano che dovrebbe presentare il podcast Gitbar, è un piccolo",
      "tokens": [
        682,
        47512,
        38706,
        39042,
        37309,
        3730,
        947,
        30870,
        39487,
        1974,
        543,
        1930,
        7367,
        16939,
        5356,
        11,
        4873,
        517,
        13363,
        46086
      ],
      "temperature": 0,
      "avg_logprob": -0.4337221519234254,
      "compression_ratio": 1.4792626728110598,
      "no_speech_prob": 4.2470202288313885e-7
    },
    {
      "id": 45,
      "seek": 26904,
      "start": 288.16,
      "end": 291.44,
      "text": " podcast italiano dove parla di programmazione.",
      "tokens": [
        7367,
        48486,
        23287,
        971,
        875,
        1026,
        37648,
        12928,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.4337221519234254,
      "compression_ratio": 1.4792626728110598,
      "no_speech_prob": 4.2470202288313885e-7
    },
    {
      "id": 46,
      "seek": 26904,
      "start": 291.44,
      "end": 293.44,
      "text": " Che questo è vero.",
      "tokens": [
        3351,
        10263,
        4873,
        1306,
        78,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.4337221519234254,
      "compression_ratio": 1.4792626728110598,
      "no_speech_prob": 4.2470202288313885e-7
    },
    {
      "id": 47,
      "seek": 26904,
      "start": 293.44,
      "end": 295.44,
      "text": " Esatto, ciao Luciano come va?",
      "tokens": [
        2313,
        37491,
        11,
        42860,
        37309,
        3730,
        808,
        2773,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.4337221519234254,
      "compression_ratio": 1.4792626728110598,
      "no_speech_prob": 4.2470202288313885e-7
    },
    {
      "id": 48,
      "seek": 29544,
      "start": 295.44,
      "end": 301.36,
      "text": " Tutto bene, tutto bene, è stata una lunga giornata quindi potrei dire cose strane",
      "tokens": [
        18392,
        1353,
        2537,
        11,
        23048,
        2537,
        11,
        4873,
        49554,
        2002,
        16730,
        64,
        36937,
        3274,
        15727,
        1847,
        10271,
        1264,
        30261,
        1056,
        1929
      ],
      "temperature": 0,
      "avg_logprob": -0.2834344296842008,
      "compression_ratio": 1.5611814345991561,
      "no_speech_prob": 2.5360102995364286e-7
    },
    {
      "id": 49,
      "seek": 29544,
      "start": 301.36,
      "end": 303.84,
      "text": " però magari quella è la parte divertente.",
      "tokens": [
        12673,
        49932,
        32234,
        4873,
        635,
        6975,
        23781,
        1576,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2834344296842008,
      "compression_ratio": 1.5611814345991561,
      "no_speech_prob": 2.5360102995364286e-7
    },
    {
      "id": 50,
      "seek": 29544,
      "start": 303.84,
      "end": 312.48,
      "text": " Ma sei nel posto giusto, so che hai preso di corsa un treno, hai fatto di tutto per",
      "tokens": [
        4042,
        10842,
        15373,
        2183,
        78,
        1735,
        48260,
        11,
        370,
        947,
        21822,
        1183,
        78,
        1026,
        269,
        38822,
        517,
        23136,
        78,
        11,
        21822,
        23228,
        1026,
        23048,
        680
      ],
      "temperature": 0,
      "avg_logprob": -0.2834344296842008,
      "compression_ratio": 1.5611814345991561,
      "no_speech_prob": 2.5360102995364286e-7
    },
    {
      "id": 51,
      "seek": 29544,
      "start": 312.48,
      "end": 318.32,
      "text": " essere qua e per questo ti ringraziamo. La prima domanda che voglio farti",
      "tokens": [
        19799,
        24159,
        308,
        680,
        10263,
        8757,
        4875,
        30695,
        7415,
        13,
        2369,
        19507,
        3285,
        5575,
        947,
        31273,
        19987,
        24575,
        72
      ],
      "temperature": 0,
      "avg_logprob": -0.2834344296842008,
      "compression_ratio": 1.5611814345991561,
      "no_speech_prob": 2.5360102995364286e-7
    },
    {
      "id": 52,
      "seek": 29544,
      "start": 318.32,
      "end": 323.8,
      "text": " Luciano è, noi ci siamo sentiti un anno e mezzo fa più o meno qua su Gitbar, poi ci",
      "tokens": [
        37309,
        3730,
        4873,
        11,
        22447,
        6983,
        33459,
        2279,
        8707,
        517,
        46277,
        308,
        385,
        35130,
        2050,
        10589,
        277,
        40236,
        24159,
        459,
        16939,
        5356,
        11,
        19260,
        6983
      ],
      "temperature": 0,
      "avg_logprob": -0.2834344296842008,
      "compression_ratio": 1.5611814345991561,
      "no_speech_prob": 2.5360102995364286e-7
    },
    {
      "id": 53,
      "seek": 32380,
      "start": 323.8,
      "end": 331.76,
      "text": " siamo visti un po' dopo, siamo visti a Code Emotion, abbiamo mangiato insieme, ma cosa",
      "tokens": [
        33459,
        40247,
        72,
        517,
        714,
        6,
        35196,
        11,
        33459,
        40247,
        72,
        257,
        15549,
        3968,
        19228,
        11,
        22815,
        587,
        7834,
        2513,
        1028,
        44940,
        11,
        463,
        10163
      ],
      "temperature": 0,
      "avg_logprob": -0.3661155326693666,
      "compression_ratio": 1.5,
      "no_speech_prob": 7.690346137678716e-7
    },
    {
      "id": 54,
      "seek": 32380,
      "start": 331.76,
      "end": 334.48,
      "text": " bolle in pentola in quest'ultimo periodo?",
      "tokens": [
        748,
        2447,
        294,
        16834,
        4711,
        294,
        866,
        6,
        723,
        6934,
        2896,
        78,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.3661155326693666,
      "compression_ratio": 1.5,
      "no_speech_prob": 7.690346137678716e-7
    },
    {
      "id": 55,
      "seek": 32380,
      "start": 334.48,
      "end": 337.56,
      "text": " La stai combinando?",
      "tokens": [
        2369,
        342,
        1301,
        38514,
        1806,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.3661155326693666,
      "compression_ratio": 1.5,
      "no_speech_prob": 7.690346137678716e-7
    },
    {
      "id": 56,
      "seek": 32380,
      "start": 337.56,
      "end": 341.2,
      "text": " Nella mia vita personale lavorativa o in generale?",
      "tokens": [
        426,
        9885,
        21290,
        32712,
        954,
        1220,
        29241,
        18740,
        277,
        294,
        1337,
        1220,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.3661155326693666,
      "compression_ratio": 1.5,
      "no_speech_prob": 7.690346137678716e-7
    },
    {
      "id": 57,
      "seek": 32380,
      "start": 341.2,
      "end": 345,
      "text": " A livello code related, IT related.",
      "tokens": [
        316,
        1621,
        1913,
        3089,
        4077,
        11,
        6783,
        4077,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.3661155326693666,
      "compression_ratio": 1.5,
      "no_speech_prob": 7.690346137678716e-7
    },
    {
      "id": 58,
      "seek": 32380,
      "start": 345,
      "end": 350.04,
      "text": " Ma diciamo che non è cambiato tantissimo dall'ultima volta che ci siamo sentiti, nel",
      "tokens": [
        4042,
        14285,
        7415,
        947,
        2107,
        4873,
        19569,
        2513,
        12095,
        34966,
        43351,
        6,
        723,
        4775,
        18765,
        947,
        6983,
        33459,
        2279,
        8707,
        11,
        15373
      ],
      "temperature": 0,
      "avg_logprob": -0.3661155326693666,
      "compression_ratio": 1.5,
      "no_speech_prob": 7.690346137678716e-7
    },
    {
      "id": 59,
      "seek": 35004,
      "start": 350.04,
      "end": 354,
      "text": " senso che lavoro ancora per Fortiorem che è un'azienda di consulenza specializzata",
      "tokens": [
        3151,
        539,
        947,
        42060,
        30656,
        680,
        11002,
        72,
        418,
        76,
        947,
        4873,
        517,
        6,
        921,
        30498,
        1026,
        1014,
        425,
        23691,
        2121,
        8072,
        3274
      ],
      "temperature": 0,
      "avg_logprob": -0.26361921429634094,
      "compression_ratio": 1.6,
      "no_speech_prob": 6.083561743253085e-7
    },
    {
      "id": 60,
      "seek": 35004,
      "start": 354,
      "end": 361.88,
      "text": " su AWS e continuo con questo ruolo che è una sorta di ibrido tra full stack web development",
      "tokens": [
        459,
        17650,
        308,
        2993,
        78,
        416,
        10263,
        5420,
        7902,
        947,
        4873,
        2002,
        33425,
        1026,
        741,
        1443,
        2925,
        944,
        1577,
        8630,
        3670,
        3250
      ],
      "temperature": 0,
      "avg_logprob": -0.26361921429634094,
      "compression_ratio": 1.6,
      "no_speech_prob": 6.083561743253085e-7
    },
    {
      "id": 61,
      "seek": 35004,
      "start": 361.88,
      "end": 367.68,
      "text": " e cloud architect e quindi diciamo che continuo un po' a imparare tutto quello che c'è",
      "tokens": [
        308,
        4588,
        6331,
        308,
        15727,
        14285,
        7415,
        947,
        2993,
        78,
        517,
        714,
        6,
        257,
        704,
        289,
        543,
        23048,
        22813,
        947,
        269,
        6,
        1462
      ],
      "temperature": 0,
      "avg_logprob": -0.26361921429634094,
      "compression_ratio": 1.6,
      "no_speech_prob": 6.083561743253085e-7
    },
    {
      "id": 62,
      "seek": 35004,
      "start": 367.68,
      "end": 371.28000000000003,
      "text": " da sapere sul cloud, AWS, migrazioni eccetera.",
      "tokens": [
        1120,
        18985,
        323,
        17603,
        4588,
        11,
        17650,
        11,
        6186,
        30695,
        15273,
        29613,
        20269,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.26361921429634094,
      "compression_ratio": 1.6,
      "no_speech_prob": 6.083561743253085e-7
    },
    {
      "id": 63,
      "seek": 35004,
      "start": 371.28000000000003,
      "end": 377.8,
      "text": " Non so se è un buon riassunto ma insomma questo è a grandi linee quello che ho fatto",
      "tokens": [
        8774,
        370,
        369,
        4873,
        517,
        758,
        266,
        19739,
        640,
        24052,
        463,
        1028,
        30243,
        10263,
        4873,
        257,
        45155,
        1622,
        68,
        22813,
        947,
        1106,
        23228
      ],
      "temperature": 0,
      "avg_logprob": -0.26361921429634094,
      "compression_ratio": 1.6,
      "no_speech_prob": 6.083561743253085e-7
    },
    {
      "id": 64,
      "seek": 35004,
      "start": 377.8,
      "end": 378.8,
      "text": " nell'ultimo anno e mezzo.",
      "tokens": [
        44666,
        6,
        723,
        6934,
        46277,
        308,
        385,
        35130,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.26361921429634094,
      "compression_ratio": 1.6,
      "no_speech_prob": 6.083561743253085e-7
    },
    {
      "id": 65,
      "seek": 37880,
      "start": 378.8,
      "end": 382.08,
      "text": " Mi ti faccio una domanda perché questa è una curiosità.",
      "tokens": [
        10204,
        8757,
        1915,
        8529,
        2002,
        3285,
        5575,
        14303,
        16540,
        4873,
        2002,
        13625,
        12445,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2517971112890151,
      "compression_ratio": 1.55,
      "no_speech_prob": 3.274957904864095e-8
    },
    {
      "id": 66,
      "seek": 37880,
      "start": 382.08,
      "end": 390.96000000000004,
      "text": " Trovi delle difficoltà a sposare la parte da sviluppatore con la parte di cloud architect?",
      "tokens": [
        19406,
        4917,
        16485,
        2204,
        4837,
        1467,
        257,
        20443,
        543,
        635,
        6975,
        1120,
        17342,
        388,
        10504,
        43148,
        416,
        635,
        6975,
        1026,
        4588,
        6331,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.2517971112890151,
      "compression_ratio": 1.55,
      "no_speech_prob": 3.274957904864095e-8
    },
    {
      "id": 67,
      "seek": 37880,
      "start": 390.96000000000004,
      "end": 396.12,
      "text": " Cioè talvolta è come indossare due cappelli, due berretti no?",
      "tokens": [
        383,
        35983,
        4023,
        9646,
        1328,
        4873,
        808,
        1016,
        772,
        543,
        3462,
        1335,
        427,
        41129,
        11,
        3462,
        5948,
        1505,
        7317,
        572,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.2517971112890151,
      "compression_ratio": 1.55,
      "no_speech_prob": 3.274957904864095e-8
    },
    {
      "id": 68,
      "seek": 37880,
      "start": 396.12,
      "end": 406.08000000000004,
      "text": " Come fai a fare, se serve farlo, context switching e a gestire queste due personalità che talvolta",
      "tokens": [
        2492,
        283,
        1301,
        257,
        11994,
        11,
        369,
        4596,
        1400,
        752,
        11,
        4319,
        16493,
        308,
        257,
        7219,
        621,
        35455,
        3462,
        2973,
        12445,
        947,
        4023,
        9646,
        1328
      ],
      "temperature": 0,
      "avg_logprob": -0.2517971112890151,
      "compression_ratio": 1.55,
      "no_speech_prob": 3.274957904864095e-8
    },
    {
      "id": 69,
      "seek": 37880,
      "start": 406.08000000000004,
      "end": 408.36,
      "text": " sono anche in antitesi no?",
      "tokens": [
        9259,
        11585,
        294,
        2511,
        3324,
        72,
        572,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.2517971112890151,
      "compression_ratio": 1.55,
      "no_speech_prob": 3.274957904864095e-8
    },
    {
      "id": 70,
      "seek": 40836,
      "start": 408.36,
      "end": 414.04,
      "text": " Bella domanda, non so se mi sono mai posto il problema da questo punto di vista.",
      "tokens": [
        29133,
        3285,
        5575,
        11,
        2107,
        370,
        369,
        2752,
        9259,
        12698,
        2183,
        78,
        1930,
        12395,
        1120,
        10263,
        14326,
        1026,
        22553,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2776589435079823,
      "compression_ratio": 1.5405405405405406,
      "no_speech_prob": 4.7650310364133475e-8
    },
    {
      "id": 71,
      "seek": 40836,
      "start": 414.04,
      "end": 417.04,
      "text": " Forse ho una personalità che è molto...",
      "tokens": [
        1171,
        405,
        1106,
        2002,
        2973,
        12445,
        947,
        4873,
        16394,
        485
      ],
      "temperature": 0,
      "avg_logprob": -0.2776589435079823,
      "compression_ratio": 1.5405405405405406,
      "no_speech_prob": 4.7650310364133475e-8
    },
    {
      "id": 72,
      "seek": 40836,
      "start": 417.04,
      "end": 424.16,
      "text": " A me piace molto spaziare, andare a vedere il problema a 360 gradi piuttosto che a concentrarmi",
      "tokens": [
        316,
        385,
        50062,
        16394,
        637,
        26637,
        543,
        11,
        42742,
        257,
        35373,
        1930,
        12395,
        257,
        13898,
        2771,
        72,
        3895,
        13478,
        22756,
        947,
        257,
        5512,
        5352,
        3057
      ],
      "temperature": 0,
      "avg_logprob": -0.2776589435079823,
      "compression_ratio": 1.5405405405405406,
      "no_speech_prob": 4.7650310364133475e-8
    },
    {
      "id": 73,
      "seek": 40836,
      "start": 424.16,
      "end": 426.36,
      "text": " in particolar modo su un aspetto specifico.",
      "tokens": [
        294,
        1276,
        15276,
        16664,
        459,
        517,
        382,
        42801,
        2685,
        78,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2776589435079823,
      "compression_ratio": 1.5405405405405406,
      "no_speech_prob": 4.7650310364133475e-8
    },
    {
      "id": 74,
      "seek": 40836,
      "start": 426.36,
      "end": 431.52000000000004,
      "text": " Poi come esperienza personale ho più di 10 anni di sviluppo full stack quindi quella",
      "tokens": [
        430,
        4869,
        808,
        10045,
        42331,
        954,
        1220,
        1106,
        10589,
        1026,
        1266,
        31164,
        1026,
        17342,
        388,
        10504,
        78,
        1577,
        8630,
        15727,
        32234
      ],
      "temperature": 0,
      "avg_logprob": -0.2776589435079823,
      "compression_ratio": 1.5405405405405406,
      "no_speech_prob": 4.7650310364133475e-8
    },
    {
      "id": 75,
      "seek": 40836,
      "start": 431.52000000000004,
      "end": 434.44,
      "text": " è una cosa su cui mi sento abbastanza tranquillo.",
      "tokens": [
        4873,
        2002,
        10163,
        459,
        22929,
        2752,
        2279,
        78,
        16903,
        525,
        20030,
        17640,
        15831,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2776589435079823,
      "compression_ratio": 1.5405405405405406,
      "no_speech_prob": 4.7650310364133475e-8
    },
    {
      "id": 76,
      "seek": 43444,
      "start": 434.44,
      "end": 440.28,
      "text": " Tutta la parte cloud è un po' più in divenire, poi ci sono sempre tantissime innovazioni",
      "tokens": [
        18392,
        1328,
        635,
        6975,
        4588,
        4873,
        517,
        714,
        6,
        10589,
        294,
        1026,
        553,
        621,
        11,
        19260,
        6983,
        9259,
        9553,
        12095,
        891,
        1312,
        5083,
        27569
      ],
      "temperature": 0,
      "avg_logprob": -0.22020453091325431,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 1.0407796224853882e-7
    },
    {
      "id": 77,
      "seek": 43444,
      "start": 440.28,
      "end": 445.68,
      "text": " e in più c'è il fatto che il metodo con cui Fortiorem lavora forse è un po' particolare.",
      "tokens": [
        308,
        294,
        10589,
        269,
        6,
        1462,
        1930,
        23228,
        947,
        1930,
        1131,
        17423,
        416,
        22929,
        11002,
        72,
        418,
        76,
        20923,
        3252,
        337,
        405,
        4873,
        517,
        714,
        6,
        1276,
        43141,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.22020453091325431,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 1.0407796224853882e-7
    },
    {
      "id": 78,
      "seek": 43444,
      "start": 445.68,
      "end": 450.16,
      "text": " Nel senso che noi cerchiamo di, benché si parte sempre da un'analisi che è più da",
      "tokens": [
        426,
        338,
        3151,
        539,
        947,
        22447,
        10146,
        339,
        7415,
        1026,
        11,
        10638,
        526,
        1511,
        6975,
        9553,
        1120,
        517,
        6,
        29702,
        8021,
        947,
        4873,
        10589,
        1120
      ],
      "temperature": 0,
      "avg_logprob": -0.22020453091325431,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 1.0407796224853882e-7
    },
    {
      "id": 79,
      "seek": 43444,
      "start": 450.16,
      "end": 454.6,
      "text": " cloud architect, quindi di capire quali sono le esigenze, capire se l'architettura è quella",
      "tokens": [
        4588,
        6331,
        11,
        15727,
        1026,
        1410,
        621,
        4101,
        72,
        9259,
        476,
        785,
        3213,
        1381,
        11,
        1410,
        621,
        369,
        287,
        6,
        1178,
        270,
        3093,
        2991,
        4873,
        32234
      ],
      "temperature": 0,
      "avg_logprob": -0.22020453091325431,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 1.0407796224853882e-7
    },
    {
      "id": 80,
      "seek": 43444,
      "start": 454.6,
      "end": 455.6,
      "text": " corretta.",
      "tokens": [
        1181,
        1505,
        1328,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.22020453091325431,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 1.0407796224853882e-7
    },
    {
      "id": 81,
      "seek": 43444,
      "start": 455.6,
      "end": 460.72,
      "text": " Fatto quello poi passiamo molto a una fase operativa in cui diventiamo una sorta di estensione",
      "tokens": [
        16948,
        1353,
        22813,
        19260,
        1320,
        7415,
        16394,
        257,
        2002,
        33931,
        2208,
        18740,
        294,
        22929,
        3414,
        317,
        7415,
        2002,
        33425,
        1026,
        871,
        3378,
        68
      ],
      "temperature": 0,
      "avg_logprob": -0.22020453091325431,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 1.0407796224853882e-7
    },
    {
      "id": 82,
      "seek": 46072,
      "start": 460.72,
      "end": 465.6,
      "text": " del team del nostro cliente e quindi andiamo proprio a fare pairing col team dell'azienda",
      "tokens": [
        1103,
        1469,
        1103,
        35779,
        6423,
        68,
        308,
        15727,
        293,
        7415,
        28203,
        257,
        11994,
        32735,
        1173,
        1469,
        19781,
        6,
        921,
        30498
      ],
      "temperature": 0,
      "avg_logprob": -0.2729801692015736,
      "compression_ratio": 1.7773851590106007,
      "no_speech_prob": 1.4005216542045673e-7
    },
    {
      "id": 83,
      "seek": 46072,
      "start": 465.6,
      "end": 469.64000000000004,
      "text": " con cui lavoriamo e in quel senso facciamo un po' di tutto.",
      "tokens": [
        416,
        22929,
        29241,
        7415,
        308,
        294,
        7178,
        3151,
        539,
        1915,
        42052,
        517,
        714,
        6,
        1026,
        23048,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2729801692015736,
      "compression_ratio": 1.7773851590106007,
      "no_speech_prob": 1.4005216542045673e-7
    },
    {
      "id": 84,
      "seek": 46072,
      "start": 469.64000000000004,
      "end": 475.08000000000004,
      "text": " Facciamo dalla parte di agile, scrum, eccetera, alla parte proprio di sviluppo pure per programming",
      "tokens": [
        17667,
        42052,
        35566,
        6975,
        1026,
        30072,
        11,
        5918,
        449,
        11,
        29613,
        20269,
        11,
        11591,
        6975,
        28203,
        1026,
        17342,
        388,
        10504,
        78,
        6075,
        680,
        9410
      ],
      "temperature": 0,
      "avg_logprob": -0.2729801692015736,
      "compression_ratio": 1.7773851590106007,
      "no_speech_prob": 1.4005216542045673e-7
    },
    {
      "id": 85,
      "seek": 46072,
      "start": 475.08000000000004,
      "end": 476.96000000000004,
      "text": " con gli sviluppatori dell'azienda.",
      "tokens": [
        416,
        17161,
        17342,
        388,
        10504,
        39842,
        19781,
        6,
        921,
        30498,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2729801692015736,
      "compression_ratio": 1.7773851590106007,
      "no_speech_prob": 1.4005216542045673e-7
    },
    {
      "id": 86,
      "seek": 46072,
      "start": 476.96000000000004,
      "end": 482.68,
      "text": " Quindi è una sorta di secondo me inserimento molto naturale dal questo è l'obiettivo,",
      "tokens": [
        32534,
        4873,
        2002,
        33425,
        1026,
        41601,
        385,
        1028,
        260,
        10030,
        16394,
        40877,
        11702,
        10263,
        4873,
        287,
        6,
        996,
        1684,
        83,
        6340,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.2729801692015736,
      "compression_ratio": 1.7773851590106007,
      "no_speech_prob": 1.4005216542045673e-7
    },
    {
      "id": 87,
      "seek": 46072,
      "start": 482.68,
      "end": 486.68,
      "text": " definiamo insieme la strategia, una volta consolidata quella strategia cerchiamo proprio",
      "tokens": [
        1561,
        7415,
        1028,
        44940,
        635,
        5464,
        654,
        11,
        2002,
        18765,
        19045,
        3274,
        32234,
        5464,
        654,
        10146,
        339,
        7415,
        28203
      ],
      "temperature": 0,
      "avg_logprob": -0.2729801692015736,
      "compression_ratio": 1.7773851590106007,
      "no_speech_prob": 1.4005216542045673e-7
    },
    {
      "id": 88,
      "seek": 46072,
      "start": 486.68,
      "end": 488.88000000000005,
      "text": " di metterla in pratica in modo operativo.",
      "tokens": [
        1026,
        1131,
        391,
        875,
        294,
        28844,
        2262,
        294,
        16664,
        2208,
        18586,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2729801692015736,
      "compression_ratio": 1.7773851590106007,
      "no_speech_prob": 1.4005216542045673e-7
    },
    {
      "id": 89,
      "seek": 48888,
      "start": 488.88,
      "end": 495.04,
      "text": " Quindi non vedo molto un conflitto tra queste due personalità come le definite tu, però",
      "tokens": [
        32534,
        2107,
        14267,
        78,
        16394,
        517,
        1497,
        75,
        34924,
        944,
        35455,
        3462,
        2973,
        12445,
        808,
        476,
        1561,
        642,
        2604,
        11,
        12673
      ],
      "temperature": 0,
      "avg_logprob": -0.251607252422132,
      "compression_ratio": 1.6798029556650247,
      "no_speech_prob": 9.184843463572179e-8
    },
    {
      "id": 90,
      "seek": 48888,
      "start": 495.04,
      "end": 498.48,
      "text": " forse dipende proprio molto dal modo in cui lavoriamo noi come azienda.",
      "tokens": [
        337,
        405,
        10460,
        5445,
        28203,
        16394,
        11702,
        16664,
        294,
        22929,
        29241,
        7415,
        22447,
        808,
        7883,
        30498,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.251607252422132,
      "compression_ratio": 1.6798029556650247,
      "no_speech_prob": 9.184843463572179e-8
    },
    {
      "id": 91,
      "seek": 48888,
      "start": 498.48,
      "end": 507.15999999999997,
      "text": " Proprio in funzione di questo immagino che il metodo con cui lavorate non è molto lontano",
      "tokens": [
        430,
        5072,
        78,
        294,
        1019,
        19706,
        1026,
        10263,
        3397,
        559,
        2982,
        947,
        1930,
        1131,
        17423,
        416,
        22929,
        29241,
        473,
        2107,
        4873,
        16394,
        287,
        896,
        3730
      ],
      "temperature": 0,
      "avg_logprob": -0.251607252422132,
      "compression_ratio": 1.6798029556650247,
      "no_speech_prob": 9.184843463572179e-8
    },
    {
      "id": 92,
      "seek": 48888,
      "start": 507.15999999999997,
      "end": 513,
      "text": " dal metodo con il quale lavoriamo noi e quello che ti chiedo è quando, essendo comunque",
      "tokens": [
        11702,
        1131,
        17423,
        416,
        1930,
        421,
        1220,
        29241,
        7415,
        22447,
        308,
        22813,
        947,
        8757,
        417,
        36035,
        4873,
        7770,
        11,
        2097,
        3999,
        45736
      ],
      "temperature": 0,
      "avg_logprob": -0.251607252422132,
      "compression_ratio": 1.6798029556650247,
      "no_speech_prob": 9.184843463572179e-8
    },
    {
      "id": 93,
      "seek": 51300,
      "start": 513,
      "end": 522.72,
      "text": " un'azienda di consulenza come hai detto, quando vieni integrato nel team del cliente",
      "tokens": [
        517,
        6,
        921,
        30498,
        1026,
        1014,
        425,
        23691,
        808,
        21822,
        41031,
        11,
        7770,
        371,
        35462,
        3572,
        2513,
        15373,
        1469,
        1103,
        6423,
        68
      ],
      "temperature": 0,
      "avg_logprob": -0.23350315329469282,
      "compression_ratio": 1.5082872928176796,
      "no_speech_prob": 5.152218207626902e-8
    },
    {
      "id": 94,
      "seek": 51300,
      "start": 522.72,
      "end": 530.96,
      "text": " e in qualche modo hai un ruolo anche da evangelist, da educatore, perché se sei un consulente",
      "tokens": [
        308,
        294,
        38737,
        16664,
        21822,
        517,
        5420,
        7902,
        11585,
        1120,
        24546,
        468,
        11,
        1120,
        2400,
        43148,
        11,
        14303,
        369,
        10842,
        517,
        1014,
        425,
        1576
      ],
      "temperature": 0,
      "avg_logprob": -0.23350315329469282,
      "compression_ratio": 1.5082872928176796,
      "no_speech_prob": 5.152218207626902e-8
    },
    {
      "id": 95,
      "seek": 51300,
      "start": 530.96,
      "end": 538.76,
      "text": " o se un prestatore d'opera alla consulenza più bè c'era, oppure devi portare un improvement",
      "tokens": [
        277,
        369,
        517,
        16305,
        43148,
        274,
        6,
        404,
        1663,
        11591,
        1014,
        425,
        23691,
        10589,
        272,
        1462,
        269,
        6,
        1663,
        11,
        1458,
        540,
        31219,
        2436,
        543,
        517,
        10444
      ],
      "temperature": 0,
      "avg_logprob": -0.23350315329469282,
      "compression_ratio": 1.5082872928176796,
      "no_speech_prob": 5.152218207626902e-8
    },
    {
      "id": 96,
      "seek": 53876,
      "start": 538.76,
      "end": 545.36,
      "text": " al team, devi portare metodologie, devi portare pragmatismo, devi portare una serie di competenze.",
      "tokens": [
        419,
        1469,
        11,
        31219,
        2436,
        543,
        1131,
        378,
        20121,
        11,
        31219,
        2436,
        543,
        33394,
        15677,
        6882,
        11,
        31219,
        2436,
        543,
        2002,
        23030,
        1026,
        2850,
        268,
        1381,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.22807268164623742,
      "compression_ratio": 1.6091954022988506,
      "no_speech_prob": 4.271348785778173e-8
    },
    {
      "id": 97,
      "seek": 53876,
      "start": 545.36,
      "end": 554.3199999999999,
      "text": " Quali sono, nella tua esperienza ormai lunga anche con Fortiorem, quali sono i modi che",
      "tokens": [
        13616,
        72,
        9259,
        11,
        23878,
        33578,
        10045,
        42331,
        420,
        76,
        1301,
        16730,
        64,
        11585,
        416,
        11002,
        72,
        37956,
        11,
        4101,
        72,
        9259,
        741,
        1072,
        72,
        947
      ],
      "temperature": 0,
      "avg_logprob": -0.22807268164623742,
      "compression_ratio": 1.6091954022988506,
      "no_speech_prob": 4.271348785778173e-8
    },
    {
      "id": 98,
      "seek": 53876,
      "start": 554.3199999999999,
      "end": 563.6,
      "text": " hai trovato funzionali per integrarti e trasferire la conoscenza pur rimanendo un consulente?",
      "tokens": [
        21822,
        35449,
        2513,
        49345,
        1966,
        72,
        680,
        3572,
        40155,
        308,
        22507,
        612,
        621,
        635,
        416,
        10466,
        23691,
        1864,
        15982,
        282,
        3999,
        517,
        1014,
        425,
        1576,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.22807268164623742,
      "compression_ratio": 1.6091954022988506,
      "no_speech_prob": 4.271348785778173e-8
    },
    {
      "id": 99,
      "seek": 56360,
      "start": 563.6,
      "end": 573.52,
      "text": " Ok, non so se ho mai fatto una riflessione approfondita su questa cosa, diciamo che nella",
      "tokens": [
        3477,
        11,
        2107,
        370,
        369,
        1106,
        12698,
        23228,
        2002,
        13203,
        1832,
        5328,
        2075,
        69,
        684,
        2786,
        459,
        16540,
        10163,
        11,
        14285,
        7415,
        947,
        23878
      ],
      "temperature": 0,
      "avg_logprob": -0.22695320264428062,
      "compression_ratio": 1.6425339366515836,
      "no_speech_prob": 3.8288114012630103e-8
    },
    {
      "id": 100,
      "seek": 56360,
      "start": 573.52,
      "end": 577.8000000000001,
      "text": " quotidianità di tutti i giorni ci sono varie cose che si fanno e forse non ci si dà troppo",
      "tokens": [
        9641,
        34681,
        12445,
        1026,
        19822,
        741,
        36937,
        72,
        6983,
        9259,
        1374,
        414,
        30261,
        947,
        1511,
        283,
        13484,
        308,
        337,
        405,
        2107,
        6983,
        1511,
        274,
        1467,
        4495,
        27000
      ],
      "temperature": 0,
      "avg_logprob": -0.22695320264428062,
      "compression_ratio": 1.6425339366515836,
      "no_speech_prob": 3.8288114012630103e-8
    },
    {
      "id": 101,
      "seek": 56360,
      "start": 577.8000000000001,
      "end": 578.8000000000001,
      "text": " peso.",
      "tokens": [
        28149,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.22695320264428062,
      "compression_ratio": 1.6425339366515836,
      "no_speech_prob": 3.8288114012630103e-8
    },
    {
      "id": 102,
      "seek": 56360,
      "start": 578.8000000000001,
      "end": 584.24,
      "text": " In generale credo che ci siano varie tecniche che valgono secondo me, a prescindere che",
      "tokens": [
        682,
        1337,
        1220,
        3864,
        78,
        947,
        6983,
        262,
        6254,
        1374,
        414,
        20105,
        9304,
        947,
        1323,
        70,
        8957,
        41601,
        385,
        11,
        257,
        1183,
        66,
        471,
        323,
        947
      ],
      "temperature": 0,
      "avg_logprob": -0.22695320264428062,
      "compression_ratio": 1.6425339366515836,
      "no_speech_prob": 3.8288114012630103e-8
    },
    {
      "id": 103,
      "seek": 56360,
      "start": 584.24,
      "end": 588.44,
      "text": " nel caso in cui tu sia un consulente esterno se proprio sei una persona che lavora per",
      "tokens": [
        15373,
        9666,
        294,
        22929,
        2604,
        25176,
        517,
        1014,
        425,
        1576,
        871,
        1248,
        78,
        369,
        28203,
        10842,
        2002,
        12184,
        947,
        20923,
        3252,
        680
      ],
      "temperature": 0,
      "avg_logprob": -0.22695320264428062,
      "compression_ratio": 1.6425339366515836,
      "no_speech_prob": 3.8288114012630103e-8
    },
    {
      "id": 104,
      "seek": 58844,
      "start": 588.44,
      "end": 593.7600000000001,
      "text": " quell'azienda, ovvero che se tu propone un cambiamento troppo drammatico dall'oggi al",
      "tokens": [
        631,
        285,
        6,
        921,
        30498,
        11,
        14187,
        39332,
        947,
        369,
        2604,
        2365,
        546,
        517,
        19569,
        8824,
        4495,
        27000,
        1224,
        5136,
        2399,
        78,
        43351,
        6,
        664,
        7834,
        419
      ],
      "temperature": 0,
      "avg_logprob": -0.25397979511934166,
      "compression_ratio": 1.6549019607843136,
      "no_speech_prob": 2.0176427639739813e-8
    },
    {
      "id": 105,
      "seek": 58844,
      "start": 593.7600000000001,
      "end": 603.08,
      "text": " domani è difficile riuscire a ottenere consensi nel senso più lato, ma anche quando c'hai",
      "tokens": [
        3285,
        3782,
        4873,
        26607,
        367,
        4872,
        537,
        265,
        257,
        4337,
        1147,
        323,
        1014,
        694,
        72,
        15373,
        3151,
        539,
        10589,
        287,
        2513,
        11,
        463,
        11585,
        7770,
        269,
        6,
        18230
      ],
      "temperature": 0,
      "avg_logprob": -0.25397979511934166,
      "compression_ratio": 1.6549019607843136,
      "no_speech_prob": 2.0176427639739813e-8
    },
    {
      "id": 106,
      "seek": 58844,
      "start": 603.08,
      "end": 608.2800000000001,
      "text": " una situazione assolutamente aperta di un team che vuole abbracciare l'innovazione,",
      "tokens": [
        2002,
        2054,
        12928,
        1256,
        2308,
        3439,
        43139,
        1328,
        1026,
        517,
        1469,
        947,
        9732,
        4812,
        410,
        1443,
        43870,
        543,
        287,
        6,
        259,
        4185,
        12928,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.25397979511934166,
      "compression_ratio": 1.6549019607843136,
      "no_speech_prob": 2.0176427639739813e-8
    },
    {
      "id": 107,
      "seek": 58844,
      "start": 608.2800000000001,
      "end": 613.6400000000001,
      "text": " è disposto a fare la qualsiasi cosa per innovare, se viene fatto il passo più lungo della gamma",
      "tokens": [
        4873,
        4920,
        22756,
        257,
        11994,
        635,
        421,
        1124,
        4609,
        72,
        10163,
        680,
        5083,
        543,
        11,
        369,
        19561,
        23228,
        1930,
        38159,
        10589,
        16730,
        78,
        11618,
        15546
      ],
      "temperature": 0,
      "avg_logprob": -0.25397979511934166,
      "compression_ratio": 1.6549019607843136,
      "no_speech_prob": 2.0176427639739813e-8
    },
    {
      "id": 108,
      "seek": 58844,
      "start": 613.6400000000001,
      "end": 616.7600000000001,
      "text": " è sempre un po' difficile riuscire ad arrivare all'obiettivo.",
      "tokens": [
        4873,
        9553,
        517,
        714,
        6,
        26607,
        367,
        4872,
        537,
        265,
        614,
        30697,
        543,
        439,
        6,
        996,
        1684,
        83,
        6340,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.25397979511934166,
      "compression_ratio": 1.6549019607843136,
      "no_speech_prob": 2.0176427639739813e-8
    },
    {
      "id": 109,
      "seek": 61676,
      "start": 616.76,
      "end": 622.84,
      "text": " Quindi preferisco un po' l'approccio incrementale in cui si parte un po' da quelle che sono",
      "tokens": [
        32534,
        4382,
        8610,
        517,
        714,
        6,
        287,
        6,
        1746,
        24174,
        8529,
        26200,
        1220,
        294,
        22929,
        1511,
        6975,
        517,
        714,
        6,
        1120,
        29237,
        947,
        9259
      ],
      "temperature": 0,
      "avg_logprob": -0.20372925828767302,
      "compression_ratio": 1.689419795221843,
      "no_speech_prob": 1.2167949137165124e-7
    },
    {
      "id": 110,
      "seek": 61676,
      "start": 622.84,
      "end": 627.8,
      "text": " le conoscenze attuali del team e si aggiungono degli elementi un po' alla volta e pian piano",
      "tokens": [
        476,
        416,
        10466,
        268,
        1381,
        951,
        901,
        72,
        1103,
        1469,
        308,
        1511,
        42254,
        1063,
        8957,
        32079,
        4478,
        72,
        517,
        714,
        6,
        11591,
        18765,
        308,
        32198,
        9211
      ],
      "temperature": 0,
      "avg_logprob": -0.20372925828767302,
      "compression_ratio": 1.689419795221843,
      "no_speech_prob": 1.2167949137165124e-7
    },
    {
      "id": 111,
      "seek": 61676,
      "start": 627.8,
      "end": 629.88,
      "text": " si arriva a fare innovazione.",
      "tokens": [
        1511,
        3399,
        2757,
        257,
        11994,
        5083,
        12928,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.20372925828767302,
      "compression_ratio": 1.689419795221843,
      "no_speech_prob": 1.2167949137165124e-7
    },
    {
      "id": 112,
      "seek": 61676,
      "start": 629.88,
      "end": 634,
      "text": " Giusto per farti un esempio pratico, mi è capitato il caso di un cliente che doveva",
      "tokens": [
        15334,
        48260,
        680,
        24575,
        72,
        517,
        33627,
        33852,
        78,
        11,
        2752,
        4873,
        33807,
        2513,
        1930,
        9666,
        1026,
        517,
        6423,
        68,
        947,
        23287,
        2757
      ],
      "temperature": 0,
      "avg_logprob": -0.20372925828767302,
      "compression_ratio": 1.689419795221843,
      "no_speech_prob": 1.2167949137165124e-7
    },
    {
      "id": 113,
      "seek": 61676,
      "start": 634,
      "end": 640.56,
      "text": " fare una migrazione un po' classica da on-premise a cloud, semplicemente non perché la volevano",
      "tokens": [
        11994,
        2002,
        6186,
        424,
        19706,
        517,
        714,
        6,
        1508,
        2262,
        1120,
        322,
        12,
        29403,
        908,
        257,
        4588,
        11,
        4361,
        4770,
        16288,
        2107,
        14303,
        635,
        1650,
        28316,
        3730
      ],
      "temperature": 0,
      "avg_logprob": -0.20372925828767302,
      "compression_ratio": 1.689419795221843,
      "no_speech_prob": 1.2167949137165124e-7
    },
    {
      "id": 114,
      "seek": 61676,
      "start": 640.56,
      "end": 645.88,
      "text": " fare così per sport, ma perché avevano problemi di scalabilità abbastanza seri, avevano bisogno",
      "tokens": [
        11994,
        23278,
        680,
        7282,
        11,
        463,
        14303,
        3472,
        85,
        3730,
        1154,
        72,
        1026,
        15664,
        5177,
        12445,
        16903,
        525,
        20030,
        816,
        72,
        11,
        3472,
        85,
        3730,
        40505,
        1771
      ],
      "temperature": 0,
      "avg_logprob": -0.20372925828767302,
      "compression_ratio": 1.689419795221843,
      "no_speech_prob": 1.2167949137165124e-7
    },
    {
      "id": 115,
      "seek": 64588,
      "start": 645.88,
      "end": 652.36,
      "text": " di quell'elasticità che potevano trovare solo sul cloud e nonostante il loro caso d'uso",
      "tokens": [
        1026,
        631,
        285,
        6,
        338,
        2750,
        12445,
        947,
        280,
        1370,
        85,
        3730,
        35449,
        543,
        6944,
        17603,
        4588,
        308,
        2107,
        555,
        2879,
        1930,
        28810,
        9666,
        274,
        6,
        24431
      ],
      "temperature": 0,
      "avg_logprob": -0.21246416428509882,
      "compression_ratio": 1.661764705882353,
      "no_speech_prob": 5.315782303227934e-8
    },
    {
      "id": 116,
      "seek": 64588,
      "start": 652.36,
      "end": 657.56,
      "text": " secondo me fosse stato un caso d'uso perfetto per utilizzare serverless, alla fine abbiamo",
      "tokens": [
        41601,
        385,
        24528,
        29657,
        517,
        9666,
        274,
        6,
        24431,
        13826,
        23778,
        680,
        40355,
        543,
        7154,
        1832,
        11,
        11591,
        2489,
        22815
      ],
      "temperature": 0,
      "avg_logprob": -0.21246416428509882,
      "compression_ratio": 1.661764705882353,
      "no_speech_prob": 5.315782303227934e-8
    },
    {
      "id": 117,
      "seek": 64588,
      "start": 657.56,
      "end": 662.24,
      "text": " preferito fare una migrazione becera proprio da virtual machine a virtual machine e mettere",
      "tokens": [
        4382,
        3528,
        11994,
        2002,
        6186,
        424,
        19706,
        312,
        41034,
        28203,
        1120,
        6374,
        3479,
        257,
        6374,
        3479,
        308,
        27812,
        323
      ],
      "temperature": 0,
      "avg_logprob": -0.21246416428509882,
      "compression_ratio": 1.661764705882353,
      "no_speech_prob": 5.315782303227934e-8
    },
    {
      "id": 118,
      "seek": 64588,
      "start": 662.24,
      "end": 668.96,
      "text": " solo dei load balancer di fronte al loro deployment con degli autoscaling group perché quello",
      "tokens": [
        6944,
        13874,
        3677,
        3119,
        28347,
        1026,
        1868,
        68,
        419,
        28810,
        19317,
        416,
        32079,
        1476,
        10466,
        4270,
        1594,
        14303,
        22813
      ],
      "temperature": 0,
      "avg_logprob": -0.21246416428509882,
      "compression_ratio": 1.661764705882353,
      "no_speech_prob": 5.315782303227934e-8
    },
    {
      "id": 119,
      "seek": 64588,
      "start": 668.96,
      "end": 673.52,
      "text": " era il modello mentale più vicino a quello che il team già conosceva ed il fatto di",
      "tokens": [
        4249,
        1930,
        1072,
        11216,
        3074,
        1220,
        10589,
        26031,
        2982,
        257,
        22813,
        947,
        1930,
        1469,
        30469,
        49892,
        384,
        2757,
        1257,
        1930,
        23228,
        1026
      ],
      "temperature": 0,
      "avg_logprob": -0.21246416428509882,
      "compression_ratio": 1.661764705882353,
      "no_speech_prob": 5.315782303227934e-8
    },
    {
      "id": 120,
      "seek": 67352,
      "start": 673.52,
      "end": 678.72,
      "text": " dover andare ad abbracciare il cloud e capire cosa fossero gli autoscaling group, come andare",
      "tokens": [
        360,
        331,
        42742,
        614,
        410,
        1443,
        43870,
        543,
        1930,
        4588,
        308,
        1410,
        621,
        10163,
        14090,
        2032,
        17161,
        1476,
        10466,
        4270,
        1594,
        11,
        808,
        42742
      ],
      "temperature": 0,
      "avg_logprob": -0.2190620363220688,
      "compression_ratio": 1.6616541353383458,
      "no_speech_prob": 2.2033302116142295e-7
    },
    {
      "id": 121,
      "seek": 67352,
      "start": 678.72,
      "end": 684.8,
      "text": " a creare delle AMI e tutta quella roba leggera, un overload cognitivo non banale e quindi",
      "tokens": [
        257,
        1197,
        543,
        16485,
        6475,
        40,
        308,
        3672,
        1328,
        32234,
        3870,
        64,
        1676,
        1321,
        64,
        11,
        517,
        28777,
        11786,
        270,
        6340,
        2107,
        5643,
        1220,
        308,
        15727
      ],
      "temperature": 0,
      "avg_logprob": -0.2190620363220688,
      "compression_ratio": 1.6616541353383458,
      "no_speech_prob": 2.2033302116142295e-7
    },
    {
      "id": 122,
      "seek": 67352,
      "start": 684.8,
      "end": 690.24,
      "text": " abbiamo detto ok prendetevi questo, questo vi risolve il problema nel medio termine,",
      "tokens": [
        22815,
        41031,
        3133,
        9866,
        3498,
        4917,
        10263,
        11,
        10263,
        1932,
        2253,
        37361,
        1930,
        12395,
        15373,
        22123,
        1433,
        533,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.2190620363220688,
      "compression_ratio": 1.6616541353383458,
      "no_speech_prob": 2.2033302116142295e-7
    },
    {
      "id": 123,
      "seek": 67352,
      "start": 690.24,
      "end": 694.4399999999999,
      "text": " nel lungo termine poi una volta che avete capito AWS, avete capito le basi del cloud",
      "tokens": [
        15373,
        16730,
        78,
        1433,
        533,
        19260,
        2002,
        18765,
        947,
        48201,
        1410,
        3528,
        17650,
        11,
        48201,
        1410,
        3528,
        476,
        987,
        72,
        1103,
        4588
      ],
      "temperature": 0,
      "avg_logprob": -0.2190620363220688,
      "compression_ratio": 1.6616541353383458,
      "no_speech_prob": 2.2033302116142295e-7
    },
    {
      "id": 124,
      "seek": 67352,
      "start": 694.4399999999999,
      "end": 699.76,
      "text": " potete cominciare a esplorare, magari spostate dei worker su delle lambda con SQS e pian",
      "tokens": [
        1847,
        3498,
        395,
        21961,
        543,
        257,
        785,
        564,
        284,
        543,
        11,
        49932,
        637,
        555,
        473,
        13874,
        11346,
        459,
        16485,
        13607,
        416,
        318,
        48,
        50,
        308,
        32198
      ],
      "temperature": 0,
      "avg_logprob": -0.2190620363220688,
      "compression_ratio": 1.6616541353383458,
      "no_speech_prob": 2.2033302116142295e-7
    },
    {
      "id": 125,
      "seek": 69976,
      "start": 699.76,
      "end": 704.56,
      "text": " in piano cominciate a integrare quel tipo di conoscenza, quindi se fossimo andati da",
      "tokens": [
        294,
        9211,
        395,
        21961,
        473,
        257,
        16200,
        35559,
        7178,
        9746,
        1026,
        416,
        10466,
        23691,
        11,
        15727,
        369,
        14090,
        6934,
        293,
        6908,
        1120
      ],
      "temperature": 0,
      "avg_logprob": -0.20232650637626648,
      "compression_ratio": 1.7,
      "no_speech_prob": 3.732266495859449e-9
    },
    {
      "id": 126,
      "seek": 69976,
      "start": 704.56,
      "end": 711.3199999999999,
      "text": " 0 a 100 su serverless sarebbe stato figo però probabilmente sarebbe stato un passo più",
      "tokens": [
        1958,
        257,
        2319,
        459,
        7154,
        1832,
        38706,
        39042,
        29657,
        2147,
        78,
        12673,
        31959,
        4082,
        38706,
        39042,
        29657,
        517,
        38159,
        10589
      ],
      "temperature": 0,
      "avg_logprob": -0.20232650637626648,
      "compression_ratio": 1.7,
      "no_speech_prob": 3.732266495859449e-9
    },
    {
      "id": 127,
      "seek": 69976,
      "start": 711.3199999999999,
      "end": 715.84,
      "text": " lungo della gamba per il team e magari ci sarebbero stati, cioè magari come consulente",
      "tokens": [
        16730,
        78,
        11618,
        290,
        23337,
        680,
        1930,
        1469,
        308,
        49932,
        6983,
        38706,
        65,
        46659,
        2219,
        72,
        11,
        41827,
        49932,
        808,
        1014,
        425,
        1576
      ],
      "temperature": 0,
      "avg_logprob": -0.20232650637626648,
      "compression_ratio": 1.7,
      "no_speech_prob": 3.732266495859449e-9
    },
    {
      "id": 128,
      "seek": 69976,
      "start": 715.84,
      "end": 721.68,
      "text": " avremmo dovuto fare il 99% del lavoro noi e poi andare a dare in gestione al cliente",
      "tokens": [
        1305,
        265,
        2174,
        78,
        30870,
        8262,
        11994,
        1930,
        11803,
        4,
        1103,
        42060,
        22447,
        308,
        19260,
        42742,
        257,
        8955,
        294,
        7219,
        5328,
        419,
        6423,
        68
      ],
      "temperature": 0,
      "avg_logprob": -0.20232650637626648,
      "compression_ratio": 1.7,
      "no_speech_prob": 3.732266495859449e-9
    },
    {
      "id": 129,
      "seek": 69976,
      "start": 721.68,
      "end": 726.48,
      "text": " una roba che magari loro non avevano del tutto capito e non sarebbero stati in grado di gestire",
      "tokens": [
        2002,
        3870,
        64,
        947,
        49932,
        28810,
        2107,
        3472,
        85,
        3730,
        1103,
        23048,
        1410,
        3528,
        308,
        2107,
        38706,
        65,
        46659,
        2219,
        72,
        294,
        677,
        1573,
        1026,
        7219,
        621
      ],
      "temperature": 0,
      "avg_logprob": -0.20232650637626648,
      "compression_ratio": 1.7,
      "no_speech_prob": 3.732266495859449e-9
    },
    {
      "id": 130,
      "seek": 72648,
      "start": 726.48,
      "end": 735.4,
      "text": " la solita. E questo ne dimostra anche il fatto dell'approccio che hai col cliente, cioè",
      "tokens": [
        635,
        1404,
        2786,
        13,
        462,
        10263,
        408,
        5013,
        555,
        424,
        11585,
        1930,
        23228,
        19781,
        6,
        1746,
        24174,
        8529,
        947,
        21822,
        1173,
        6423,
        68,
        11,
        41827
      ],
      "temperature": 0,
      "avg_logprob": -0.27079600822634814,
      "compression_ratio": 1.5747126436781609,
      "no_speech_prob": 7.856178285692295e-8
    },
    {
      "id": 131,
      "seek": 72648,
      "start": 735.4,
      "end": 746.76,
      "text": " il levitare l'effetto lock-in a tutti i costi, cioè il essere un catalizzatore di successo",
      "tokens": [
        1930,
        20445,
        270,
        543,
        287,
        6,
        30774,
        23778,
        4017,
        12,
        259,
        257,
        19822,
        741,
        2063,
        72,
        11,
        41827,
        1930,
        19799,
        517,
        13192,
        8072,
        43148,
        1026,
        2245,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.27079600822634814,
      "compression_ratio": 1.5747126436781609,
      "no_speech_prob": 7.856178285692295e-8
    },
    {
      "id": 132,
      "seek": 72648,
      "start": 746.76,
      "end": 753.88,
      "text": " piuttosto che essere una rondella della macchina, questa secondo me è una di quelle cose che",
      "tokens": [
        3895,
        13478,
        22756,
        947,
        19799,
        2002,
        39353,
        9885,
        11618,
        7912,
        339,
        1426,
        11,
        16540,
        41601,
        385,
        4873,
        2002,
        1026,
        29237,
        30261,
        947
      ],
      "temperature": 0,
      "avg_logprob": -0.27079600822634814,
      "compression_ratio": 1.5747126436781609,
      "no_speech_prob": 7.856178285692295e-8
    },
    {
      "id": 133,
      "seek": 75388,
      "start": 753.88,
      "end": 759.8,
      "text": " quando si parla di consulenza è necessario mettere il focus, la puntata di oggi non è",
      "tokens": [
        7770,
        1511,
        971,
        875,
        1026,
        1014,
        425,
        23691,
        4873,
        2688,
        4912,
        27812,
        323,
        1930,
        1879,
        11,
        635,
        18212,
        3274,
        1026,
        34768,
        2107,
        4873
      ],
      "temperature": 0,
      "avg_logprob": -0.2795099682278103,
      "compression_ratio": 1.4971098265895955,
      "no_speech_prob": 3.7110098105586076e-8
    },
    {
      "id": 134,
      "seek": 75388,
      "start": 759.8,
      "end": 766.24,
      "text": " sulla consulenza anche perché non abbiamo Carmine con noi a sparare le bold opinion,",
      "tokens": [
        33625,
        1014,
        425,
        23691,
        11585,
        14303,
        2107,
        22815,
        44530,
        533,
        416,
        22447,
        257,
        45954,
        543,
        476,
        11928,
        4800,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.2795099682278103,
      "compression_ratio": 1.4971098265895955,
      "no_speech_prob": 3.7110098105586076e-8
    },
    {
      "id": 135,
      "seek": 75388,
      "start": 766.24,
      "end": 773.12,
      "text": " ma è invece su un'altra tematica che hai citato che è il mondo serverless. Il mondo",
      "tokens": [
        463,
        4873,
        36344,
        459,
        517,
        6,
        38865,
        32954,
        2262,
        947,
        21822,
        4814,
        2513,
        947,
        4873,
        1930,
        40499,
        7154,
        1832,
        13,
        4416,
        40499
      ],
      "temperature": 0,
      "avg_logprob": -0.2795099682278103,
      "compression_ratio": 1.4971098265895955,
      "no_speech_prob": 3.7110098105586076e-8
    },
    {
      "id": 136,
      "seek": 77312,
      "start": 773.12,
      "end": 784.28,
      "text": " serverless 2014, 2015, 2023, di anni ne sono passati parecchi. Come si è evoluto lungo",
      "tokens": [
        7154,
        1832,
        8227,
        11,
        7546,
        11,
        44377,
        11,
        1026,
        31164,
        408,
        9259,
        1320,
        6908,
        7448,
        66,
        8036,
        13,
        2492,
        1511,
        4873,
        1073,
        2308,
        78,
        16730,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.27344239788290897,
      "compression_ratio": 1.4126984126984128,
      "no_speech_prob": 2.845333391121585e-8
    },
    {
      "id": 137,
      "seek": 77312,
      "start": 784.28,
      "end": 793.96,
      "text": " tutto questo quasi dieci anni? Allora parto subito con la opinione conflittuale che forse",
      "tokens": [
        23048,
        10263,
        20954,
        978,
        537,
        31164,
        30,
        1057,
        3252,
        644,
        78,
        1422,
        3528,
        416,
        635,
        4800,
        68,
        1497,
        75,
        593,
        901,
        68,
        947,
        337,
        405
      ],
      "temperature": 0,
      "avg_logprob": -0.27344239788290897,
      "compression_ratio": 1.4126984126984128,
      "no_speech_prob": 2.845333391121585e-8
    },
    {
      "id": 138,
      "seek": 77312,
      "start": 793.96,
      "end": 798.6,
      "text": " ti tirerà fuori gli argomenti di discussioni interessanti perché ultimamente sto avendo",
      "tokens": [
        8757,
        13807,
        260,
        1467,
        8536,
        7386,
        17161,
        3882,
        298,
        23012,
        1026,
        5017,
        72,
        12478,
        11520,
        14303,
        3725,
        332,
        3439,
        22784,
        1305,
        3999
      ],
      "temperature": 0,
      "avg_logprob": -0.27344239788290897,
      "compression_ratio": 1.4126984126984128,
      "no_speech_prob": 2.845333391121585e-8
    },
    {
      "id": 139,
      "seek": 79860,
      "start": 798.6,
      "end": 805.08,
      "text": " un po' una delusione da serverless, quindi vorrei portare questo tipo di opinione, nel",
      "tokens": [
        517,
        714,
        6,
        2002,
        1103,
        301,
        5328,
        1120,
        7154,
        1832,
        11,
        15727,
        4245,
        10271,
        2436,
        543,
        10263,
        9746,
        1026,
        4800,
        68,
        11,
        15373
      ],
      "temperature": 0,
      "avg_logprob": -0.227625593847158,
      "compression_ratio": 1.567099567099567,
      "no_speech_prob": 5.07235426994157e-8
    },
    {
      "id": 140,
      "seek": 79860,
      "start": 805.08,
      "end": 812.08,
      "text": " senso che quando è stata rilasciata lambda, credo forse proprio 2014, aveva un po' questa",
      "tokens": [
        3151,
        539,
        947,
        7770,
        4873,
        49554,
        367,
        388,
        296,
        537,
        3274,
        13607,
        11,
        3864,
        78,
        337,
        405,
        28203,
        8227,
        11,
        3472,
        2757,
        517,
        714,
        6,
        16540
      ],
      "temperature": 0,
      "avg_logprob": -0.227625593847158,
      "compression_ratio": 1.567099567099567,
      "no_speech_prob": 5.07235426994157e-8
    },
    {
      "id": 141,
      "seek": 79860,
      "start": 812.08,
      "end": 817.5600000000001,
      "text": " promessa di dire finalmente abbiamo trovato una strazione che a livello di business vi",
      "tokens": [
        2234,
        8391,
        1026,
        1264,
        35577,
        22815,
        35449,
        2513,
        2002,
        2148,
        19706,
        947,
        257,
        1621,
        1913,
        1026,
        1606,
        1932
      ],
      "temperature": 0,
      "avg_logprob": -0.227625593847158,
      "compression_ratio": 1.567099567099567,
      "no_speech_prob": 5.07235426994157e-8
    },
    {
      "id": 142,
      "seek": 79860,
      "start": 817.5600000000001,
      "end": 824.08,
      "text": " fa concentrare quanto più possibile sui problemi di business, quindi scrivete la minor quantità",
      "tokens": [
        2050,
        5512,
        35559,
        17820,
        10589,
        50184,
        459,
        72,
        1154,
        72,
        1026,
        1606,
        11,
        15727,
        5545,
        85,
        3498,
        635,
        6696,
        4426,
        12445
      ],
      "temperature": 0,
      "avg_logprob": -0.227625593847158,
      "compression_ratio": 1.567099567099567,
      "no_speech_prob": 5.07235426994157e-8
    },
    {
      "id": 143,
      "seek": 82408,
      "start": 824.08,
      "end": 829.2,
      "text": " di codice possibile per risolvere un problema di business, boom, produzione, non vi dovete",
      "tokens": [
        1026,
        17656,
        573,
        50184,
        680,
        2253,
        401,
        5887,
        517,
        12395,
        1026,
        1606,
        11,
        9351,
        11,
        1082,
        19706,
        11,
        2107,
        1932,
        30870,
        3498
      ],
      "temperature": 0,
      "avg_logprob": -0.2472681157729205,
      "compression_ratio": 1.5822222222222222,
      "no_speech_prob": 7.4224981716497496e-9
    },
    {
      "id": 144,
      "seek": 82408,
      "start": 829.2,
      "end": 836.12,
      "text": " preoccupare quasi di niente. Che forse all'inizio c'era una abbastanza vicina a questo tipo",
      "tokens": [
        44388,
        543,
        20954,
        1026,
        297,
        8413,
        13,
        3351,
        337,
        405,
        439,
        6,
        9328,
        1004,
        269,
        6,
        1663,
        2002,
        16903,
        525,
        20030,
        26031,
        1426,
        257,
        10263,
        9746
      ],
      "temperature": 0,
      "avg_logprob": -0.2472681157729205,
      "compression_ratio": 1.5822222222222222,
      "no_speech_prob": 7.4224981716497496e-9
    },
    {
      "id": 145,
      "seek": 82408,
      "start": 836.12,
      "end": 843.4000000000001,
      "text": " di concetto e poi all'atto pratico quello che è successo passando dal quasi dieci anni",
      "tokens": [
        1026,
        1588,
        23778,
        308,
        19260,
        439,
        6,
        37491,
        33852,
        78,
        22813,
        947,
        4873,
        2245,
        78,
        1320,
        1806,
        11702,
        20954,
        978,
        537,
        31164
      ],
      "temperature": 0,
      "avg_logprob": -0.2472681157729205,
      "compression_ratio": 1.5822222222222222,
      "no_speech_prob": 7.4224981716497496e-9
    },
    {
      "id": 146,
      "seek": 82408,
      "start": 843.4000000000001,
      "end": 848.32,
      "text": " dopo, sono passati nove anni, in realtà se prendiamo, io parlo in particolar modo di",
      "tokens": [
        35196,
        11,
        9259,
        1320,
        6908,
        26972,
        31164,
        11,
        294,
        47512,
        369,
        9866,
        7415,
        11,
        19785,
        971,
        752,
        294,
        1276,
        15276,
        16664,
        1026
      ],
      "temperature": 0,
      "avg_logprob": -0.2472681157729205,
      "compression_ratio": 1.5822222222222222,
      "no_speech_prob": 7.4224981716497496e-9
    },
    {
      "id": 147,
      "seek": 84832,
      "start": 848.32,
      "end": 855.48,
      "text": " AWS lambda e di contesto AWS, quello che hanno fatto non è stato altro che aggiungere feature",
      "tokens": [
        17650,
        13607,
        308,
        1026,
        660,
        18465,
        17650,
        11,
        22813,
        947,
        26595,
        23228,
        2107,
        4873,
        29657,
        40924,
        947,
        42254,
        1063,
        323,
        4111
      ],
      "temperature": 0,
      "avg_logprob": -0.22462513066139542,
      "compression_ratio": 1.6828358208955223,
      "no_speech_prob": 5.602795560832874e-9
    },
    {
      "id": 148,
      "seek": 84832,
      "start": 855.48,
      "end": 861.4000000000001,
      "text": " su feature su feature su, e per feature parlo proprio di configurabilità, dimensioni in",
      "tokens": [
        459,
        4111,
        459,
        4111,
        459,
        11,
        308,
        680,
        4111,
        971,
        752,
        28203,
        1026,
        22192,
        5177,
        12445,
        11,
        10139,
        72,
        294
      ],
      "temperature": 0,
      "avg_logprob": -0.22462513066139542,
      "compression_ratio": 1.6828358208955223,
      "no_speech_prob": 5.602795560832874e-9
    },
    {
      "id": 149,
      "seek": 84832,
      "start": 861.4000000000001,
      "end": 867.08,
      "text": " cui si può configurare una lambda, e all'atto pratico oggi è forse più complesso andare",
      "tokens": [
        22929,
        1511,
        26526,
        22192,
        543,
        2002,
        13607,
        11,
        308,
        439,
        6,
        37491,
        582,
        6908,
        1291,
        34768,
        4873,
        337,
        405,
        10589,
        1209,
        5557,
        42742
      ],
      "temperature": 0,
      "avg_logprob": -0.22462513066139542,
      "compression_ratio": 1.6828358208955223,
      "no_speech_prob": 5.602795560832874e-9
    },
    {
      "id": 150,
      "seek": 84832,
      "start": 867.08,
      "end": 871.9200000000001,
      "text": " a mettere in piedi una lambda di quanto lo era nove anni fa, perché c'è una matrice",
      "tokens": [
        257,
        27812,
        323,
        294,
        24186,
        72,
        2002,
        13607,
        1026,
        17820,
        450,
        4249,
        26972,
        31164,
        2050,
        11,
        14303,
        269,
        6,
        1462,
        2002,
        3803,
        21299
      ],
      "temperature": 0,
      "avg_logprob": -0.22462513066139542,
      "compression_ratio": 1.6828358208955223,
      "no_speech_prob": 5.602795560832874e-9
    },
    {
      "id": 151,
      "seek": 84832,
      "start": 871.9200000000001,
      "end": 877,
      "text": " di configurazione infinita e bisogna veramente andare a capire cosa vuol dire ogni singolo",
      "tokens": [
        1026,
        22192,
        12928,
        7193,
        2786,
        308,
        40505,
        629,
        50079,
        42742,
        257,
        1410,
        621,
        10163,
        9732,
        401,
        1264,
        33189,
        1522,
        7902
      ],
      "temperature": 0,
      "avg_logprob": -0.22462513066139542,
      "compression_ratio": 1.6828358208955223,
      "no_speech_prob": 5.602795560832874e-9
    },
    {
      "id": 152,
      "seek": 87700,
      "start": 877,
      "end": 882.4,
      "text": " parametro configurazione per mettere in piedi qualcosa di decente. Quindi per assurdo è",
      "tokens": [
        6220,
        302,
        340,
        22192,
        12928,
        680,
        27812,
        323,
        294,
        24186,
        72,
        42400,
        1026,
        979,
        1576,
        13,
        32534,
        680,
        1256,
        374,
        2595,
        4873
      ],
      "temperature": 0,
      "avg_logprob": -0.23466453552246094,
      "compression_ratio": 1.6227106227106227,
      "no_speech_prob": 3.224184652594886e-8
    },
    {
      "id": 153,
      "seek": 87700,
      "start": 882.4,
      "end": 889.26,
      "text": " un po' un paradosso, nel senso che siamo partiti con quell'ideale di diamo un servizio quanto",
      "tokens": [
        517,
        714,
        6,
        517,
        971,
        4181,
        539,
        11,
        15373,
        3151,
        539,
        947,
        33459,
        644,
        8707,
        416,
        631,
        285,
        6,
        482,
        1220,
        1026,
        7484,
        78,
        517,
        1658,
        590,
        1004,
        17820
      ],
      "temperature": 0,
      "avg_logprob": -0.23466453552246094,
      "compression_ratio": 1.6227106227106227,
      "no_speech_prob": 3.224184652594886e-8
    },
    {
      "id": 154,
      "seek": 87700,
      "start": 889.26,
      "end": 894.04,
      "text": " più manage possibile in modo che tu scrivi con una strazione semplicissima il codice,",
      "tokens": [
        10589,
        3067,
        50184,
        294,
        16664,
        947,
        2604,
        5545,
        4917,
        416,
        2002,
        1056,
        12928,
        4361,
        4770,
        891,
        4775,
        1930,
        17656,
        573,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.23466453552246094,
      "compression_ratio": 1.6227106227106227,
      "no_speech_prob": 3.224184652594886e-8
    },
    {
      "id": 155,
      "seek": 87700,
      "start": 894.04,
      "end": 899.48,
      "text": " risolvi un problema, deploy, fine, tutto il resto se lo avete il cloud provider, e siamo",
      "tokens": [
        2253,
        401,
        4917,
        517,
        12395,
        11,
        7274,
        11,
        2489,
        11,
        23048,
        1930,
        28247,
        369,
        450,
        48201,
        1930,
        4588,
        12398,
        11,
        308,
        33459
      ],
      "temperature": 0,
      "avg_logprob": -0.23466453552246094,
      "compression_ratio": 1.6227106227106227,
      "no_speech_prob": 3.224184652594886e-8
    },
    {
      "id": 156,
      "seek": 87700,
      "start": 899.48,
      "end": 903.96,
      "text": " arrivati al fatto che ovviamente gli utenti hanno avuto sempre delle richieste molto",
      "tokens": [
        30697,
        6908,
        419,
        23228,
        947,
        14187,
        23347,
        17161,
        2839,
        23012,
        26595,
        1305,
        8262,
        9553,
        16485,
        4593,
        6495,
        68,
        16394
      ],
      "temperature": 0,
      "avg_logprob": -0.23466453552246094,
      "compression_ratio": 1.6227106227106227,
      "no_speech_prob": 3.224184652594886e-8
    },
    {
      "id": 157,
      "seek": 90396,
      "start": 903.96,
      "end": 909.32,
      "text": " più specifiche, e AWS ha quella filosofia di customer first, quindi se abbastanza clienti",
      "tokens": [
        10589,
        1608,
        351,
        9304,
        11,
        308,
        17650,
        324,
        32234,
        46045,
        2670,
        654,
        1026,
        5474,
        700,
        11,
        15727,
        369,
        16903,
        525,
        20030,
        6423,
        72
      ],
      "temperature": 0,
      "avg_logprob": -0.23817908245584238,
      "compression_ratio": 1.6476868327402134,
      "no_speech_prob": 7.380232602827164e-8
    },
    {
      "id": 158,
      "seek": 90396,
      "start": 909.32,
      "end": 915.36,
      "text": " chiedono una cosa AWS la fa, e all'atto pratico siamo arrivati a una sorta di astrazione che",
      "tokens": [
        417,
        1091,
        8957,
        2002,
        10163,
        17650,
        635,
        2050,
        11,
        308,
        439,
        6,
        37491,
        33852,
        78,
        33459,
        30697,
        6908,
        257,
        2002,
        33425,
        1026,
        5357,
        424,
        19706,
        947
      ],
      "temperature": 0,
      "avg_logprob": -0.23817908245584238,
      "compression_ratio": 1.6476868327402134,
      "no_speech_prob": 7.380232602827164e-8
    },
    {
      "id": 159,
      "seek": 90396,
      "start": 915.36,
      "end": 921.1600000000001,
      "text": " non è più un'astrazione perché puoi configurare lambda in mille modi diversi, e se tu ti stai",
      "tokens": [
        2107,
        4873,
        10589,
        517,
        6,
        525,
        424,
        19706,
        14303,
        2362,
        4869,
        22192,
        543,
        13607,
        294,
        1728,
        68,
        1072,
        72,
        6111,
        72,
        11,
        308,
        369,
        2604,
        8757,
        342,
        1301
      ],
      "temperature": 0,
      "avg_logprob": -0.23817908245584238,
      "compression_ratio": 1.6476868327402134,
      "no_speech_prob": 7.380232602827164e-8
    },
    {
      "id": 160,
      "seek": 90396,
      "start": 921.1600000000001,
      "end": 927,
      "text": " approcciando a lambda oggi per la prima volta può essere un po' diciamo una cosa che fa",
      "tokens": [
        2075,
        66,
        537,
        1806,
        257,
        13607,
        34768,
        680,
        635,
        19507,
        18765,
        26526,
        19799,
        517,
        714,
        6,
        14285,
        7415,
        2002,
        10163,
        947,
        2050
      ],
      "temperature": 0,
      "avg_logprob": -0.23817908245584238,
      "compression_ratio": 1.6476868327402134,
      "no_speech_prob": 7.380232602827164e-8
    },
    {
      "id": 161,
      "seek": 90396,
      "start": 927,
      "end": 931.36,
      "text": " un po' paura perché dici ok mi hanno promesso un'esperienza molto semplice, all'atto pratico",
      "tokens": [
        517,
        714,
        6,
        2502,
        2991,
        14303,
        274,
        8787,
        3133,
        2752,
        26595,
        2234,
        5557,
        517,
        6,
        34698,
        42331,
        16394,
        4361,
        564,
        573,
        11,
        439,
        6,
        37491,
        33852,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.23817908245584238,
      "compression_ratio": 1.6476868327402134,
      "no_speech_prob": 7.380232602827164e-8
    },
    {
      "id": 162,
      "seek": 93136,
      "start": 931.36,
      "end": 936.4,
      "text": " non ho idea di dove iniziare perché c'è talmente tanta roba da configurare che effettivamente",
      "tokens": [
        2107,
        1106,
        1558,
        1026,
        23287,
        294,
        24300,
        543,
        14303,
        269,
        6,
        1462,
        4023,
        4082,
        40864,
        3870,
        64,
        1120,
        22192,
        543,
        947,
        1244,
        3093,
        23957
      ],
      "temperature": 0,
      "avg_logprob": -0.24223925372746985,
      "compression_ratio": 1.6791044776119404,
      "no_speech_prob": 5.152229221039306e-8
    },
    {
      "id": 163,
      "seek": 93136,
      "start": 936.4,
      "end": 942.08,
      "text": " è difficile capire da dove iniziare, volevo portare questa opinione un po' conflittuale",
      "tokens": [
        4873,
        26607,
        1410,
        621,
        1120,
        23287,
        294,
        24300,
        543,
        11,
        49877,
        3080,
        2436,
        543,
        16540,
        4800,
        68,
        517,
        714,
        6,
        1497,
        75,
        593,
        901,
        68
      ],
      "temperature": 0,
      "avg_logprob": -0.24223925372746985,
      "compression_ratio": 1.6791044776119404,
      "no_speech_prob": 5.152229221039306e-8
    },
    {
      "id": 164,
      "seek": 93136,
      "start": 942.08,
      "end": 946.8000000000001,
      "text": " che la promessa di serverless secondo me è andata un po' a decadere negli anni. Come",
      "tokens": [
        947,
        635,
        2234,
        8391,
        1026,
        7154,
        1832,
        41601,
        385,
        4873,
        293,
        3274,
        517,
        714,
        6,
        257,
        979,
        345,
        323,
        2485,
        2081,
        31164,
        13,
        2492
      ],
      "temperature": 0,
      "avg_logprob": -0.24223925372746985,
      "compression_ratio": 1.6791044776119404,
      "no_speech_prob": 5.152229221039306e-8
    },
    {
      "id": 165,
      "seek": 93136,
      "start": 946.8000000000001,
      "end": 952.44,
      "text": " il discorso del per esempio parlando di lambda, della quantità di memoria che allochi per",
      "tokens": [
        1930,
        2983,
        284,
        539,
        1103,
        680,
        33627,
        971,
        16201,
        1026,
        13607,
        11,
        11618,
        4426,
        12445,
        1026,
        1334,
        8172,
        947,
        439,
        78,
        8036,
        680
      ],
      "temperature": 0,
      "avg_logprob": -0.24223925372746985,
      "compression_ratio": 1.6791044776119404,
      "no_speech_prob": 5.152229221039306e-8
    },
    {
      "id": 166,
      "seek": 93136,
      "start": 952.44,
      "end": 957.76,
      "text": " ogni lambda che in realtà influisce anche sulla potenza di calcolo della lambda stessa,",
      "tokens": [
        33189,
        13607,
        947,
        294,
        47512,
        4015,
        49596,
        11585,
        33625,
        1847,
        23691,
        1026,
        2104,
        46086,
        11618,
        13607,
        342,
        8391,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.24223925372746985,
      "compression_ratio": 1.6791044776119404,
      "no_speech_prob": 5.152229221039306e-8
    },
    {
      "id": 167,
      "seek": 95776,
      "start": 957.76,
      "end": 963.36,
      "text": " quindi te puoi decidere di dare più memoria e quindi più potenza per ridurre il tempo",
      "tokens": [
        15727,
        535,
        2362,
        4869,
        21937,
        323,
        1026,
        8955,
        10589,
        1334,
        8172,
        308,
        15727,
        10589,
        1847,
        23691,
        680,
        3973,
        374,
        265,
        1930,
        8972
      ],
      "temperature": 0,
      "avg_logprob": -0.24051583082156075,
      "compression_ratio": 1.7569721115537849,
      "no_speech_prob": 0.00000893967899173731
    },
    {
      "id": 168,
      "seek": 95776,
      "start": 963.36,
      "end": 969.16,
      "text": " di esecuzione, dato che la lambda la paghi al millisecondo, quando vai a deploiare devi",
      "tokens": [
        1026,
        785,
        3045,
        3334,
        5328,
        11,
        46971,
        947,
        635,
        13607,
        635,
        11812,
        4954,
        419,
        27940,
        18882,
        78,
        11,
        7770,
        4405,
        257,
        368,
        21132,
        72,
        543,
        31219
      ],
      "temperature": 0,
      "avg_logprob": -0.24051583082156075,
      "compression_ratio": 1.7569721115537849,
      "no_speech_prob": 0.00000893967899173731
    },
    {
      "id": 169,
      "seek": 95776,
      "start": 969.16,
      "end": 974.04,
      "text": " fare delle prove per capire se la tua applicazione, cioè se paghi meno aumentando la potenza",
      "tokens": [
        11994,
        16485,
        7081,
        680,
        1410,
        621,
        369,
        635,
        33578,
        2580,
        12928,
        11,
        41827,
        369,
        11812,
        4954,
        40236,
        17128,
        1806,
        635,
        1847,
        23691
      ],
      "temperature": 0,
      "avg_logprob": -0.24051583082156075,
      "compression_ratio": 1.7569721115537849,
      "no_speech_prob": 0.00000893967899173731
    },
    {
      "id": 170,
      "seek": 95776,
      "start": 974.04,
      "end": 979.68,
      "text": " e diminuendo il tempo di utilizzo, oppure tenendo un tempo di utilizzo più lungo,",
      "tokens": [
        308,
        15739,
        84,
        3999,
        1930,
        8972,
        1026,
        19906,
        4765,
        11,
        1458,
        540,
        2064,
        3999,
        517,
        8972,
        1026,
        19906,
        4765,
        10589,
        16730,
        78,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.24051583082156075,
      "compression_ratio": 1.7569721115537849,
      "no_speech_prob": 0.00000893967899173731
    },
    {
      "id": 171,
      "seek": 95776,
      "start": 979.68,
      "end": 984.08,
      "text": " eppure come hai detto te all'inizio dicevano te metti la funzione e viene eseguita e non",
      "tokens": [
        308,
        427,
        540,
        808,
        21822,
        41031,
        535,
        439,
        6,
        9328,
        1004,
        10313,
        85,
        3730,
        535,
        1131,
        7317,
        635,
        1019,
        19706,
        308,
        19561,
        785,
        1146,
        1983,
        64,
        308,
        2107
      ],
      "temperature": 0,
      "avg_logprob": -0.24051583082156075,
      "compression_ratio": 1.7569721115537849,
      "no_speech_prob": 0.00000893967899173731
    },
    {
      "id": 172,
      "seek": 98408,
      "start": 984.08,
      "end": 989.44,
      "text": " ti devi preoccupare della scalabilità. Su questo voglio aggiungere una cosa perché",
      "tokens": [
        8757,
        31219,
        44388,
        543,
        11618,
        15664,
        5177,
        12445,
        13,
        2746,
        10263,
        31273,
        19987,
        42254,
        1063,
        323,
        2002,
        10163,
        14303
      ],
      "temperature": 0,
      "avg_logprob": -0.23974159642269738,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.0000011015939662684104
    },
    {
      "id": 173,
      "seek": 98408,
      "start": 989.44,
      "end": 994.2800000000001,
      "text": " qua su Github abbiamo un episodio proprio su questo topic che registrammo un po' di",
      "tokens": [
        24159,
        459,
        460,
        355,
        836,
        22815,
        517,
        39200,
        1004,
        28203,
        459,
        10263,
        4829,
        947,
        11376,
        2356,
        3280,
        517,
        714,
        6,
        1026
      ],
      "temperature": 0,
      "avg_logprob": -0.23974159642269738,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.0000011015939662684104
    },
    {
      "id": 174,
      "seek": 98408,
      "start": 994.2800000000001,
      "end": 1004.1600000000001,
      "text": " tempo fa con Alex Casalboni, proprio sul dimensionamento, aveva fatto dei lavori, era uscito con un tool",
      "tokens": [
        8972,
        2050,
        416,
        5202,
        16100,
        304,
        4351,
        72,
        11,
        28203,
        17603,
        10139,
        8824,
        11,
        3472,
        2757,
        23228,
        13874,
        20923,
        7386,
        11,
        4249,
        505,
        32030,
        416,
        517,
        2290
      ],
      "temperature": 0,
      "avg_logprob": -0.23974159642269738,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.0000011015939662684104
    },
    {
      "id": 175,
      "seek": 98408,
      "start": 1004.1600000000001,
      "end": 1010.4000000000001,
      "text": " che si occupava proprio del dimensionamento delle lambda, quindi ve lo metto nelle note",
      "tokens": [
        947,
        1511,
        8073,
        4061,
        28203,
        1103,
        10139,
        8824,
        16485,
        13607,
        11,
        15727,
        1241,
        450,
        1131,
        1353,
        46350,
        3637
      ],
      "temperature": 0,
      "avg_logprob": -0.23974159642269738,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.0000011015939662684104
    },
    {
      "id": 176,
      "seek": 101040,
      "start": 1010.4,
      "end": 1015.76,
      "text": " dell'episodio e lo andiamo a recuperare. Quello che però è interessante è quello",
      "tokens": [
        19781,
        6,
        595,
        271,
        378,
        1004,
        308,
        450,
        293,
        7415,
        257,
        25692,
        543,
        13,
        4493,
        1913,
        947,
        12673,
        4873,
        24372,
        4873,
        22813
      ],
      "temperature": 0,
      "avg_logprob": -0.2067399819691976,
      "compression_ratio": 1.6073059360730593,
      "no_speech_prob": 4.4763382334167545e-8
    },
    {
      "id": 177,
      "seek": 101040,
      "start": 1015.76,
      "end": 1020.68,
      "text": " che ha detto Leo, perché comunque noi non abbiamo solo un problema di configurabilità",
      "tokens": [
        947,
        324,
        41031,
        19344,
        11,
        14303,
        45736,
        22447,
        2107,
        22815,
        6944,
        517,
        12395,
        1026,
        22192,
        5177,
        12445
      ],
      "temperature": 0,
      "avg_logprob": -0.2067399819691976,
      "compression_ratio": 1.6073059360730593,
      "no_speech_prob": 4.4763382334167545e-8
    },
    {
      "id": 178,
      "seek": 101040,
      "start": 1020.68,
      "end": 1029.72,
      "text": " in termini di integrazione con servizi terzi, ma anche la stessa funzione serverless ha",
      "tokens": [
        294,
        1433,
        3812,
        1026,
        16200,
        424,
        19706,
        416,
        1658,
        24300,
        1796,
        3992,
        11,
        463,
        11585,
        635,
        342,
        8391,
        1019,
        19706,
        7154,
        1832,
        324
      ],
      "temperature": 0,
      "avg_logprob": -0.2067399819691976,
      "compression_ratio": 1.6073059360730593,
      "no_speech_prob": 4.4763382334167545e-8
    },
    {
      "id": 179,
      "seek": 101040,
      "start": 1029.72,
      "end": 1036.08,
      "text": " una certa complessità intrinseca, la stessa architettura anche solo del concetto serverless",
      "tokens": [
        2002,
        44438,
        1209,
        442,
        12445,
        560,
        12629,
        405,
        496,
        11,
        635,
        342,
        8391,
        3912,
        270,
        3093,
        2991,
        11585,
        6944,
        1103,
        1588,
        23778,
        7154,
        1832
      ],
      "temperature": 0,
      "avg_logprob": -0.2067399819691976,
      "compression_ratio": 1.6073059360730593,
      "no_speech_prob": 4.4763382334167545e-8
    },
    {
      "id": 180,
      "seek": 103608,
      "start": 1036.08,
      "end": 1045.72,
      "text": " ha una certa complessità sua, naturale. Hai parlato prima di configurabilità, si può",
      "tokens": [
        324,
        2002,
        44438,
        1209,
        442,
        12445,
        8233,
        11,
        40877,
        13,
        24055,
        13734,
        2513,
        19507,
        1026,
        22192,
        5177,
        12445,
        11,
        1511,
        26526
      ],
      "temperature": 0,
      "avg_logprob": -0.2843040720621745,
      "compression_ratio": 1.463276836158192,
      "no_speech_prob": 2.309069770944916e-7
    },
    {
      "id": 181,
      "seek": 103608,
      "start": 1045.72,
      "end": 1057.76,
      "text": " dire configurabilità in italiano? Male che va di un neologismo. Volevo chiederti, hai",
      "tokens": [
        1264,
        22192,
        5177,
        12445,
        294,
        48486,
        30,
        21080,
        947,
        2773,
        1026,
        517,
        408,
        1132,
        6882,
        13,
        691,
        4812,
        3080,
        417,
        1091,
        911,
        72,
        11,
        21822
      ],
      "temperature": 0,
      "avg_logprob": -0.2843040720621745,
      "compression_ratio": 1.463276836158192,
      "no_speech_prob": 2.309069770944916e-7
    },
    {
      "id": 182,
      "seek": 103608,
      "start": 1057.76,
      "end": 1064.4399999999998,
      "text": " degli esempi, dei casi di uso particolari che evidenzino questo tipo di complessità",
      "tokens": [
        32079,
        32340,
        72,
        11,
        13874,
        22567,
        1026,
        22728,
        1276,
        401,
        3504,
        947,
        43699,
        89,
        2982,
        10263,
        9746,
        1026,
        1209,
        442,
        12445
      ],
      "temperature": 0,
      "avg_logprob": -0.2843040720621745,
      "compression_ratio": 1.463276836158192,
      "no_speech_prob": 2.309069770944916e-7
    },
    {
      "id": 183,
      "seek": 106444,
      "start": 1064.44,
      "end": 1069.8,
      "text": " che va a crescere proprio data dal fatto che possiamo utilizzarle anche per farci il caffè?",
      "tokens": [
        947,
        2773,
        257,
        20964,
        15312,
        28203,
        1412,
        11702,
        23228,
        947,
        44758,
        40355,
        36153,
        11585,
        680,
        1400,
        537,
        1930,
        1335,
        602,
        1462,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.26304759676494294,
      "compression_ratio": 1.6346863468634687,
      "no_speech_prob": 5.203561954658653e-7
    },
    {
      "id": 184,
      "seek": 106444,
      "start": 1069.8,
      "end": 1075.68,
      "text": " Oddio, un esempio particolare non so se mi viene in mente così su due piedi, però in",
      "tokens": [
        12210,
        41256,
        11,
        517,
        33627,
        1276,
        43141,
        2107,
        370,
        369,
        2752,
        19561,
        294,
        26577,
        23278,
        459,
        3462,
        24186,
        72,
        11,
        12673,
        294
      ],
      "temperature": 0,
      "avg_logprob": -0.26304759676494294,
      "compression_ratio": 1.6346863468634687,
      "no_speech_prob": 5.203561954658653e-7
    },
    {
      "id": 185,
      "seek": 106444,
      "start": 1075.68,
      "end": 1080.88,
      "text": " generale quando io parlo di configurabilità non parlo solo diciamo delle opzioni che hai",
      "tokens": [
        1337,
        1220,
        7770,
        19785,
        971,
        752,
        1026,
        22192,
        5177,
        12445,
        2107,
        971,
        752,
        6944,
        14285,
        7415,
        16485,
        999,
        89,
        15273,
        947,
        21822
      ],
      "temperature": 0,
      "avg_logprob": -0.26304759676494294,
      "compression_ratio": 1.6346863468634687,
      "no_speech_prob": 5.203561954658653e-7
    },
    {
      "id": 186,
      "seek": 106444,
      "start": 1080.88,
      "end": 1085.3200000000002,
      "text": " in termini proprio di i parametri che puoi andare a configurare, ma anche di tutti i",
      "tokens": [
        294,
        1433,
        3812,
        28203,
        1026,
        741,
        6220,
        302,
        470,
        947,
        2362,
        4869,
        42742,
        257,
        22192,
        543,
        11,
        463,
        11585,
        1026,
        19822,
        741
      ],
      "temperature": 0,
      "avg_logprob": -0.26304759676494294,
      "compression_ratio": 1.6346863468634687,
      "no_speech_prob": 5.203561954658653e-7
    },
    {
      "id": 187,
      "seek": 106444,
      "start": 1085.3200000000002,
      "end": 1091.16,
      "text": " limiti quelli che sono imposti dal runtime che ti da la lambda. Esempio banale, non puoi",
      "tokens": [
        4948,
        72,
        631,
        16320,
        947,
        9259,
        47804,
        72,
        11702,
        34474,
        947,
        8757,
        1120,
        635,
        13607,
        13,
        462,
        405,
        2455,
        1004,
        5643,
        1220,
        11,
        2107,
        2362,
        4869
      ],
      "temperature": 0,
      "avg_logprob": -0.26304759676494294,
      "compression_ratio": 1.6346863468634687,
      "no_speech_prob": 5.203561954658653e-7
    },
    {
      "id": 188,
      "seek": 109116,
      "start": 1091.16,
      "end": 1096.68,
      "text": " avere un payload credo più di 5 megabyte, né puoi restituire una risposta che sia più",
      "tokens": [
        37914,
        517,
        30918,
        3864,
        78,
        10589,
        1026,
        1025,
        10816,
        34529,
        11,
        7024,
        2362,
        4869,
        1472,
        6380,
        621,
        2002,
        2253,
        79,
        8638,
        947,
        25176,
        10589
      ],
      "temperature": 0,
      "avg_logprob": -0.2779480146325153,
      "compression_ratio": 1.5862068965517242,
      "no_speech_prob": 6.02357062007286e-8
    },
    {
      "id": 189,
      "seek": 109116,
      "start": 1096.68,
      "end": 1103.28,
      "text": " di 5 megabyte. In più il modello non è streaming ma è semplicemente richiesta risposta e c'hai",
      "tokens": [
        1026,
        1025,
        10816,
        34529,
        13,
        682,
        10589,
        1930,
        1072,
        11216,
        2107,
        4873,
        11791,
        463,
        4873,
        4361,
        4770,
        16288,
        4593,
        38804,
        2253,
        79,
        8638,
        308,
        269,
        6,
        18230
      ],
      "temperature": 0,
      "avg_logprob": -0.2779480146325153,
      "compression_ratio": 1.5862068965517242,
      "no_speech_prob": 6.02357062007286e-8
    },
    {
      "id": 190,
      "seek": 109116,
      "start": 1103.28,
      "end": 1109.0800000000002,
      "text": " dei json in entrata e in uscita, quindi banalmente già questo ti ha precluso tutta una serie",
      "tokens": [
        13874,
        361,
        3015,
        294,
        948,
        4481,
        64,
        308,
        294,
        505,
        66,
        2786,
        11,
        15727,
        5643,
        304,
        4082,
        30469,
        10263,
        8757,
        324,
        4346,
        3063,
        78,
        3672,
        1328,
        2002,
        23030
      ],
      "temperature": 0,
      "avg_logprob": -0.2779480146325153,
      "compression_ratio": 1.5862068965517242,
      "no_speech_prob": 6.02357062007286e-8
    },
    {
      "id": 191,
      "seek": 109116,
      "start": 1109.0800000000002,
      "end": 1114.64,
      "text": " di casi d'uso che magari a latto pratico ne potresti aver bisogno. Banalmente devo fare",
      "tokens": [
        1026,
        22567,
        274,
        6,
        24431,
        947,
        49932,
        257,
        287,
        1591,
        78,
        33852,
        78,
        408,
        1847,
        4149,
        72,
        18247,
        40505,
        1771,
        13,
        13850,
        304,
        4082,
        49717,
        11994
      ],
      "temperature": 0,
      "avg_logprob": -0.2779480146325153,
      "compression_ratio": 1.5862068965517242,
      "no_speech_prob": 6.02357062007286e-8
    },
    {
      "id": 192,
      "seek": 111464,
      "start": 1114.64,
      "end": 1123.2,
      "text": " un upload di un video, non lo puoi fare direttamente con lambda ma devi utilizzare qualche strumento",
      "tokens": [
        517,
        6580,
        1026,
        517,
        960,
        11,
        2107,
        450,
        2362,
        4869,
        11994,
        1264,
        6319,
        3439,
        416,
        13607,
        463,
        31219,
        40355,
        543,
        38737,
        1056,
        2206,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.23900264940763774,
      "compression_ratio": 1.6422413793103448,
      "no_speech_prob": 3.1249879128836255e-8
    },
    {
      "id": 193,
      "seek": 111464,
      "start": 1123.2,
      "end": 1129.1200000000001,
      "text": " diverso proprio perché quello ti va a prendere un limite specifico delle lambda. Poi come",
      "tokens": [
        18558,
        539,
        28203,
        14303,
        22813,
        8757,
        2773,
        257,
        9866,
        323,
        517,
        39946,
        2685,
        78,
        16485,
        13607,
        13,
        430,
        4869,
        808
      ],
      "temperature": 0,
      "avg_logprob": -0.23900264940763774,
      "compression_ratio": 1.6422413793103448,
      "no_speech_prob": 3.1249879128836255e-8
    },
    {
      "id": 194,
      "seek": 111464,
      "start": 1129.1200000000001,
      "end": 1134.48,
      "text": " abbiamo detto, come ha detto Leonardo, ci sono questi problemi del tipo che il dimensionamento",
      "tokens": [
        22815,
        41031,
        11,
        808,
        324,
        41031,
        36523,
        11,
        6983,
        9259,
        29729,
        1154,
        72,
        1103,
        9746,
        947,
        1930,
        10139,
        8824
      ],
      "temperature": 0,
      "avg_logprob": -0.23900264940763774,
      "compression_ratio": 1.6422413793103448,
      "no_speech_prob": 3.1249879128836255e-8
    },
    {
      "id": 195,
      "seek": 111464,
      "start": 1134.48,
      "end": 1140.14,
      "text": " delle lambda è fatto in questo modo proporzionale in cui più aumenti la memoria più aumenta",
      "tokens": [
        16485,
        13607,
        4873,
        23228,
        294,
        10263,
        16664,
        41516,
        89,
        313,
        1220,
        294,
        22929,
        10589,
        17128,
        72,
        635,
        1334,
        8172,
        10589,
        17128,
        64
      ],
      "temperature": 0,
      "avg_logprob": -0.23900264940763774,
      "compression_ratio": 1.6422413793103448,
      "no_speech_prob": 3.1249879128836255e-8
    },
    {
      "id": 196,
      "seek": 114014,
      "start": 1140.14,
      "end": 1146.44,
      "text": " la CPU, questo probabilmente per un discorso interno di come vengono dimensionate le lambda",
      "tokens": [
        635,
        13199,
        11,
        10263,
        31959,
        4082,
        680,
        517,
        2983,
        284,
        539,
        728,
        1771,
        1026,
        808,
        371,
        1501,
        8957,
        10139,
        473,
        476,
        13607
      ],
      "temperature": 0,
      "avg_logprob": -0.22372206266935882,
      "compression_ratio": 1.5423728813559323,
      "no_speech_prob": 1.1496189777915333e-8
    },
    {
      "id": 197,
      "seek": 114014,
      "start": 1146.44,
      "end": 1153.1200000000001,
      "text": " e a lato pratico questa è una leaky abstraction, nel senso che una decisione tecnica di AWS",
      "tokens": [
        308,
        257,
        287,
        2513,
        33852,
        78,
        16540,
        4873,
        2002,
        476,
        15681,
        37765,
        11,
        15373,
        3151,
        539,
        947,
        2002,
        3537,
        68,
        20105,
        2262,
        1026,
        17650
      ],
      "temperature": 0,
      "avg_logprob": -0.22372206266935882,
      "compression_ratio": 1.5423728813559323,
      "no_speech_prob": 1.1496189777915333e-8
    },
    {
      "id": 198,
      "seek": 114014,
      "start": 1153.1200000000001,
      "end": 1161.2800000000002,
      "text": " può influire sull'esperienza che l'utente ha e limita le scelte dell'utente. Altri esempi",
      "tokens": [
        26526,
        4015,
        621,
        459,
        285,
        6,
        34698,
        42331,
        947,
        287,
        6,
        325,
        1576,
        324,
        308,
        2364,
        2786,
        476,
        795,
        338,
        975,
        19781,
        6,
        325,
        1576,
        13,
        15992,
        470,
        32340,
        72
      ],
      "temperature": 0,
      "avg_logprob": -0.22372206266935882,
      "compression_ratio": 1.5423728813559323,
      "no_speech_prob": 1.1496189777915333e-8
    },
    {
      "id": 199,
      "seek": 114014,
      "start": 1161.2800000000002,
      "end": 1167.68,
      "text": " banali, ci sono dei limiti su quante lambda concorrenti possono esistere in una regione,",
      "tokens": [
        5643,
        5103,
        11,
        6983,
        9259,
        13874,
        4948,
        72,
        459,
        421,
        2879,
        13607,
        1588,
        284,
        1753,
        72,
        43857,
        785,
        468,
        323,
        294,
        2002,
        4458,
        68,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.22372206266935882,
      "compression_ratio": 1.5423728813559323,
      "no_speech_prob": 1.1496189777915333e-8
    },
    {
      "id": 200,
      "seek": 116768,
      "start": 1167.68,
      "end": 1174.6000000000001,
      "text": " in un account in un determinato momento, potresti incorrere in un problema nel quale se hai",
      "tokens": [
        294,
        517,
        2696,
        294,
        517,
        15957,
        2513,
        9333,
        11,
        1847,
        4149,
        72,
        7121,
        81,
        323,
        294,
        517,
        12395,
        15373,
        421,
        1220,
        369,
        21822
      ],
      "temperature": 0,
      "avg_logprob": -0.23630105881463914,
      "compression_ratio": 1.7451737451737452,
      "no_speech_prob": 6.023572041158332e-8
    },
    {
      "id": 201,
      "seek": 116768,
      "start": 1174.6000000000001,
      "end": 1178.88,
      "text": " tantissime lambda, in un determinato momento una lambda non può partire perché non c'è",
      "tokens": [
        12095,
        891,
        1312,
        13607,
        11,
        294,
        517,
        15957,
        2513,
        9333,
        2002,
        13607,
        2107,
        26526,
        644,
        621,
        14303,
        2107,
        269,
        6,
        1462
      ],
      "temperature": 0,
      "avg_logprob": -0.23630105881463914,
      "compression_ratio": 1.7451737451737452,
      "no_speech_prob": 6.023572041158332e-8
    },
    {
      "id": 202,
      "seek": 116768,
      "start": 1178.88,
      "end": 1184.28,
      "text": " abbastanza capacità in quell'account e quella regione e quello ti può portare a altre soluzioni",
      "tokens": [
        16903,
        525,
        20030,
        4637,
        12445,
        294,
        631,
        285,
        6,
        8476,
        792,
        308,
        32234,
        4458,
        68,
        308,
        22813,
        8757,
        26526,
        2436,
        543,
        257,
        34983,
        1404,
        3334,
        15273
      ],
      "temperature": 0,
      "avg_logprob": -0.23630105881463914,
      "compression_ratio": 1.7451737451737452,
      "no_speech_prob": 6.023572041158332e-8
    },
    {
      "id": 203,
      "seek": 116768,
      "start": 1184.28,
      "end": 1189,
      "text": " anche un po' paradossali del tipo ok allora riservo questa lambda e la tengo sempre lì",
      "tokens": [
        11585,
        517,
        714,
        6,
        13480,
        772,
        5103,
        1103,
        9746,
        3133,
        44141,
        2253,
        1978,
        78,
        16540,
        13607,
        308,
        635,
        13989,
        9553,
        287,
        4749
      ],
      "temperature": 0,
      "avg_logprob": -0.23630105881463914,
      "compression_ratio": 1.7451737451737452,
      "no_speech_prob": 6.023572041158332e-8
    },
    {
      "id": 204,
      "seek": 116768,
      "start": 1189,
      "end": 1194.04,
      "text": " pronta a partire, il che significa che tu un oggetto che è stato pensato per essere",
      "tokens": [
        582,
        45442,
        257,
        644,
        621,
        11,
        1930,
        947,
        19957,
        947,
        2604,
        517,
        5360,
        847,
        1353,
        947,
        4873,
        29657,
        6099,
        2513,
        680,
        19799
      ],
      "temperature": 0,
      "avg_logprob": -0.23630105881463914,
      "compression_ratio": 1.7451737451737452,
      "no_speech_prob": 6.023572041158332e-8
    },
    {
      "id": 205,
      "seek": 119404,
      "start": 1194.04,
      "end": 1200.36,
      "text": " super scalabile on demand e ti costa pure relativamente tanto se pensi che lo tieni",
      "tokens": [
        1687,
        15664,
        33288,
        322,
        4733,
        308,
        8757,
        2063,
        64,
        6075,
        21960,
        3439,
        10331,
        369,
        6099,
        72,
        947,
        450,
        4902,
        72
      ],
      "temperature": 0,
      "avg_logprob": -0.2063292745333999,
      "compression_ratio": 1.6509090909090909,
      "no_speech_prob": 2.9818846059015414e-8
    },
    {
      "id": 206,
      "seek": 119404,
      "start": 1200.36,
      "end": 1207.84,
      "text": " sempre lì ad eseguire, ti ritrovi quasi costretto a doverlo tenere sempre lì attivo semplicemente",
      "tokens": [
        9553,
        287,
        4749,
        614,
        785,
        1146,
        43612,
        11,
        8757,
        11289,
        340,
        4917,
        20954,
        2063,
        1505,
        1353,
        257,
        360,
        331,
        752,
        2064,
        323,
        9553,
        287,
        4749,
        951,
        6340,
        4361,
        4770,
        16288
      ],
      "temperature": 0,
      "avg_logprob": -0.2063292745333999,
      "compression_ratio": 1.6509090909090909,
      "no_speech_prob": 2.9818846059015414e-8
    },
    {
      "id": 207,
      "seek": 119404,
      "start": 1207.84,
      "end": 1212.6,
      "text": " per riservare quella concorrenza che sennò potrebbe essere rubata da altre lambda. Quindi",
      "tokens": [
        680,
        2253,
        1978,
        543,
        32234,
        1588,
        284,
        1095,
        2394,
        947,
        262,
        1857,
        4293,
        1847,
        39487,
        19799,
        5915,
        3274,
        1120,
        34983,
        13607,
        13,
        32534
      ],
      "temperature": 0,
      "avg_logprob": -0.2063292745333999,
      "compression_ratio": 1.6509090909090909,
      "no_speech_prob": 2.9818846059015414e-8
    },
    {
      "id": 208,
      "seek": 119404,
      "start": 1212.6,
      "end": 1217.6,
      "text": " ci sono tutta una serie di dettagli tecnici che adesso sto pure un po' estremizzando perché",
      "tokens": [
        6983,
        9259,
        3672,
        1328,
        2002,
        23030,
        1026,
        1141,
        25030,
        2081,
        535,
        66,
        7692,
        72,
        947,
        39552,
        22784,
        6075,
        517,
        714,
        6,
        871,
        2579,
        8072,
        1806,
        14303
      ],
      "temperature": 0,
      "avg_logprob": -0.2063292745333999,
      "compression_ratio": 1.6509090909090909,
      "no_speech_prob": 2.9818846059015414e-8
    },
    {
      "id": 209,
      "seek": 119404,
      "start": 1217.6,
      "end": 1221.6399999999999,
      "text": " a lato pratico se non si arriva a una certa scala questi problemi non sono neanche dei",
      "tokens": [
        257,
        287,
        2513,
        33852,
        78,
        369,
        2107,
        1511,
        3399,
        2757,
        257,
        2002,
        44438,
        795,
        5159,
        29729,
        1154,
        72,
        2107,
        9259,
        408,
        22806,
        13874
      ],
      "temperature": 0,
      "avg_logprob": -0.2063292745333999,
      "compression_ratio": 1.6509090909090909,
      "no_speech_prob": 2.9818846059015414e-8
    },
    {
      "id": 210,
      "seek": 122164,
      "start": 1221.64,
      "end": 1227.2,
      "text": " problemi così così forti però è vero pure che se vai a costruire un'architettura complessa",
      "tokens": [
        1154,
        72,
        23278,
        23278,
        5009,
        72,
        12673,
        4873,
        1306,
        78,
        6075,
        947,
        369,
        4405,
        257,
        2063,
        894,
        621,
        517,
        6,
        1178,
        270,
        3093,
        2991,
        1209,
        8391
      ],
      "temperature": 0,
      "avg_logprob": -0.17661726022068458,
      "compression_ratio": 1.4473684210526316,
      "no_speech_prob": 2.286290445852046e-8
    },
    {
      "id": 211,
      "seek": 122164,
      "start": 1227.2,
      "end": 1233,
      "text": " quella promessa di serverless che ti dava meno rogne tecniche in realtà diventa sempre",
      "tokens": [
        32234,
        2234,
        8391,
        1026,
        7154,
        1832,
        947,
        8757,
        274,
        4061,
        40236,
        744,
        70,
        716,
        20105,
        9304,
        294,
        47512,
        3414,
        8938,
        9553
      ],
      "temperature": 0,
      "avg_logprob": -0.17661726022068458,
      "compression_ratio": 1.4473684210526316,
      "no_speech_prob": 2.286290445852046e-8
    },
    {
      "id": 212,
      "seek": 122164,
      "start": 1233,
      "end": 1241.24,
      "text": " più debole. Posso farti però una provocazione basata su un tuo blog post recentissimo dove",
      "tokens": [
        10589,
        368,
        1763,
        306,
        13,
        25906,
        539,
        24575,
        72,
        12673,
        2002,
        1439,
        24035,
        19706,
        987,
        3274,
        459,
        517,
        45352,
        6968,
        2183,
        5162,
        34966,
        23287
      ],
      "temperature": 0,
      "avg_logprob": -0.17661726022068458,
      "compression_ratio": 1.4473684210526316,
      "no_speech_prob": 2.286290445852046e-8
    },
    {
      "id": 213,
      "seek": 124124,
      "start": 1241.24,
      "end": 1253,
      "text": " spiegavi qualcosa relativo a S3, gli upload, le signature e quant'altro. Nel tuo ragionamento,",
      "tokens": [
        637,
        20408,
        18442,
        42400,
        1039,
        18586,
        257,
        318,
        18,
        11,
        17161,
        6580,
        11,
        476,
        13397,
        308,
        4426,
        6,
        47484,
        13,
        426,
        338,
        45352,
        17539,
        313,
        8824,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.256033058626106,
      "compression_ratio": 1.4944444444444445,
      "no_speech_prob": 1.914284553095058e-7
    },
    {
      "id": 214,
      "seek": 124124,
      "start": 1253,
      "end": 1258.68,
      "text": " almeno quello che hai fatto adesso, forse non stiamo, ed è un problema che ho anch'io,",
      "tokens": [
        419,
        43232,
        22813,
        947,
        21822,
        23228,
        39552,
        11,
        337,
        405,
        2107,
        342,
        7415,
        11,
        1257,
        4873,
        517,
        12395,
        947,
        1106,
        12723,
        6,
        1004,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.256033058626106,
      "compression_ratio": 1.4944444444444445,
      "no_speech_prob": 1.914284553095058e-7
    },
    {
      "id": 215,
      "seek": 124124,
      "start": 1258.68,
      "end": 1265.68,
      "text": " forse non stiamo rischiando di perdere di vista quella che è la vera utilità, quello",
      "tokens": [
        337,
        405,
        2107,
        342,
        7415,
        2253,
        339,
        952,
        2595,
        1026,
        12611,
        323,
        1026,
        22553,
        32234,
        947,
        4873,
        635,
        1306,
        64,
        4976,
        12445,
        11,
        22813
      ],
      "temperature": 0,
      "avg_logprob": -0.256033058626106,
      "compression_ratio": 1.4944444444444445,
      "no_speech_prob": 1.914284553095058e-7
    },
    {
      "id": 216,
      "seek": 126568,
      "start": 1265.68,
      "end": 1272.1200000000001,
      "text": " che è il motivo per cui dovremmo utilizzare le lambda. Hai detto bene, se io riservo",
      "tokens": [
        947,
        4873,
        1930,
        35804,
        680,
        22929,
        30870,
        265,
        2174,
        78,
        40355,
        543,
        476,
        13607,
        13,
        24055,
        41031,
        2537,
        11,
        369,
        19785,
        2253,
        1978,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.23302309329693133,
      "compression_ratio": 1.6129032258064515,
      "no_speech_prob": 9.988061933086101e-9
    },
    {
      "id": 217,
      "seek": 126568,
      "start": 1272.1200000000001,
      "end": 1281.44,
      "text": " una lambda vuol dire che o non ho capito una cipa di come funzionano le lambda oppure ho",
      "tokens": [
        2002,
        13607,
        9732,
        401,
        1264,
        947,
        277,
        2107,
        1106,
        1410,
        3528,
        2002,
        269,
        647,
        64,
        1026,
        808,
        49345,
        313,
        3730,
        476,
        13607,
        1458,
        540,
        1106
      ],
      "temperature": 0,
      "avg_logprob": -0.23302309329693133,
      "compression_ratio": 1.6129032258064515,
      "no_speech_prob": 9.988061933086101e-9
    },
    {
      "id": 218,
      "seek": 126568,
      "start": 1281.44,
      "end": 1288.44,
      "text": " pensato di utilizzare una chiave inglese anche per mettere i chiodi nel muro e questo ci",
      "tokens": [
        6099,
        2513,
        1026,
        40355,
        543,
        2002,
        45793,
        303,
        3957,
        904,
        68,
        11585,
        680,
        27812,
        323,
        741,
        417,
        2695,
        72,
        15373,
        2992,
        340,
        308,
        10263,
        6983
      ],
      "temperature": 0,
      "avg_logprob": -0.23302309329693133,
      "compression_ratio": 1.6129032258064515,
      "no_speech_prob": 9.988061933086101e-9
    },
    {
      "id": 219,
      "seek": 126568,
      "start": 1288.44,
      "end": 1294.44,
      "text": " sta quando c'è un team complesso, quando gli devi fare una formazione ed è difficile",
      "tokens": [
        11135,
        7770,
        269,
        6,
        1462,
        517,
        1469,
        1209,
        5557,
        11,
        7770,
        17161,
        31219,
        11994,
        2002,
        1254,
        12928,
        1257,
        4873,
        26607
      ],
      "temperature": 0,
      "avg_logprob": -0.23302309329693133,
      "compression_ratio": 1.6129032258064515,
      "no_speech_prob": 9.988061933086101e-9
    },
    {
      "id": 220,
      "seek": 129444,
      "start": 1294.44,
      "end": 1299.3600000000001,
      "text": " insegnargli o fare una certa pipeline per il deploy o per l'uso di Fargate o per l'uso",
      "tokens": [
        33874,
        4568,
        33544,
        2081,
        277,
        11994,
        2002,
        44438,
        15517,
        680,
        1930,
        7274,
        277,
        680,
        287,
        6,
        24431,
        1026,
        9067,
        22514,
        277,
        680,
        287,
        6,
        24431
      ],
      "temperature": 0,
      "avg_logprob": -0.26755625792223997,
      "compression_ratio": 1.568888888888889,
      "no_speech_prob": 1.4677341653168696e-7
    },
    {
      "id": 221,
      "seek": 129444,
      "start": 1299.3600000000001,
      "end": 1306.44,
      "text": " di Kubernetes o per altre cose, quindi ci sta. Però il problema non viene per esempio dal",
      "tokens": [
        1026,
        23145,
        277,
        680,
        34983,
        30261,
        11,
        15727,
        6983,
        11135,
        13,
        20533,
        1930,
        12395,
        2107,
        19561,
        680,
        33627,
        11702
      ],
      "temperature": 0,
      "avg_logprob": -0.26755625792223997,
      "compression_ratio": 1.568888888888889,
      "no_speech_prob": 1.4677341653168696e-7
    },
    {
      "id": 222,
      "seek": 129444,
      "start": 1306.44,
      "end": 1310.92,
      "text": " utilizzare uno strumento che non è pensato per quello in un contesto specifico e te",
      "tokens": [
        40355,
        543,
        8526,
        1056,
        2206,
        78,
        947,
        2107,
        4873,
        6099,
        2513,
        680,
        22813,
        294,
        517,
        10287,
        78,
        2685,
        78,
        308,
        535
      ],
      "temperature": 0,
      "avg_logprob": -0.26755625792223997,
      "compression_ratio": 1.568888888888889,
      "no_speech_prob": 1.4677341653168696e-7
    },
    {
      "id": 223,
      "seek": 129444,
      "start": 1310.92,
      "end": 1317.16,
      "text": " lo dico perché vengo con l'esperienza che mi arriva da mia moglie dove in alcune pipeline",
      "tokens": [
        450,
        274,
        2789,
        14303,
        371,
        30362,
        416,
        287,
        6,
        34698,
        42331,
        947,
        2752,
        3399,
        2757,
        1120,
        21290,
        13172,
        6302,
        23287,
        294,
        20005,
        2613,
        15517
      ],
      "temperature": 0,
      "avg_logprob": -0.26755625792223997,
      "compression_ratio": 1.568888888888889,
      "no_speech_prob": 1.4677341653168696e-7
    },
    {
      "id": 224,
      "seek": 131716,
      "start": 1317.16,
      "end": 1325.8000000000002,
      "text": " di big data ho visto usare le lambda e ho detto no amico mio forse in questo caso non",
      "tokens": [
        1026,
        955,
        1412,
        1106,
        17558,
        505,
        543,
        476,
        13607,
        308,
        1106,
        41031,
        572,
        669,
        2789,
        29908,
        337,
        405,
        294,
        10263,
        9666,
        2107
      ],
      "temperature": 0,
      "avg_logprob": -0.2906939697265625,
      "compression_ratio": 1.48,
      "no_speech_prob": 6.023569909530124e-8
    },
    {
      "id": 225,
      "seek": 131716,
      "start": 1325.8000000000002,
      "end": 1333.8000000000002,
      "text": " è lo strumento giusto delle lambda utilizzate e accese per un sacco di tempo che comunque",
      "tokens": [
        4873,
        450,
        1056,
        2206,
        78,
        1735,
        48260,
        16485,
        13607,
        40355,
        473,
        308,
        35707,
        68,
        680,
        517,
        4899,
        1291,
        1026,
        8972,
        947,
        45736
      ],
      "temperature": 0,
      "avg_logprob": -0.2906939697265625,
      "compression_ratio": 1.48,
      "no_speech_prob": 6.023569909530124e-8
    },
    {
      "id": 226,
      "seek": 131716,
      "start": 1333.8000000000002,
      "end": 1340.24,
      "text": " venivano richiamate in modo che si riduce il cold start, delle cose un po' tricky.",
      "tokens": [
        6138,
        592,
        3730,
        4593,
        2918,
        473,
        294,
        16664,
        947,
        1511,
        3973,
        4176,
        1930,
        3554,
        722,
        11,
        16485,
        30261,
        517,
        714,
        6,
        12414,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2906939697265625,
      "compression_ratio": 1.48,
      "no_speech_prob": 6.023569909530124e-8
    },
    {
      "id": 227,
      "seek": 134024,
      "start": 1340.24,
      "end": 1350.36,
      "text": " Concordo assolutamente e da una parte secondo me va pure fatta la chiarezza su cosa noi",
      "tokens": [
        18200,
        23872,
        1256,
        2308,
        3439,
        308,
        1120,
        2002,
        6975,
        41601,
        385,
        2773,
        6075,
        4046,
        1328,
        635,
        13228,
        543,
        26786,
        459,
        10163,
        22447
      ],
      "temperature": 0,
      "avg_logprob": -0.2446612144003109,
      "compression_ratio": 1.6367713004484306,
      "no_speech_prob": 2.3588638597971112e-8
    },
    {
      "id": 228,
      "seek": 134024,
      "start": 1350.36,
      "end": 1354.84,
      "text": " intendiamo per serverless perché ci stiamo concentrando molto su lambda ma lambda è solo",
      "tokens": [
        19759,
        7415,
        680,
        7154,
        1832,
        14303,
        6983,
        342,
        7415,
        5512,
        19845,
        16394,
        459,
        13607,
        463,
        13607,
        4873,
        6944
      ],
      "temperature": 0,
      "avg_logprob": -0.2446612144003109,
      "compression_ratio": 1.6367713004484306,
      "no_speech_prob": 2.3588638597971112e-8
    },
    {
      "id": 229,
      "seek": 134024,
      "start": 1354.84,
      "end": 1359.6,
      "text": " diciamo una parte di quello che viene definito serverless, però sono perfettamente d'accordo",
      "tokens": [
        14285,
        7415,
        2002,
        6975,
        1026,
        22813,
        947,
        19561,
        1561,
        3528,
        7154,
        1832,
        11,
        12673,
        9259,
        13826,
        3093,
        3439,
        274,
        6,
        19947,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.2446612144003109,
      "compression_ratio": 1.6367713004484306,
      "no_speech_prob": 2.3588638597971112e-8
    },
    {
      "id": 230,
      "seek": 134024,
      "start": 1359.6,
      "end": 1366.96,
      "text": " che lambda in sé come astrazione di compute non è adeguata per tutti i casi d'uso e spesso",
      "tokens": [
        947,
        13607,
        294,
        7910,
        808,
        5357,
        424,
        19706,
        1026,
        14722,
        2107,
        4873,
        614,
        1146,
        84,
        3274,
        680,
        19822,
        741,
        22567,
        274,
        6,
        24431,
        308,
        637,
        5557
      ],
      "temperature": 0,
      "avg_logprob": -0.2446612144003109,
      "compression_ratio": 1.6367713004484306,
      "no_speech_prob": 2.3588638597971112e-8
    },
    {
      "id": 231,
      "seek": 136696,
      "start": 1366.96,
      "end": 1372.68,
      "text": " si fa quest'errore di andare a dire voglio essere serverless first o serverless 100%",
      "tokens": [
        1511,
        2050,
        866,
        6,
        260,
        340,
        265,
        1026,
        42742,
        257,
        1264,
        31273,
        19987,
        19799,
        7154,
        1832,
        700,
        277,
        7154,
        1832,
        2319,
        4
      ],
      "temperature": 0,
      "avg_logprob": -0.1914058564201234,
      "compression_ratio": 1.6526717557251909,
      "no_speech_prob": 1.7529590223830382e-8
    },
    {
      "id": 232,
      "seek": 136696,
      "start": 1372.68,
      "end": 1376.92,
      "text": " quindi qualsiasi caso d'uso lo devo risolvere con le lambda e lì poi ti ritrovi a dover",
      "tokens": [
        15727,
        421,
        1124,
        4609,
        72,
        9666,
        274,
        6,
        24431,
        450,
        49717,
        2253,
        401,
        5887,
        416,
        476,
        13607,
        308,
        287,
        4749,
        19260,
        8757,
        11289,
        340,
        4917,
        257,
        360,
        331
      ],
      "temperature": 0,
      "avg_logprob": -0.1914058564201234,
      "compression_ratio": 1.6526717557251909,
      "no_speech_prob": 1.7529590223830382e-8
    },
    {
      "id": 233,
      "seek": 136696,
      "start": 1376.92,
      "end": 1381.96,
      "text": " fare tutta una serie di cose che magari riesci a risolvere il problema però ti ritrovi a",
      "tokens": [
        11994,
        3672,
        1328,
        2002,
        23030,
        1026,
        30261,
        947,
        49932,
        23932,
        537,
        257,
        2253,
        401,
        5887,
        1930,
        12395,
        12673,
        8757,
        11289,
        340,
        4917,
        257
      ],
      "temperature": 0,
      "avg_logprob": -0.1914058564201234,
      "compression_ratio": 1.6526717557251909,
      "no_speech_prob": 1.7529590223830382e-8
    },
    {
      "id": 234,
      "seek": 136696,
      "start": 1381.96,
      "end": 1387.16,
      "text": " fare qualcosa che non è assolutamente ottimale per quel tipo di applicazione.",
      "tokens": [
        11994,
        42400,
        947,
        2107,
        4873,
        1256,
        2308,
        3439,
        4337,
        31208,
        1220,
        680,
        7178,
        9746,
        1026,
        2580,
        12928,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.1914058564201234,
      "compression_ratio": 1.6526717557251909,
      "no_speech_prob": 1.7529590223830382e-8
    },
    {
      "id": 235,
      "seek": 136696,
      "start": 1387.16,
      "end": 1395.44,
      "text": " Hai detto un'altra cosa interessante che andremo ad analizzare dopo che tutto l'ecosistema",
      "tokens": [
        24055,
        41031,
        517,
        6,
        38865,
        10163,
        24372,
        947,
        293,
        44172,
        614,
        2624,
        8072,
        543,
        35196,
        947,
        23048,
        287,
        6,
        3045,
        329,
        468,
        5619
      ],
      "temperature": 0,
      "avg_logprob": -0.1914058564201234,
      "compression_ratio": 1.6526717557251909,
      "no_speech_prob": 1.7529590223830382e-8
    },
    {
      "id": 236,
      "seek": 139544,
      "start": 1395.44,
      "end": 1401.04,
      "text": " serverless quindi non solo lambda però ho visto un dittino muoversi da Luca volevi dire",
      "tokens": [
        7154,
        1832,
        15727,
        2107,
        6944,
        13607,
        12673,
        1106,
        17558,
        517,
        274,
        593,
        2982,
        2992,
        25348,
        72,
        1120,
        42076,
        49877,
        4917,
        1264
      ],
      "temperature": 0,
      "avg_logprob": -0.26661267961774554,
      "compression_ratio": 1.6033755274261603,
      "no_speech_prob": 4.450836286196136e-7
    },
    {
      "id": 237,
      "seek": 139544,
      "start": 1401.04,
      "end": 1402.04,
      "text": " qualcosa?",
      "tokens": [
        42400,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.26661267961774554,
      "compression_ratio": 1.6033755274261603,
      "no_speech_prob": 4.450836286196136e-7
    },
    {
      "id": 238,
      "seek": 139544,
      "start": 1402.04,
      "end": 1410.04,
      "text": " No certo stavo pensando alla difficoltà di non inserire pioli tondi in buchi quadrati",
      "tokens": [
        883,
        22261,
        342,
        25713,
        34525,
        11591,
        2204,
        4837,
        1467,
        1026,
        2107,
        1028,
        260,
        621,
        3895,
        9384,
        256,
        684,
        72,
        294,
        272,
        30026,
        10787,
        4481,
        72
      ],
      "temperature": 0,
      "avg_logprob": -0.26661267961774554,
      "compression_ratio": 1.6033755274261603,
      "no_speech_prob": 4.450836286196136e-7
    },
    {
      "id": 239,
      "seek": 139544,
      "start": 1410.04,
      "end": 1417.8,
      "text": " come come mi piace dire però anche questo vuol dire dover comunque studiare molto approfonditamente",
      "tokens": [
        808,
        808,
        2752,
        50062,
        1264,
        12673,
        11585,
        10263,
        9732,
        401,
        1264,
        360,
        331,
        45736,
        972,
        72,
        543,
        16394,
        2075,
        69,
        684,
        270,
        3439
      ],
      "temperature": 0,
      "avg_logprob": -0.26661267961774554,
      "compression_ratio": 1.6033755274261603,
      "no_speech_prob": 4.450836286196136e-7
    },
    {
      "id": 240,
      "seek": 139544,
      "start": 1417.8,
      "end": 1423.68,
      "text": " quello che è l'ecosistema serverless quello che AWS offre o quello che google cloud platform",
      "tokens": [
        22813,
        947,
        4873,
        287,
        6,
        3045,
        329,
        468,
        5619,
        7154,
        1832,
        22813,
        947,
        17650,
        766,
        265,
        277,
        22813,
        947,
        20742,
        4588,
        3663
      ],
      "temperature": 0,
      "avg_logprob": -0.26661267961774554,
      "compression_ratio": 1.6033755274261603,
      "no_speech_prob": 4.450836286196136e-7
    },
    {
      "id": 241,
      "seek": 142368,
      "start": 1423.68,
      "end": 1432.8400000000001,
      "text": " offre e così via e quindi di nuovo viene un po' meno quella promessa che dice devi pensare",
      "tokens": [
        766,
        265,
        308,
        23278,
        5766,
        308,
        15727,
        1026,
        49348,
        19561,
        517,
        714,
        6,
        40236,
        32234,
        2234,
        8391,
        947,
        10313,
        31219,
        6099,
        543
      ],
      "temperature": 0,
      "avg_logprob": -0.2607805078679865,
      "compression_ratio": 1.5588235294117647,
      "no_speech_prob": 7.979928540180481e-8
    },
    {
      "id": 242,
      "seek": 142368,
      "start": 1432.8400000000001,
      "end": 1436.8400000000001,
      "text": " soltanto al tuo domino, alla tua business logic.",
      "tokens": [
        1404,
        83,
        5857,
        419,
        45352,
        3285,
        2982,
        11,
        11591,
        33578,
        1606,
        9952,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2607805078679865,
      "compression_ratio": 1.5588235294117647,
      "no_speech_prob": 7.979928540180481e-8
    },
    {
      "id": 243,
      "seek": 142368,
      "start": 1436.8400000000001,
      "end": 1441.68,
      "text": " Questo lo sto vivendo proprio nella mia pelle proprio perché io comunque c'ho anche un",
      "tokens": [
        38167,
        450,
        22784,
        11005,
        3999,
        28203,
        23878,
        21290,
        520,
        2447,
        28203,
        14303,
        19785,
        45736,
        269,
        6,
        1289,
        11585,
        517
      ],
      "temperature": 0,
      "avg_logprob": -0.2607805078679865,
      "compression_ratio": 1.5588235294117647,
      "no_speech_prob": 7.979928540180481e-8
    },
    {
      "id": 244,
      "seek": 142368,
      "start": 1441.68,
      "end": 1448.3,
      "text": " caso d'uso semplice però anche solo proprio perché voglio evitare di usare lo strumento",
      "tokens": [
        9666,
        274,
        6,
        24431,
        4361,
        564,
        573,
        12673,
        11585,
        6944,
        28203,
        14303,
        31273,
        19987,
        1073,
        270,
        543,
        1026,
        505,
        543,
        450,
        1056,
        2206,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.2607805078679865,
      "compression_ratio": 1.5588235294117647,
      "no_speech_prob": 7.979928540180481e-8
    },
    {
      "id": 245,
      "seek": 144830,
      "start": 1448.3,
      "end": 1459.44,
      "text": " sbagliato nel posto sbagliato io attualmente non sto pensando alla business logic sto pensando",
      "tokens": [
        262,
        17282,
        2081,
        2513,
        15373,
        2183,
        78,
        262,
        17282,
        2081,
        2513,
        19785,
        951,
        901,
        4082,
        2107,
        22784,
        34525,
        11591,
        1606,
        9952,
        22784,
        34525
      ],
      "temperature": 0,
      "avg_logprob": -0.2459780904981825,
      "compression_ratio": 1.6013071895424837,
      "no_speech_prob": 3.7694498189466685e-8
    },
    {
      "id": 246,
      "seek": 144830,
      "start": 1459.44,
      "end": 1468.12,
      "text": " a dove infilare i pioli sostanzialmente e quindi no niente appunto speravo sto cercando",
      "tokens": [
        257,
        23287,
        1536,
        388,
        543,
        741,
        3895,
        9384,
        41585,
        3910,
        831,
        4082,
        308,
        15727,
        572,
        297,
        8413,
        724,
        24052,
        24152,
        25713,
        22784,
        36099,
        1806
      ],
      "temperature": 0,
      "avg_logprob": -0.2459780904981825,
      "compression_ratio": 1.6013071895424837,
      "no_speech_prob": 3.7694498189466685e-8
    },
    {
      "id": 247,
      "seek": 144830,
      "start": 1468.12,
      "end": 1473.3999999999999,
      "text": " risposte le troverò in questa puntata credo anche per questo.",
      "tokens": [
        2253,
        23744,
        68,
        476,
        4495,
        331,
        4293,
        294,
        16540,
        18212,
        3274,
        3864,
        78,
        11585,
        680,
        10263,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2459780904981825,
      "compression_ratio": 1.6013071895424837,
      "no_speech_prob": 3.7694498189466685e-8
    },
    {
      "id": 248,
      "seek": 147340,
      "start": 1473.4,
      "end": 1478.4,
      "text": " Io, Leo volevi dire qualcosa?",
      "tokens": [
        19239,
        11,
        19344,
        49877,
        4917,
        1264,
        42400,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.2762190431028932,
      "compression_ratio": 1.549738219895288,
      "no_speech_prob": 2.757787775919951e-8
    },
    {
      "id": 249,
      "seek": 147340,
      "start": 1478.4,
      "end": 1485.5600000000002,
      "text": " Volevo non so provare a introdurre un argomento o dire una cosa che mi passa per la testa",
      "tokens": [
        691,
        4812,
        3080,
        2107,
        370,
        1439,
        543,
        257,
        560,
        11452,
        374,
        265,
        517,
        3882,
        298,
        15467,
        277,
        1264,
        2002,
        10163,
        947,
        2752,
        23880,
        680,
        635,
        1500,
        64
      ],
      "temperature": 0,
      "avg_logprob": -0.2762190431028932,
      "compression_ratio": 1.549738219895288,
      "no_speech_prob": 2.757787775919951e-8
    },
    {
      "id": 250,
      "seek": 147340,
      "start": 1485.5600000000002,
      "end": 1492,
      "text": " allora il serverless, l'architettura serverless funziona molto bene nei momenti in cui uno",
      "tokens": [
        44141,
        1930,
        7154,
        1832,
        11,
        287,
        6,
        1178,
        270,
        3093,
        2991,
        7154,
        1832,
        49345,
        21758,
        16394,
        2537,
        34517,
        1623,
        72,
        294,
        22929,
        8526
      ],
      "temperature": 0,
      "avg_logprob": -0.2762190431028932,
      "compression_ratio": 1.549738219895288,
      "no_speech_prob": 2.757787775919951e-8
    },
    {
      "id": 251,
      "seek": 147340,
      "start": 1492,
      "end": 1499.2,
      "text": " non conosce la diciamo ha dei picchi non lo so di traffico e quindi non vuole stare a",
      "tokens": [
        2107,
        49892,
        384,
        635,
        14285,
        7415,
        324,
        13874,
        13363,
        8036,
        2107,
        450,
        370,
        1026,
        21073,
        2789,
        308,
        15727,
        2107,
        9732,
        4812,
        22432,
        257
      ],
      "temperature": 0,
      "avg_logprob": -0.2762190431028932,
      "compression_ratio": 1.549738219895288,
      "no_speech_prob": 2.757787775919951e-8
    },
    {
      "id": 252,
      "seek": 149920,
      "start": 1499.2,
      "end": 1509.52,
      "text": " scalare manualmente e lascia fare tutto a AWS ma se un business conosce esattamente",
      "tokens": [
        15664,
        543,
        9688,
        4082,
        308,
        2439,
        2755,
        11994,
        23048,
        257,
        17650,
        463,
        369,
        517,
        1606,
        49892,
        384,
        785,
        1591,
        3439
      ],
      "temperature": 0,
      "avg_logprob": -0.18995078180877256,
      "compression_ratio": 1.4475138121546962,
      "no_speech_prob": 9.72139673649508e-7
    },
    {
      "id": 253,
      "seek": 149920,
      "start": 1509.52,
      "end": 1516.92,
      "text": " il traffico il numero di utenti non ha questi picchi tipo black friday eccetera serverless",
      "tokens": [
        1930,
        21073,
        2789,
        1930,
        46839,
        1026,
        2839,
        23012,
        2107,
        324,
        29729,
        13363,
        8036,
        9746,
        2211,
        431,
        4708,
        29613,
        20269,
        7154,
        1832
      ],
      "temperature": 0,
      "avg_logprob": -0.18995078180877256,
      "compression_ratio": 1.4475138121546962,
      "no_speech_prob": 9.72139673649508e-7
    },
    {
      "id": 254,
      "seek": 149920,
      "start": 1516.92,
      "end": 1524.5,
      "text": " aiuta è funzionale o a quel punto perde la maggior parte del suo vantaggio perché una",
      "tokens": [
        9783,
        12093,
        4873,
        49345,
        313,
        1220,
        277,
        257,
        7178,
        14326,
        44182,
        635,
        44639,
        1973,
        6975,
        1103,
        34197,
        371,
        394,
        30763,
        14303,
        2002
      ],
      "temperature": 0,
      "avg_logprob": -0.18995078180877256,
      "compression_ratio": 1.4475138121546962,
      "no_speech_prob": 9.72139673649508e-7
    },
    {
      "id": 255,
      "seek": 152450,
      "start": 1524.5,
      "end": 1530.36,
      "text": " frase che ho sentito dire un po' di tempo fa in un podcast è enterprises don't use",
      "tokens": [
        38406,
        947,
        1106,
        2279,
        3528,
        1264,
        517,
        714,
        6,
        1026,
        8972,
        2050,
        294,
        517,
        7367,
        4873,
        29034,
        500,
        380,
        764
      ],
      "temperature": 0,
      "avg_logprob": -0.26486239482447044,
      "compression_ratio": 1.7163461538461537,
      "no_speech_prob": 1.1078736861236393e-7
    },
    {
      "id": 256,
      "seek": 152450,
      "start": 1530.36,
      "end": 1536.76,
      "text": " serverless cioè le enterprise le grandi big molloc che sanno esattamente qual è il loro",
      "tokens": [
        7154,
        1832,
        41827,
        476,
        14132,
        476,
        45155,
        955,
        705,
        285,
        905,
        947,
        262,
        13484,
        785,
        1591,
        3439,
        4101,
        4873,
        1930,
        28810
      ],
      "temperature": 0,
      "avg_logprob": -0.26486239482447044,
      "compression_ratio": 1.7163461538461537,
      "no_speech_prob": 1.1078736861236393e-7
    },
    {
      "id": 257,
      "seek": 152450,
      "start": 1536.76,
      "end": 1544.04,
      "text": " traffico non usano il serverless perché conoscono esattamente le risorse di cui hanno bisogno",
      "tokens": [
        21073,
        2789,
        2107,
        505,
        3730,
        1930,
        7154,
        1832,
        14303,
        49892,
        45846,
        785,
        1591,
        3439,
        476,
        2253,
        18699,
        1026,
        22929,
        26595,
        40505,
        1771
      ],
      "temperature": 0,
      "avg_logprob": -0.26486239482447044,
      "compression_ratio": 1.7163461538461537,
      "no_speech_prob": 1.1078736861236393e-7
    },
    {
      "id": 258,
      "seek": 152450,
      "start": 1544.04,
      "end": 1548.72,
      "text": " in quel caso il fatto di non dover gestire i server che non vuol dire attaccare la spina",
      "tokens": [
        294,
        7178,
        9666,
        1930,
        23228,
        1026,
        2107,
        360,
        331,
        7219,
        621,
        741,
        7154,
        947,
        2107,
        9732,
        401,
        1264,
        951,
        326,
        5685,
        635,
        637,
        1426
      ],
      "temperature": 0,
      "avg_logprob": -0.26486239482447044,
      "compression_ratio": 1.7163461538461537,
      "no_speech_prob": 1.1078736861236393e-7
    },
    {
      "id": 259,
      "seek": 154872,
      "start": 1548.72,
      "end": 1560.64,
      "text": " o cambiare il disco andiamo qualche livello sotto ho perso la domanda nel senso come posso",
      "tokens": [
        277,
        19569,
        543,
        1930,
        3622,
        293,
        7415,
        38737,
        1621,
        1913,
        43754,
        1106,
        868,
        78,
        635,
        3285,
        5575,
        15373,
        3151,
        539,
        808,
        22501
      ],
      "temperature": 0,
      "avg_logprob": -0.2664608558019002,
      "compression_ratio": 1.7142857142857142,
      "no_speech_prob": 4.944428422248848e-9
    },
    {
      "id": 260,
      "seek": 154872,
      "start": 1560.64,
      "end": 1564.6000000000001,
      "text": " dire se uno conosce esattamente le capacità di cui ha bisogno ha bisogno di serverless",
      "tokens": [
        1264,
        369,
        8526,
        49892,
        384,
        785,
        1591,
        3439,
        476,
        4637,
        12445,
        1026,
        22929,
        324,
        40505,
        1771,
        324,
        40505,
        1771,
        1026,
        7154,
        1832
      ],
      "temperature": 0,
      "avg_logprob": -0.2664608558019002,
      "compression_ratio": 1.7142857142857142,
      "no_speech_prob": 4.944428422248848e-9
    },
    {
      "id": 261,
      "seek": 154872,
      "start": 1564.6000000000001,
      "end": 1569.6000000000001,
      "text": " o gli basta prendere un on-premise con quelle capacità di cui conosce le dimensioni",
      "tokens": [
        277,
        17161,
        45282,
        9866,
        323,
        517,
        322,
        12,
        29403,
        908,
        416,
        29237,
        4637,
        12445,
        1026,
        22929,
        49892,
        384,
        476,
        10139,
        72
      ],
      "temperature": 0,
      "avg_logprob": -0.2664608558019002,
      "compression_ratio": 1.7142857142857142,
      "no_speech_prob": 4.944428422248848e-9
    },
    {
      "id": 262,
      "seek": 154872,
      "start": 1569.6000000000001,
      "end": 1575.56,
      "text": " no questa è un'ottima domanda che spesso è un qualcosa di cui discutiamo anche con",
      "tokens": [
        572,
        16540,
        4873,
        517,
        6,
        1521,
        4775,
        3285,
        5575,
        947,
        637,
        5557,
        4873,
        517,
        42400,
        1026,
        22929,
        42085,
        7415,
        11585,
        416
      ],
      "temperature": 0,
      "avg_logprob": -0.2664608558019002,
      "compression_ratio": 1.7142857142857142,
      "no_speech_prob": 4.944428422248848e-9
    },
    {
      "id": 263,
      "seek": 157556,
      "start": 1575.56,
      "end": 1582.84,
      "text": " i nostri clienti e non è mai diciamo una decisione binaria ovvia o si serve le siano",
      "tokens": [
        741,
        10397,
        470,
        6423,
        72,
        308,
        2107,
        4873,
        12698,
        14285,
        7415,
        2002,
        3537,
        68,
        5171,
        9831,
        14187,
        11617,
        277,
        1511,
        4596,
        476,
        262,
        6254
      ],
      "temperature": 0,
      "avg_logprob": -0.25695496196894685,
      "compression_ratio": 1.7598425196850394,
      "no_speech_prob": 1.4307204310171073e-8
    },
    {
      "id": 264,
      "seek": 157556,
      "start": 1582.84,
      "end": 1588.04,
      "text": " perché secondo me bisogna un po chiarire quali sono i vantaggi di serverless nel senso",
      "tokens": [
        14303,
        41601,
        385,
        40505,
        629,
        517,
        714,
        47454,
        621,
        4101,
        72,
        9259,
        741,
        371,
        394,
        46893,
        1026,
        7154,
        1832,
        15373,
        3151,
        539
      ],
      "temperature": 0,
      "avg_logprob": -0.25695496196894685,
      "compression_ratio": 1.7598425196850394,
      "no_speech_prob": 1.4307204310171073e-8
    },
    {
      "id": 265,
      "seek": 157556,
      "start": 1588.04,
      "end": 1593.8799999999999,
      "text": " che non sempre un vantaggio di costo come magari se fatta molta enfasi soprattutto all'inizio",
      "tokens": [
        947,
        2107,
        9553,
        517,
        371,
        394,
        30763,
        1026,
        2063,
        78,
        808,
        49932,
        369,
        4046,
        1328,
        48564,
        10667,
        8483,
        50002,
        439,
        6,
        9328,
        1004
      ],
      "temperature": 0,
      "avg_logprob": -0.25695496196894685,
      "compression_ratio": 1.7598425196850394,
      "no_speech_prob": 1.4307204310171073e-8
    },
    {
      "id": 266,
      "seek": 157556,
      "start": 1593.8799999999999,
      "end": 1598.84,
      "text": " del di questo fenomeno serverless diceva è però se metti tutto su serverless paghi sempre",
      "tokens": [
        1103,
        1026,
        10263,
        26830,
        4726,
        78,
        7154,
        1832,
        10313,
        2757,
        4873,
        12673,
        369,
        1131,
        7317,
        23048,
        459,
        7154,
        1832,
        11812,
        4954,
        9553
      ],
      "temperature": 0,
      "avg_logprob": -0.25695496196894685,
      "compression_ratio": 1.7598425196850394,
      "no_speech_prob": 1.4307204310171073e-8
    },
    {
      "id": 267,
      "seek": 157556,
      "start": 1598.84,
      "end": 1604.24,
      "text": " pochi centesimi piuttosto che magari pagare centinaia o migliaia di dollari al mese che",
      "tokens": [
        714,
        8036,
        1489,
        279,
        10121,
        3895,
        13478,
        22756,
        947,
        49932,
        11812,
        543,
        1489,
        1426,
        654,
        277,
        6186,
        14218,
        654,
        1026,
        2722,
        3504,
        419,
        275,
        1130,
        947
      ],
      "temperature": 0,
      "avg_logprob": -0.25695496196894685,
      "compression_ratio": 1.7598425196850394,
      "no_speech_prob": 1.4307204310171073e-8
    },
    {
      "id": 268,
      "seek": 160424,
      "start": 1604.24,
      "end": 1610.92,
      "text": " può essere vero ma secondo me non è una diciamo un effetto necessario dell'utilizzare",
      "tokens": [
        26526,
        19799,
        1306,
        78,
        463,
        41601,
        385,
        2107,
        4873,
        2002,
        14285,
        7415,
        517,
        1244,
        23778,
        2688,
        4912,
        19781,
        6,
        20835,
        8072,
        543
      ],
      "temperature": 0,
      "avg_logprob": -0.25591051353598543,
      "compression_ratio": 1.5913043478260869,
      "no_speech_prob": 2.688249844950974e-9
    },
    {
      "id": 269,
      "seek": 160424,
      "start": 1610.92,
      "end": 1616.56,
      "text": " serverless quello dipende molto al caso d'uso e per assurdo serverless potrebbe anche costarti",
      "tokens": [
        7154,
        1832,
        22813,
        10460,
        5445,
        16394,
        419,
        9666,
        274,
        6,
        24431,
        308,
        680,
        1256,
        374,
        2595,
        7154,
        1832,
        1847,
        39487,
        11585,
        2063,
        40155
      ],
      "temperature": 0,
      "avg_logprob": -0.25591051353598543,
      "compression_ratio": 1.5913043478260869,
      "no_speech_prob": 2.688249844950974e-9
    },
    {
      "id": 270,
      "seek": 160424,
      "start": 1616.56,
      "end": 1622.92,
      "text": " di più se vai a vedere il puro costo del compute appunto c'è tra l'altro un articolo",
      "tokens": [
        1026,
        10589,
        369,
        4405,
        257,
        35373,
        1930,
        2362,
        340,
        2063,
        78,
        1103,
        14722,
        724,
        24052,
        269,
        6,
        1462,
        944,
        287,
        6,
        47484,
        517,
        15228,
        7902
      ],
      "temperature": 0,
      "avg_logprob": -0.25591051353598543,
      "compression_ratio": 1.5913043478260869,
      "no_speech_prob": 2.688249844950974e-9
    },
    {
      "id": 271,
      "seek": 160424,
      "start": 1622.92,
      "end": 1628.72,
      "text": " del del sito di Fortiorem che magari poi cerco il link ve lo passo qui che fa proprio un'analisi",
      "tokens": [
        1103,
        1103,
        1394,
        78,
        1026,
        11002,
        72,
        37956,
        947,
        49932,
        19260,
        10146,
        1291,
        1930,
        2113,
        1241,
        450,
        38159,
        1956,
        947,
        2050,
        28203,
        517,
        6,
        29702,
        8021
      ],
      "temperature": 0,
      "avg_logprob": -0.25591051353598543,
      "compression_ratio": 1.5913043478260869,
      "no_speech_prob": 2.688249844950974e-9
    },
    {
      "id": 272,
      "seek": 162872,
      "start": 1628.72,
      "end": 1634.76,
      "text": " molto dettagliata su un caso d'uso in cui la necessità di compiut è ben nota e lui",
      "tokens": [
        16394,
        1141,
        25030,
        2081,
        3274,
        459,
        517,
        9666,
        274,
        6,
        24431,
        294,
        22929,
        635,
        2688,
        12445,
        1026,
        715,
        72,
        325,
        4873,
        3271,
        36192,
        308,
        8783
      ],
      "temperature": 0,
      "avg_logprob": -0.29265157458851637,
      "compression_ratio": 1.6745283018867925,
      "no_speech_prob": 5.022312787872352e-9
    },
    {
      "id": 273,
      "seek": 162872,
      "start": 1634.76,
      "end": 1640.72,
      "text": " confronta a parità di compute se faccio una cosa su isi tu quindi virtual machine pure",
      "tokens": [
        12422,
        64,
        257,
        971,
        12445,
        1026,
        14722,
        369,
        1915,
        8529,
        2002,
        10163,
        459,
        307,
        72,
        2604,
        15727,
        6374,
        3479,
        6075
      ],
      "temperature": 0,
      "avg_logprob": -0.29265157458851637,
      "compression_ratio": 1.6745283018867925,
      "no_speech_prob": 5.022312787872352e-9
    },
    {
      "id": 274,
      "seek": 162872,
      "start": 1640.72,
      "end": 1646.72,
      "text": " su rispetto fargate quindi dockerizzazione rispetto lambda ogni volta che tu vai a aumentare",
      "tokens": [
        459,
        2253,
        42801,
        1400,
        22514,
        15727,
        360,
        9178,
        8072,
        12928,
        2253,
        42801,
        13607,
        33189,
        18765,
        947,
        2604,
        4405,
        257,
        17128,
        543
      ],
      "temperature": 0,
      "avg_logprob": -0.29265157458851637,
      "compression_ratio": 1.6745283018867925,
      "no_speech_prob": 5.022312787872352e-9
    },
    {
      "id": 275,
      "seek": 162872,
      "start": 1646.72,
      "end": 1651.48,
      "text": " il livello d'astrazione quindi in ordine isi tu fargate e lambda c'è un aumento di costo",
      "tokens": [
        1930,
        1621,
        1913,
        274,
        6,
        525,
        424,
        19706,
        15727,
        294,
        4792,
        533,
        307,
        72,
        2604,
        1400,
        22514,
        308,
        13607,
        269,
        6,
        1462,
        517,
        43600,
        1026,
        2063,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.29265157458851637,
      "compression_ratio": 1.6745283018867925,
      "no_speech_prob": 5.022312787872352e-9
    },
    {
      "id": 276,
      "seek": 165148,
      "start": 1651.48,
      "end": 1660.16,
      "text": " di 20 per quindi sostanzialmente lambda ti va a costare 400 volte di più di isi tu quindi",
      "tokens": [
        1026,
        945,
        680,
        15727,
        41585,
        3910,
        831,
        4082,
        13607,
        8757,
        2773,
        257,
        2063,
        543,
        8423,
        37801,
        1026,
        10589,
        1026,
        307,
        72,
        2604,
        15727
      ],
      "temperature": 0,
      "avg_logprob": -0.22873565742561408,
      "compression_ratio": 1.7363636363636363,
      "no_speech_prob": 1.461576526473607e-9
    },
    {
      "id": 277,
      "seek": 165148,
      "start": 1660.16,
      "end": 1665.32,
      "text": " di virtual machine a parità proprio di capacità di compute quindi se tu riuscissi ad ottimare",
      "tokens": [
        1026,
        6374,
        3479,
        257,
        971,
        12445,
        28203,
        1026,
        4637,
        12445,
        1026,
        14722,
        15727,
        369,
        2604,
        367,
        4872,
        66,
        891,
        72,
        614,
        4337,
        31208,
        543
      ],
      "temperature": 0,
      "avg_logprob": -0.22873565742561408,
      "compression_ratio": 1.7363636363636363,
      "no_speech_prob": 1.461576526473607e-9
    },
    {
      "id": 278,
      "seek": 165148,
      "start": 1665.32,
      "end": 1671.3600000000001,
      "text": " assolutamente l'utilizzo a ottimizzare assolutamente l'utilizzo di isi tu risparmi parecchio rispetto",
      "tokens": [
        1256,
        2308,
        3439,
        287,
        6,
        20835,
        590,
        4765,
        257,
        4337,
        31208,
        8072,
        543,
        1256,
        2308,
        3439,
        287,
        6,
        20835,
        590,
        4765,
        1026,
        307,
        72,
        2604,
        2253,
        2181,
        3057,
        7448,
        66,
        31033,
        2253,
        42801
      ],
      "temperature": 0,
      "avg_logprob": -0.22873565742561408,
      "compression_ratio": 1.7363636363636363,
      "no_speech_prob": 1.461576526473607e-9
    },
    {
      "id": 279,
      "seek": 165148,
      "start": 1671.3600000000001,
      "end": 1677.68,
      "text": " a lambda con un utilizzo costante chiaramente però secondo me quella è una visione parziale",
      "tokens": [
        257,
        13607,
        416,
        517,
        19906,
        4765,
        2063,
        2879,
        47454,
        3439,
        12673,
        41601,
        385,
        32234,
        4873,
        2002,
        5201,
        68,
        971,
        17787,
        68
      ],
      "temperature": 0,
      "avg_logprob": -0.22873565742561408,
      "compression_ratio": 1.7363636363636363,
      "no_speech_prob": 1.461576526473607e-9
    },
    {
      "id": 280,
      "seek": 167768,
      "start": 1677.68,
      "end": 1682.52,
      "text": " del costo perché in realtà va fatto una visione un po' più completa andando a includere quello",
      "tokens": [
        1103,
        2063,
        78,
        14303,
        294,
        47512,
        2773,
        23228,
        2002,
        5201,
        68,
        517,
        714,
        6,
        10589,
        46822,
        293,
        1806,
        257,
        1637,
        323,
        22813
      ],
      "temperature": 0,
      "avg_logprob": -0.23063896960160862,
      "compression_ratio": 1.8801652892561984,
      "no_speech_prob": 4.6911626583323596e-8
    },
    {
      "id": 281,
      "seek": 167768,
      "start": 1682.52,
      "end": 1687.96,
      "text": " che viene chiamato il total cost of ownership nel senso che una cosa è il costo proprio",
      "tokens": [
        947,
        19561,
        417,
        2918,
        2513,
        1930,
        3217,
        2063,
        295,
        15279,
        15373,
        3151,
        539,
        947,
        2002,
        10163,
        4873,
        1930,
        2063,
        78,
        28203
      ],
      "temperature": 0,
      "avg_logprob": -0.23063896960160862,
      "compression_ratio": 1.8801652892561984,
      "no_speech_prob": 4.6911626583323596e-8
    },
    {
      "id": 282,
      "seek": 167768,
      "start": 1687.96,
      "end": 1694.6000000000001,
      "text": " del compute in sé ovvero cpu che gira e paghi per quella cpu una cosa è il costo umano",
      "tokens": [
        1103,
        14722,
        294,
        7910,
        14187,
        39332,
        269,
        34859,
        947,
        290,
        4271,
        308,
        11812,
        4954,
        680,
        32234,
        269,
        34859,
        2002,
        10163,
        4873,
        1930,
        2063,
        78,
        1105,
        3730
      ],
      "temperature": 0,
      "avg_logprob": -0.23063896960160862,
      "compression_ratio": 1.8801652892561984,
      "no_speech_prob": 4.6911626583323596e-8
    },
    {
      "id": 283,
      "seek": 167768,
      "start": 1694.6000000000001,
      "end": 1700.28,
      "text": " di andare a pensare come faccio a mettere in piedi una virtual machine e mantenerna",
      "tokens": [
        1026,
        42742,
        257,
        6099,
        543,
        808,
        1915,
        8529,
        257,
        27812,
        323,
        294,
        24186,
        72,
        2002,
        6374,
        3479,
        308,
        38417,
        1248,
        64
      ],
      "temperature": 0,
      "avg_logprob": -0.23063896960160862,
      "compression_ratio": 1.8801652892561984,
      "no_speech_prob": 4.6911626583323596e-8
    },
    {
      "id": 284,
      "seek": 167768,
      "start": 1700.28,
      "end": 1706.5600000000002,
      "text": " nel tempo come faccio a mettere in piedi una lambda e mantenerna nel tempo e bisogna ricordarsi",
      "tokens": [
        15373,
        8972,
        808,
        1915,
        8529,
        257,
        27812,
        323,
        294,
        24186,
        72,
        2002,
        13607,
        308,
        38417,
        1248,
        64,
        15373,
        8972,
        308,
        40505,
        629,
        21040,
        765,
        32742
      ],
      "temperature": 0,
      "avg_logprob": -0.23063896960160862,
      "compression_ratio": 1.8801652892561984,
      "no_speech_prob": 4.6911626583323596e-8
    },
    {
      "id": 285,
      "seek": 170656,
      "start": 1706.56,
      "end": 1710.6399999999999,
      "text": " che quando metti in piedi una virtual machine devi pensare a tutta una serie di cose che",
      "tokens": [
        947,
        7770,
        1131,
        7317,
        294,
        24186,
        72,
        2002,
        6374,
        3479,
        31219,
        6099,
        543,
        257,
        3672,
        1328,
        2002,
        23030,
        1026,
        30261,
        947
      ],
      "temperature": 0,
      "avg_logprob": -0.2277253379284496,
      "compression_ratio": 1.7435064935064934,
      "no_speech_prob": 5.8382440215609677e-8
    },
    {
      "id": 286,
      "seek": 170656,
      "start": 1710.6399999999999,
      "end": 1716.08,
      "text": " con lambda non devi pensare nel senso devi pensare a non solo il dimensionamento ma anche",
      "tokens": [
        416,
        13607,
        2107,
        31219,
        6099,
        543,
        15373,
        3151,
        539,
        31219,
        6099,
        543,
        257,
        2107,
        6944,
        1930,
        10139,
        8824,
        463,
        11585
      ],
      "temperature": 0,
      "avg_logprob": -0.2277253379284496,
      "compression_ratio": 1.7435064935064934,
      "no_speech_prob": 5.8382440215609677e-8
    },
    {
      "id": 287,
      "seek": 170656,
      "start": 1716.08,
      "end": 1720.76,
      "text": " che sistema operativo utilizzo come faccio a tenere l'aggiornato tutto lo stack software",
      "tokens": [
        947,
        13245,
        2208,
        18586,
        19906,
        4765,
        808,
        1915,
        8529,
        257,
        2064,
        323,
        287,
        6,
        46893,
        1865,
        2513,
        23048,
        450,
        8630,
        4722
      ],
      "temperature": 0,
      "avg_logprob": -0.2277253379284496,
      "compression_ratio": 1.7435064935064934,
      "no_speech_prob": 5.8382440215609677e-8
    },
    {
      "id": 288,
      "seek": 170656,
      "start": 1720.76,
      "end": 1725.6799999999998,
      "text": " da andare a installare come tenere l'aggiornato patch di sicurezza eccetera e quindi diventa",
      "tokens": [
        1120,
        42742,
        257,
        3625,
        543,
        808,
        2064,
        323,
        287,
        6,
        46893,
        1865,
        2513,
        9972,
        1026,
        33579,
        540,
        26786,
        29613,
        20269,
        308,
        15727,
        3414,
        8938
      ],
      "temperature": 0,
      "avg_logprob": -0.2277253379284496,
      "compression_ratio": 1.7435064935064934,
      "no_speech_prob": 5.8382440215609677e-8
    },
    {
      "id": 289,
      "seek": 170656,
      "start": 1725.6799999999998,
      "end": 1731.84,
      "text": " un lavoro molto più grande di quello di una lambda in cui benché abbiamo detto che non",
      "tokens": [
        517,
        42060,
        16394,
        10589,
        8883,
        1026,
        22813,
        1026,
        2002,
        13607,
        294,
        22929,
        10638,
        526,
        22815,
        41031,
        947,
        2107
      ],
      "temperature": 0,
      "avg_logprob": -0.2277253379284496,
      "compression_ratio": 1.7435064935064934,
      "no_speech_prob": 5.8382440215609677e-8
    },
    {
      "id": 290,
      "seek": 170656,
      "start": 1731.84,
      "end": 1736.52,
      "text": " è al 100% vero in teoria pensa a scrivere una funzione e quella funzione gira poi può",
      "tokens": [
        4873,
        419,
        2319,
        4,
        1306,
        78,
        294,
        535,
        8172,
        46909,
        257,
        5545,
        5887,
        2002,
        1019,
        19706,
        308,
        32234,
        1019,
        19706,
        290,
        4271,
        19260,
        26526
      ],
      "temperature": 0,
      "avg_logprob": -0.2277253379284496,
      "compression_ratio": 1.7435064935064934,
      "no_speech_prob": 5.8382440215609677e-8
    },
    {
      "id": 291,
      "seek": 173652,
      "start": 1736.52,
      "end": 1741.8,
      "text": " relici sono tutta una serie di parametri da configurare ma rispetto a una macchina virtuale",
      "tokens": [
        220,
        265,
        2081,
        537,
        9259,
        3672,
        1328,
        2002,
        23030,
        1026,
        6220,
        302,
        470,
        1120,
        22192,
        543,
        463,
        2253,
        42801,
        257,
        2002,
        7912,
        339,
        1426,
        6374,
        68
      ],
      "temperature": 0,
      "avg_logprob": -0.3122926527454007,
      "compression_ratio": 1.812,
      "no_speech_prob": 1.3026889789102825e-8
    },
    {
      "id": 292,
      "seek": 173652,
      "start": 1741.8,
      "end": 1747.84,
      "text": " la superficie di configurazione è molto più bassa e quindi il costo umano di dover andare",
      "tokens": [
        635,
        23881,
        414,
        1026,
        22192,
        12928,
        4873,
        16394,
        10589,
        10136,
        64,
        308,
        15727,
        1930,
        2063,
        78,
        1105,
        3730,
        1026,
        360,
        331,
        42742
      ],
      "temperature": 0,
      "avg_logprob": -0.3122926527454007,
      "compression_ratio": 1.812,
      "no_speech_prob": 1.3026889789102825e-8
    },
    {
      "id": 293,
      "seek": 173652,
      "start": 1747.84,
      "end": 1752.52,
      "text": " a gestire una lambda è più basso di quello di dover andare a gestire una virtual machine",
      "tokens": [
        257,
        7219,
        621,
        2002,
        13607,
        4873,
        10589,
        987,
        539,
        1026,
        22813,
        1026,
        360,
        331,
        42742,
        257,
        7219,
        621,
        2002,
        6374,
        3479
      ],
      "temperature": 0,
      "avg_logprob": -0.3122926527454007,
      "compression_ratio": 1.812,
      "no_speech_prob": 1.3026889789102825e-8
    },
    {
      "id": 294,
      "seek": 173652,
      "start": 1752.52,
      "end": 1756.96,
      "text": " quindi secondo me va fatto più questo tipo di analisi cioè non solo l'analisi di costo",
      "tokens": [
        15727,
        41601,
        385,
        2773,
        23228,
        10589,
        10263,
        9746,
        1026,
        2624,
        8021,
        41827,
        2107,
        6944,
        287,
        6,
        29702,
        8021,
        1026,
        2063,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.3122926527454007,
      "compression_ratio": 1.812,
      "no_speech_prob": 1.3026889789102825e-8
    },
    {
      "id": 295,
      "seek": 173652,
      "start": 1756.96,
      "end": 1762.82,
      "text": " cpu chiamiamolo così ma non è più completa di ok ma se deve avere una persona dedicata",
      "tokens": [
        269,
        34859,
        417,
        2918,
        2918,
        7902,
        23278,
        463,
        2107,
        4873,
        10589,
        46822,
        1026,
        3133,
        463,
        369,
        17761,
        37914,
        2002,
        12184,
        37071,
        3274
      ],
      "temperature": 0,
      "avg_logprob": -0.3122926527454007,
      "compression_ratio": 1.812,
      "no_speech_prob": 1.3026889789102825e-8
    },
    {
      "id": 296,
      "seek": 176282,
      "start": 1762.82,
      "end": 1768.52,
      "text": " che mi tiene in piedi questa virtual machine ed è una virtual machine critica magari sono",
      "tokens": [
        947,
        2752,
        7066,
        294,
        24186,
        72,
        16540,
        6374,
        3479,
        1257,
        4873,
        2002,
        6374,
        3479,
        3113,
        2262,
        49932,
        9259
      ],
      "temperature": 0,
      "avg_logprob": -0.26620810607383993,
      "compression_ratio": 1.7918367346938775,
      "no_speech_prob": 1.1253493426011119e-7
    },
    {
      "id": 297,
      "seek": 176282,
      "start": 1768.52,
      "end": 1772.96,
      "text": " 50.000 euro l'anno che sta spendendo così e non ti rendi conto che lei sta spendendo",
      "tokens": [
        2625,
        13,
        1360,
        14206,
        287,
        6,
        13484,
        947,
        11135,
        3496,
        3999,
        23278,
        308,
        2107,
        8757,
        6125,
        72,
        660,
        78,
        947,
        32791,
        11135,
        3496,
        3999
      ],
      "temperature": 0,
      "avg_logprob": -0.26620810607383993,
      "compression_ratio": 1.7918367346938775,
      "no_speech_prob": 1.1253493426011119e-7
    },
    {
      "id": 298,
      "seek": 176282,
      "start": 1772.96,
      "end": 1777.6,
      "text": " perché è una virtual machine rispetto a una lambda forse sto un po esagerando ma voglio",
      "tokens": [
        14303,
        4873,
        2002,
        6374,
        3479,
        2253,
        42801,
        257,
        2002,
        13607,
        337,
        405,
        22784,
        517,
        714,
        785,
        3557,
        1806,
        463,
        31273,
        19987
      ],
      "temperature": 0,
      "avg_logprob": -0.26620810607383993,
      "compression_ratio": 1.7918367346938775,
      "no_speech_prob": 1.1253493426011119e-7
    },
    {
      "id": 299,
      "seek": 176282,
      "start": 1777.6,
      "end": 1783.32,
      "text": " anche approfondire questo tipo di discorso no no era proprio il punto che che tendevo",
      "tokens": [
        11585,
        2075,
        69,
        684,
        621,
        10263,
        9746,
        1026,
        2983,
        284,
        539,
        572,
        572,
        4249,
        28203,
        1930,
        14326,
        947,
        947,
        3928,
        68,
        3080
      ],
      "temperature": 0,
      "avg_logprob": -0.26620810607383993,
      "compression_ratio": 1.7918367346938775,
      "no_speech_prob": 1.1253493426011119e-7
    },
    {
      "id": 300,
      "seek": 176282,
      "start": 1783.32,
      "end": 1787.74,
      "text": " io cioè avere qualcosa da gestire ci devi mettere anche il costo della persona che lo",
      "tokens": [
        19785,
        41827,
        37914,
        42400,
        1120,
        7219,
        621,
        6983,
        31219,
        27812,
        323,
        11585,
        1930,
        2063,
        78,
        11618,
        12184,
        947,
        450
      ],
      "temperature": 0,
      "avg_logprob": -0.26620810607383993,
      "compression_ratio": 1.7918367346938775,
      "no_speech_prob": 1.1253493426011119e-7
    },
    {
      "id": 301,
      "seek": 178774,
      "start": 1787.74,
      "end": 1793.32,
      "text": " gestisce e magari per la persona che non è economica no? magari per la persona deve",
      "tokens": [
        7219,
        49596,
        308,
        49932,
        680,
        635,
        12184,
        947,
        2107,
        4873,
        2520,
        2262,
        572,
        30,
        49932,
        680,
        635,
        12184,
        17761
      ],
      "temperature": 0,
      "avg_logprob": -0.36317869027455646,
      "compression_ratio": 1.646153846153846,
      "no_speech_prob": 1.8553879499449977e-7
    },
    {
      "id": 302,
      "seek": 178774,
      "start": 1793.32,
      "end": 1797.88,
      "text": " trovare quindi non è che uno deve prendere appunto la posizione binaria uno o l'altro",
      "tokens": [
        35449,
        543,
        15727,
        2107,
        4873,
        947,
        8526,
        17761,
        9866,
        323,
        724,
        24052,
        635,
        1366,
        35740,
        5171,
        9831,
        8526,
        277,
        287,
        6,
        47484
      ],
      "temperature": 0,
      "avg_logprob": -0.36317869027455646,
      "compression_ratio": 1.646153846153846,
      "no_speech_prob": 1.8553879499449977e-7
    },
    {
      "id": 303,
      "seek": 178774,
      "start": 1797.88,
      "end": 1805.16,
      "text": " però ci sono diciamo dei costi nascosti che uno non vede perché magari il devop ce l'ha",
      "tokens": [
        12673,
        6983,
        9259,
        14285,
        7415,
        13874,
        2063,
        72,
        297,
        4806,
        555,
        72,
        947,
        8526,
        2107,
        371,
        4858,
        14303,
        49932,
        1930,
        1905,
        404,
        1769,
        287,
        6,
        1641
      ],
      "temperature": 0,
      "avg_logprob": -0.36317869027455646,
      "compression_ratio": 1.646153846153846,
      "no_speech_prob": 1.8553879499449977e-7
    },
    {
      "id": 304,
      "seek": 178774,
      "start": 1805.16,
      "end": 1809.88,
      "text": " già e non considera quel costo all'interno del costo 10.2.",
      "tokens": [
        30469,
        308,
        2107,
        1949,
        64,
        7178,
        2063,
        78,
        439,
        6,
        5106,
        1771,
        1103,
        2063,
        78,
        1266,
        13,
        17,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.36317869027455646,
      "compression_ratio": 1.646153846153846,
      "no_speech_prob": 1.8553879499449977e-7
    },
    {
      "id": 305,
      "seek": 180988,
      "start": 1809.88,
      "end": 1819.44,
      "text": " Eh però questa anche era una mia domanda ma possiamo fare a meno veramente di un devop",
      "tokens": [
        9663,
        12673,
        16540,
        11585,
        4249,
        2002,
        21290,
        3285,
        5575,
        463,
        44758,
        11994,
        257,
        40236,
        50079,
        1026,
        517,
        1905,
        404
      ],
      "temperature": 0,
      "avg_logprob": -0.3266478756017852,
      "compression_ratio": 1.4714285714285715,
      "no_speech_prob": 1.174408681414718e-9
    },
    {
      "id": 306,
      "seek": 180988,
      "start": 1819.44,
      "end": 1822.72,
      "text": " di un caro vecchio sistemista?",
      "tokens": [
        1026,
        517,
        1032,
        78,
        42021,
        31033,
        45758,
        5236,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.3266478756017852,
      "compression_ratio": 1.4714285714285715,
      "no_speech_prob": 1.174408681414718e-9
    },
    {
      "id": 307,
      "seek": 180988,
      "start": 1822.72,
      "end": 1831.4,
      "text": " Cioè credo che per qualcosa per qualcosa anche solo per per gestire le cose di ufficio",
      "tokens": [
        383,
        35983,
        3864,
        78,
        947,
        680,
        42400,
        680,
        42400,
        11585,
        6944,
        680,
        680,
        7219,
        621,
        476,
        30261,
        1026,
        344,
        3341,
        1004
      ],
      "temperature": 0,
      "avg_logprob": -0.3266478756017852,
      "compression_ratio": 1.4714285714285715,
      "no_speech_prob": 1.174408681414718e-9
    },
    {
      "id": 308,
      "seek": 183140,
      "start": 1831.4,
      "end": 1841.88,
      "text": " boh alla fine un cavolo di servizio ti serve su una virtual machine forse forse alla fine",
      "tokens": [
        748,
        71,
        11591,
        2489,
        517,
        13971,
        7902,
        1026,
        1658,
        590,
        1004,
        8757,
        4596,
        459,
        2002,
        6374,
        3479,
        337,
        405,
        337,
        405,
        11591,
        2489
      ],
      "temperature": 0,
      "avg_logprob": -0.26753406283221665,
      "compression_ratio": 1.627906976744186,
      "no_speech_prob": 5.780631973095751e-9
    },
    {
      "id": 309,
      "seek": 183140,
      "start": 1841.88,
      "end": 1846.92,
      "text": " qualcuno ti serve che fa che faccia quel lavoro e a quel momento già che la ralla è molto",
      "tokens": [
        32101,
        12638,
        8757,
        4596,
        947,
        2050,
        947,
        1915,
        2755,
        7178,
        42060,
        308,
        257,
        7178,
        9333,
        30469,
        947,
        635,
        367,
        10352,
        4873,
        16394
      ],
      "temperature": 0,
      "avg_logprob": -0.26753406283221665,
      "compression_ratio": 1.627906976744186,
      "no_speech_prob": 5.780631973095751e-9
    },
    {
      "id": 310,
      "seek": 183140,
      "start": 1846.92,
      "end": 1856.64,
      "text": " elevata quindi già che lo paghi poi tra virgolette sfruttarlo al 100% dandogli più lavoro quindi",
      "tokens": [
        7701,
        3274,
        15727,
        30469,
        947,
        450,
        11812,
        4954,
        19260,
        944,
        4107,
        70,
        401,
        3007,
        262,
        5779,
        13478,
        19457,
        419,
        2319,
        4,
        29854,
        41443,
        10589,
        42060,
        15727
      ],
      "temperature": 0,
      "avg_logprob": -0.26753406283221665,
      "compression_ratio": 1.627906976744186,
      "no_speech_prob": 5.780631973095751e-9
    },
    {
      "id": 311,
      "seek": 185664,
      "start": 1856.64,
      "end": 1861.68,
      "text": " più virtual machine da aggiornare e quant'altro.",
      "tokens": [
        10589,
        6374,
        3479,
        1120,
        42254,
        1865,
        543,
        308,
        4426,
        6,
        47484,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.24021479026558473,
      "compression_ratio": 1.6130653266331658,
      "no_speech_prob": 3.293713524143982e-9
    },
    {
      "id": 312,
      "seek": 185664,
      "start": 1861.68,
      "end": 1866.2800000000002,
      "text": " Cioè mi chiedevo questo perché a me un sistemista proprio mi manca attualmente non ce l'ho",
      "tokens": [
        383,
        35983,
        2752,
        417,
        1091,
        68,
        3080,
        10263,
        14303,
        257,
        385,
        517,
        45758,
        5236,
        28203,
        2752,
        587,
        496,
        951,
        901,
        4082,
        2107,
        1769,
        287,
        6,
        1289
      ],
      "temperature": 0,
      "avg_logprob": -0.24021479026558473,
      "compression_ratio": 1.6130653266331658,
      "no_speech_prob": 3.293713524143982e-9
    },
    {
      "id": 313,
      "seek": 185664,
      "start": 1866.2800000000002,
      "end": 1873.6000000000001,
      "text": " ma proprio mi manca perché non per tutto c'è un servizio e non per tutto e non sempre",
      "tokens": [
        463,
        28203,
        2752,
        587,
        496,
        14303,
        2107,
        680,
        23048,
        269,
        6,
        1462,
        517,
        1658,
        590,
        1004,
        308,
        2107,
        680,
        23048,
        308,
        2107,
        9553
      ],
      "temperature": 0,
      "avg_logprob": -0.24021479026558473,
      "compression_ratio": 1.6130653266331658,
      "no_speech_prob": 3.293713524143982e-9
    },
    {
      "id": 314,
      "seek": 185664,
      "start": 1873.6000000000001,
      "end": 1881.0400000000002,
      "text": " ho il tempo le capacità e le conoscenze per studiare qual è il servizio che che mi serve",
      "tokens": [
        1106,
        1930,
        8972,
        476,
        4637,
        12445,
        308,
        476,
        416,
        10466,
        268,
        1381,
        680,
        972,
        72,
        543,
        4101,
        4873,
        1930,
        1658,
        590,
        1004,
        947,
        947,
        2752,
        4596
      ],
      "temperature": 0,
      "avg_logprob": -0.24021479026558473,
      "compression_ratio": 1.6130653266331658,
      "no_speech_prob": 3.293713524143982e-9
    },
    {
      "id": 315,
      "seek": 188104,
      "start": 1881.04,
      "end": 1887.6399999999999,
      "text": " allora dovrei fare consiglio dovrei chiedere a dovrei fare chiedere una consulenza e comunque",
      "tokens": [
        44141,
        30870,
        10271,
        11994,
        40233,
        19987,
        30870,
        10271,
        417,
        1091,
        323,
        257,
        30870,
        10271,
        11994,
        417,
        1091,
        323,
        2002,
        1014,
        425,
        23691,
        308,
        45736
      ],
      "temperature": 0,
      "avg_logprob": -0.29225912548246835,
      "compression_ratio": 1.6439024390243901,
      "no_speech_prob": 2.861626713368537e-9
    },
    {
      "id": 316,
      "seek": 188104,
      "start": 1887.6399999999999,
      "end": 1891.76,
      "text": " quei soldi lo stesso in un modo o nell'altro vanno via.",
      "tokens": [
        631,
        72,
        3718,
        72,
        450,
        44413,
        294,
        517,
        16664,
        277,
        44666,
        6,
        47484,
        371,
        13484,
        5766,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.29225912548246835,
      "compression_ratio": 1.6439024390243901,
      "no_speech_prob": 2.861626713368537e-9
    },
    {
      "id": 317,
      "seek": 188104,
      "start": 1891.76,
      "end": 1899.84,
      "text": " Posso dire una cosa io adesso mi trovo a lavorare in un progetto che potremmo definire enterprise",
      "tokens": [
        25906,
        539,
        1264,
        2002,
        10163,
        19785,
        39552,
        2752,
        4495,
        3080,
        257,
        29241,
        543,
        294,
        517,
        447,
        847,
        1353,
        947,
        1847,
        265,
        2174,
        78,
        1561,
        621,
        14132
      ],
      "temperature": 0,
      "avg_logprob": -0.29225912548246835,
      "compression_ratio": 1.6439024390243901,
      "no_speech_prob": 2.861626713368537e-9
    },
    {
      "id": 318,
      "seek": 188104,
      "start": 1899.84,
      "end": 1900.84,
      "text": " no?",
      "tokens": [
        572,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.29225912548246835,
      "compression_ratio": 1.6439024390243901,
      "no_speech_prob": 2.861626713368537e-9
    },
    {
      "id": 319,
      "seek": 188104,
      "start": 1900.84,
      "end": 1909.36,
      "text": " Quindi con una grande azienda con decine di devops ingegner o sre chiamiamoli come ci",
      "tokens": [
        32534,
        416,
        2002,
        8883,
        7883,
        30498,
        416,
        979,
        533,
        1026,
        1905,
        3370,
        3957,
        1146,
        1193,
        277,
        262,
        265,
        417,
        2918,
        2918,
        9384,
        808,
        6983
      ],
      "temperature": 0,
      "avg_logprob": -0.29225912548246835,
      "compression_ratio": 1.6439024390243901,
      "no_speech_prob": 2.861626713368537e-9
    },
    {
      "id": 320,
      "seek": 190936,
      "start": 1909.36,
      "end": 1916.04,
      "text": " pare insomma ormai i ruoli sono quasi più delle tipologie delle persone quindi diventa",
      "tokens": [
        7448,
        1028,
        30243,
        420,
        76,
        1301,
        741,
        5420,
        9384,
        9259,
        20954,
        10589,
        16485,
        4125,
        20121,
        16485,
        29944,
        15727,
        3414,
        8938
      ],
      "temperature": 0,
      "avg_logprob": -0.267509238664494,
      "compression_ratio": 1.580188679245283,
      "no_speech_prob": 1.499385682279808e-8
    },
    {
      "id": 321,
      "seek": 190936,
      "start": 1916.04,
      "end": 1921.4799999999998,
      "text": " difficile però insomma con parecchia gente che scrive dalla mattina alla sera a terra",
      "tokens": [
        26607,
        12673,
        1028,
        30243,
        416,
        7448,
        66,
        339,
        654,
        3788,
        947,
        5545,
        303,
        35566,
        16539,
        1426,
        11591,
        15021,
        257,
        26298
      ],
      "temperature": 0,
      "avg_logprob": -0.267509238664494,
      "compression_ratio": 1.580188679245283,
      "no_speech_prob": 1.499385682279808e-8
    },
    {
      "id": 322,
      "seek": 190936,
      "start": 1921.4799999999998,
      "end": 1928.52,
      "text": " forma e vive dentro cloud watch e sistemi di monitoring vari ed eventuali.",
      "tokens": [
        8366,
        308,
        28927,
        10856,
        4588,
        1159,
        308,
        10555,
        13372,
        1026,
        11028,
        3034,
        1257,
        33160,
        72,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.267509238664494,
      "compression_ratio": 1.580188679245283,
      "no_speech_prob": 1.499385682279808e-8
    },
    {
      "id": 323,
      "seek": 190936,
      "start": 1928.52,
      "end": 1936.52,
      "text": " E' una cosa un pattern che ho trovato non solo in questa grande grande multinazionale",
      "tokens": [
        462,
        6,
        2002,
        10163,
        517,
        5102,
        947,
        1106,
        35449,
        2513,
        2107,
        6944,
        294,
        16540,
        8883,
        8883,
        45872,
        921,
        313,
        1220
      ],
      "temperature": 0,
      "avg_logprob": -0.267509238664494,
      "compression_ratio": 1.580188679245283,
      "no_speech_prob": 1.499385682279808e-8
    },
    {
      "id": 324,
      "seek": 193652,
      "start": 1936.52,
      "end": 1945.32,
      "text": " ma anche in altre società piuttosto grandi e nonostante i costi una virata verso i servizi",
      "tokens": [
        463,
        11585,
        294,
        34983,
        14051,
        1467,
        3895,
        13478,
        22756,
        45155,
        308,
        2107,
        555,
        2879,
        741,
        2063,
        72,
        2002,
        4107,
        3274,
        49786,
        741,
        1658,
        24300
      ],
      "temperature": 0,
      "avg_logprob": -0.3130766091887484,
      "compression_ratio": 1.4778761061946903,
      "no_speech_prob": 7.778707455941003e-9
    },
    {
      "id": 325,
      "seek": 193652,
      "start": 1945.32,
      "end": 1950.96,
      "text": " managed e questo un po' è in controtendenza a quello che ha scritto DDD qualche qualche",
      "tokens": [
        6453,
        308,
        10263,
        517,
        714,
        6,
        4873,
        294,
        660,
        10536,
        8896,
        2394,
        257,
        22813,
        947,
        324,
        5918,
        34924,
        413,
        20818,
        38737,
        38737
      ],
      "temperature": 0,
      "avg_logprob": -0.3130766091887484,
      "compression_ratio": 1.4778761061946903,
      "no_speech_prob": 7.778707455941003e-9
    },
    {
      "id": 326,
      "seek": 193652,
      "start": 1950.96,
      "end": 1952.2,
      "text": " giorno fa no?",
      "tokens": [
        42202,
        2050,
        572,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.3130766091887484,
      "compression_ratio": 1.4778761061946903,
      "no_speech_prob": 7.778707455941003e-9
    },
    {
      "id": 327,
      "seek": 193652,
      "start": 1952.2,
      "end": 1956.08,
      "text": " Parlando dei costi di AWS e insomma del suo flame.",
      "tokens": [
        3457,
        16201,
        13874,
        2063,
        72,
        1026,
        17650,
        308,
        1028,
        30243,
        1103,
        34197,
        13287,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.3130766091887484,
      "compression_ratio": 1.4778761061946903,
      "no_speech_prob": 7.778707455941003e-9
    },
    {
      "id": 328,
      "seek": 193652,
      "start": 1956.08,
      "end": 1965,
      "text": " Però pur con una forte presenza di utilizziamo il termine old school di sistemisti o di",
      "tokens": [
        20533,
        1864,
        416,
        2002,
        23235,
        1183,
        23691,
        1026,
        40355,
        7415,
        1930,
        1433,
        533,
        1331,
        1395,
        1026,
        10555,
        443,
        45308,
        277,
        1026
      ],
      "temperature": 0,
      "avg_logprob": -0.3130766091887484,
      "compression_ratio": 1.4778761061946903,
      "no_speech_prob": 7.778707455941003e-9
    },
    {
      "id": 329,
      "seek": 196500,
      "start": 1965,
      "end": 1974.52,
      "text": " DDD e cavolo si opta per una serie di servizi managed per capirci le app sono deploiate",
      "tokens": [
        413,
        20818,
        308,
        13971,
        7902,
        1511,
        2427,
        64,
        680,
        2002,
        23030,
        1026,
        1658,
        24300,
        6453,
        680,
        1410,
        347,
        537,
        476,
        724,
        9259,
        368,
        21132,
        13024
      ],
      "temperature": 0,
      "avg_logprob": -0.29147905543230584,
      "compression_ratio": 1.6835443037974684,
      "no_speech_prob": 8.327813993957989e-10
    },
    {
      "id": 330,
      "seek": 196500,
      "start": 1974.52,
      "end": 1984.68,
      "text": " con se siamo in ambito azur app service o se devo fare una qualche qualche feature qualche",
      "tokens": [
        416,
        369,
        33459,
        294,
        3913,
        3528,
        7883,
        374,
        724,
        2643,
        277,
        369,
        49717,
        11994,
        2002,
        38737,
        38737,
        4111,
        38737
      ],
      "temperature": 0,
      "avg_logprob": -0.29147905543230584,
      "compression_ratio": 1.6835443037974684,
      "no_speech_prob": 8.327813993957989e-10
    },
    {
      "id": 331,
      "seek": 196500,
      "start": 1984.68,
      "end": 1992.88,
      "text": " funzione qualche qualche azione automatizzare qualcosa si usano le serverless functions",
      "tokens": [
        1019,
        19706,
        38737,
        38737,
        7883,
        5328,
        28034,
        8072,
        543,
        42400,
        1511,
        505,
        3730,
        476,
        7154,
        1832,
        6828
      ],
      "temperature": 0,
      "avg_logprob": -0.29147905543230584,
      "compression_ratio": 1.6835443037974684,
      "no_speech_prob": 8.327813993957989e-10
    },
    {
      "id": 332,
      "seek": 199288,
      "start": 1992.88,
      "end": 1998.92,
      "text": " piuttosto che pur avendo le risorse in house piuttosto che insomma non si dice piuttosto",
      "tokens": [
        3895,
        13478,
        22756,
        947,
        1864,
        1305,
        3999,
        476,
        2253,
        18699,
        294,
        1782,
        3895,
        13478,
        22756,
        947,
        1028,
        30243,
        2107,
        1511,
        10313,
        3895,
        13478,
        22756
      ],
      "temperature": 0,
      "avg_logprob": -0.24987774450802108,
      "compression_ratio": 1.7357512953367875,
      "no_speech_prob": 6.312642142347613e-8
    },
    {
      "id": 333,
      "seek": 199288,
      "start": 1998.92,
      "end": 2006.92,
      "text": " che ma freghiamocene piuttosto che insomma tirare in house ottenere in house un'architettura",
      "tokens": [
        947,
        463,
        2130,
        9030,
        7415,
        384,
        716,
        3895,
        13478,
        22756,
        947,
        1028,
        30243,
        13807,
        543,
        294,
        1782,
        4337,
        1147,
        323,
        294,
        1782,
        517,
        6,
        1178,
        270,
        3093,
        2991
      ],
      "temperature": 0,
      "avg_logprob": -0.24987774450802108,
      "compression_ratio": 1.7357512953367875,
      "no_speech_prob": 6.312642142347613e-8
    },
    {
      "id": 334,
      "seek": 199288,
      "start": 2006.92,
      "end": 2011,
      "text": " che diventa ancora più complessa di quello che è.",
      "tokens": [
        947,
        3414,
        8938,
        30656,
        10589,
        1209,
        8391,
        1026,
        22813,
        947,
        4873,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.24987774450802108,
      "compression_ratio": 1.7357512953367875,
      "no_speech_prob": 6.312642142347613e-8
    },
    {
      "id": 335,
      "seek": 199288,
      "start": 2011,
      "end": 2022.3600000000001,
      "text": " Allora mi chiedo e lo chiedo a Luciano specialmente forse è cambiato anche il modo con con l'avvento",
      "tokens": [
        1057,
        3252,
        2752,
        417,
        36035,
        308,
        450,
        417,
        36035,
        257,
        37309,
        3730,
        2121,
        4082,
        337,
        405,
        4873,
        19569,
        2513,
        11585,
        1930,
        16664,
        416,
        416,
        287,
        6,
        706,
        2475,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.24987774450802108,
      "compression_ratio": 1.7357512953367875,
      "no_speech_prob": 6.312642142347613e-8
    },
    {
      "id": 336,
      "seek": 202236,
      "start": 2022.36,
      "end": 2027.6399999999999,
      "text": " di serverless in una visione un po' più ampia no?",
      "tokens": [
        1026,
        7154,
        1832,
        294,
        2002,
        5201,
        68,
        517,
        714,
        6,
        10589,
        18648,
        654,
        572,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.2665091483823715,
      "compression_ratio": 1.5496688741721854,
      "no_speech_prob": 3.65347752051548e-8
    },
    {
      "id": 337,
      "seek": 202236,
      "start": 2027.6399999999999,
      "end": 2038.24,
      "text": " Quindi compresa la visione del database serverless e dei container serverless della storage dei",
      "tokens": [
        32534,
        715,
        495,
        64,
        635,
        5201,
        68,
        1103,
        8149,
        7154,
        1832,
        308,
        13874,
        10129,
        7154,
        1832,
        11618,
        6725,
        13874
      ],
      "temperature": 0,
      "avg_logprob": -0.2665091483823715,
      "compression_ratio": 1.5496688741721854,
      "no_speech_prob": 3.65347752051548e-8
    },
    {
      "id": 338,
      "seek": 202236,
      "start": 2038.24,
      "end": 2046.1599999999999,
      "text": " file fondamentalmente serverless come S3 è cambiato proprio il modo che siccome tu sei",
      "tokens": [
        3991,
        9557,
        44538,
        4082,
        7154,
        1832,
        808,
        318,
        18,
        4873,
        19569,
        2513,
        28203,
        1930,
        16664,
        947,
        33579,
        1102,
        2604,
        10842
      ],
      "temperature": 0,
      "avg_logprob": -0.2665091483823715,
      "compression_ratio": 1.5496688741721854,
      "no_speech_prob": 3.65347752051548e-8
    },
    {
      "id": 339,
      "seek": 204616,
      "start": 2046.16,
      "end": 2053.44,
      "text": " anche un full stack developer il modo in cui pensiamo il software?",
      "tokens": [
        11585,
        517,
        1577,
        8630,
        10754,
        1930,
        16664,
        294,
        22929,
        6099,
        7415,
        1930,
        4722,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.21809634984096635,
      "compression_ratio": 1.7405857740585775,
      "no_speech_prob": 1.3232025253273605e-8
    },
    {
      "id": 340,
      "seek": 204616,
      "start": 2053.44,
      "end": 2058.56,
      "text": " Si concordo assolutamente secondo me andiamo con questo con questo tipo di osservazione",
      "tokens": [
        4909,
        1588,
        23872,
        1256,
        2308,
        3439,
        41601,
        385,
        293,
        7415,
        416,
        10263,
        416,
        10263,
        9746,
        1026,
        19508,
        1978,
        12928
      ],
      "temperature": 0,
      "avg_logprob": -0.21809634984096635,
      "compression_ratio": 1.7405857740585775,
      "no_speech_prob": 1.3232025253273605e-8
    },
    {
      "id": 341,
      "seek": 204616,
      "start": 2058.56,
      "end": 2062.96,
      "text": " ad avvicinarci di più a quello che sono il vantaggio di serverless nonostante abbiamo",
      "tokens": [
        614,
        1305,
        25537,
        6470,
        537,
        1026,
        10589,
        257,
        22813,
        947,
        9259,
        1930,
        371,
        394,
        30763,
        1026,
        7154,
        1832,
        2107,
        555,
        2879,
        22815
      ],
      "temperature": 0,
      "avg_logprob": -0.21809634984096635,
      "compression_ratio": 1.7405857740585775,
      "no_speech_prob": 1.3232025253273605e-8
    },
    {
      "id": 342,
      "seek": 204616,
      "start": 2062.96,
      "end": 2070.04,
      "text": " detto che la promessa di serverless non è che sia stata così mantenuta negli anni però",
      "tokens": [
        41031,
        947,
        635,
        2234,
        8391,
        1026,
        7154,
        1832,
        2107,
        4873,
        947,
        25176,
        49554,
        23278,
        38417,
        12093,
        2485,
        2081,
        31164,
        12673
      ],
      "temperature": 0,
      "avg_logprob": -0.21809634984096635,
      "compression_ratio": 1.7405857740585775,
      "no_speech_prob": 1.3232025253273605e-8
    },
    {
      "id": 343,
      "seek": 204616,
      "start": 2070.04,
      "end": 2075.2000000000003,
      "text": " secondo me continua un po' ad esserci della verità in quella promessa di serverless",
      "tokens": [
        41601,
        385,
        40861,
        517,
        714,
        6,
        614,
        2097,
        260,
        537,
        11618,
        1306,
        12445,
        294,
        32234,
        2234,
        8391,
        1026,
        7154,
        1832
      ],
      "temperature": 0,
      "avg_logprob": -0.21809634984096635,
      "compression_ratio": 1.7405857740585775,
      "no_speech_prob": 1.3232025253273605e-8
    },
    {
      "id": 344,
      "seek": 207520,
      "start": 2075.2,
      "end": 2082.2799999999997,
      "text": " nel senso che serverless ci porta molto di più ad essere agili quando si parla di mettere",
      "tokens": [
        15373,
        3151,
        539,
        947,
        7154,
        1832,
        6983,
        28598,
        16394,
        1026,
        10589,
        614,
        19799,
        623,
        2312,
        7770,
        1511,
        971,
        875,
        1026,
        27812,
        323
      ],
      "temperature": 0,
      "avg_logprob": -0.2420262046482252,
      "compression_ratio": 1.7272727272727273,
      "no_speech_prob": 1.2359537038264534e-7
    },
    {
      "id": 345,
      "seek": 207520,
      "start": 2082.2799999999997,
      "end": 2084.04,
      "text": " in piedi una cosa nuova.",
      "tokens": [
        294,
        24186,
        72,
        2002,
        10163,
        3822,
        27924,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2420262046482252,
      "compression_ratio": 1.7272727272727273,
      "no_speech_prob": 1.2359537038264534e-7
    },
    {
      "id": 346,
      "seek": 207520,
      "start": 2084.04,
      "end": 2090.56,
      "text": " Esempio banale quando diciamo in un mondo tradizionale on premise bisognava mettere",
      "tokens": [
        462,
        405,
        2455,
        1004,
        5643,
        1220,
        7770,
        14285,
        7415,
        294,
        517,
        40499,
        2479,
        590,
        313,
        1220,
        322,
        22045,
        40505,
        629,
        2757,
        27812,
        323
      ],
      "temperature": 0,
      "avg_logprob": -0.2420262046482252,
      "compression_ratio": 1.7272727272727273,
      "no_speech_prob": 1.2359537038264534e-7
    },
    {
      "id": 347,
      "seek": 207520,
      "start": 2090.56,
      "end": 2094.3199999999997,
      "text": " in piedi un qualsiasi nuovo servizio dalla cosa più banale immaginiamo che ne so una",
      "tokens": [
        294,
        24186,
        72,
        517,
        421,
        1124,
        4609,
        72,
        49348,
        1658,
        590,
        1004,
        35566,
        10163,
        10589,
        5643,
        1220,
        3397,
        559,
        259,
        7415,
        947,
        408,
        370,
        2002
      ],
      "temperature": 0,
      "avg_logprob": -0.2420262046482252,
      "compression_ratio": 1.7272727272727273,
      "no_speech_prob": 1.2359537038264534e-7
    },
    {
      "id": 348,
      "seek": 207520,
      "start": 2094.3199999999997,
      "end": 2099.2799999999997,
      "text": " web book che deve rispondere ad un evento c'era veramente tanto lavoro di burocrazia",
      "tokens": [
        3670,
        1446,
        947,
        17761,
        2253,
        79,
        33447,
        614,
        517,
        40655,
        269,
        6,
        1663,
        50079,
        10331,
        42060,
        1026,
        758,
        24174,
        30695,
        654
      ],
      "temperature": 0,
      "avg_logprob": -0.2420262046482252,
      "compression_ratio": 1.7272727272727273,
      "no_speech_prob": 1.2359537038264534e-7
    },
    {
      "id": 349,
      "seek": 207520,
      "start": 2099.2799999999997,
      "end": 2104.52,
      "text": " da fare bisognava andare dall IT dal tizio dell'IT e dire sai dove è una macchina in",
      "tokens": [
        1120,
        11994,
        40505,
        629,
        2757,
        42742,
        43351,
        6783,
        11702,
        256,
        590,
        1004,
        19781,
        6,
        3927,
        308,
        1264,
        32417,
        23287,
        4873,
        2002,
        7912,
        339,
        1426,
        294
      ],
      "temperature": 0,
      "avg_logprob": -0.2420262046482252,
      "compression_ratio": 1.7272727272727273,
      "no_speech_prob": 1.2359537038264534e-7
    },
    {
      "id": 350,
      "seek": 210452,
      "start": 2104.52,
      "end": 2110.04,
      "text": " cui posso mettere in piedi questa cosa mi crei il certificato mi serve un dominio queste",
      "tokens": [
        22929,
        22501,
        27812,
        323,
        294,
        24186,
        72,
        16540,
        10163,
        2752,
        1197,
        72,
        1930,
        12378,
        2513,
        2752,
        4596,
        517,
        8859,
        1004,
        35455
      ],
      "temperature": 0,
      "avg_logprob": -0.2313934488499418,
      "compression_ratio": 1.6472602739726028,
      "no_speech_prob": 5.072357112112513e-8
    },
    {
      "id": 351,
      "seek": 210452,
      "start": 2110.04,
      "end": 2114.96,
      "text": " queste altre passavano due tre quattro settimane prima di poter avere l'ambiente su cui andare",
      "tokens": [
        35455,
        34983,
        1320,
        706,
        3730,
        3462,
        2192,
        421,
        1591,
        340,
        5584,
        332,
        1929,
        19507,
        1026,
        1847,
        260,
        37914,
        287,
        6,
        2173,
        8413,
        459,
        22929,
        42742
      ],
      "temperature": 0,
      "avg_logprob": -0.2313934488499418,
      "compression_ratio": 1.6472602739726028,
      "no_speech_prob": 5.072357112112513e-8
    },
    {
      "id": 352,
      "seek": 210452,
      "start": 2114.96,
      "end": 2117.36,
      "text": " a rilasciare magari 15 righe di codice.",
      "tokens": [
        257,
        367,
        388,
        296,
        537,
        543,
        49932,
        2119,
        8329,
        675,
        1026,
        17656,
        573,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2313934488499418,
      "compression_ratio": 1.6472602739726028,
      "no_speech_prob": 5.072357112112513e-8
    },
    {
      "id": 353,
      "seek": 210452,
      "start": 2117.36,
      "end": 2123.28,
      "text": " Secondo me serverless è in generale tutto questo mondo di servizi più managed come",
      "tokens": [
        5736,
        78,
        385,
        7154,
        1832,
        4873,
        294,
        1337,
        1220,
        23048,
        10263,
        40499,
        1026,
        1658,
        24300,
        10589,
        6453,
        808
      ],
      "temperature": 0,
      "avg_logprob": -0.2313934488499418,
      "compression_ratio": 1.6472602739726028,
      "no_speech_prob": 5.072357112112513e-8
    },
    {
      "id": 354,
      "seek": 210452,
      "start": 2123.28,
      "end": 2127.12,
      "text": " possiamo pure pensare che ne so DynamoDB per quanto non è una strazione che mi faccia",
      "tokens": [
        44758,
        6075,
        6099,
        543,
        947,
        408,
        370,
        22947,
        78,
        27735,
        680,
        17820,
        2107,
        4873,
        2002,
        2148,
        19706,
        947,
        2752,
        1915,
        2755
      ],
      "temperature": 0,
      "avg_logprob": -0.2313934488499418,
      "compression_ratio": 1.6472602739726028,
      "no_speech_prob": 5.072357112112513e-8
    },
    {
      "id": 355,
      "seek": 210452,
      "start": 2127.12,
      "end": 2132.96,
      "text": " impazzire è vero pure se tu devi pensare a mettere in piedi un RDS che già RDS c'è",
      "tokens": [
        704,
        9112,
        621,
        4873,
        1306,
        78,
        6075,
        369,
        2604,
        31219,
        6099,
        543,
        257,
        27812,
        323,
        294,
        24186,
        72,
        517,
        497,
        11844,
        947,
        30469,
        497,
        11844,
        269,
        6,
        1462
      ],
      "temperature": 0,
      "avg_logprob": -0.2313934488499418,
      "compression_ratio": 1.6472602739726028,
      "no_speech_prob": 5.072357112112513e-8
    },
    {
      "id": 356,
      "seek": 213296,
      "start": 2132.96,
      "end": 2138.96,
      "text": " tutta una serie di roba managed o piuttosto addirittura farti il tuo postgres da zero",
      "tokens": [
        3672,
        1328,
        2002,
        23030,
        1026,
        3870,
        64,
        6453,
        277,
        3895,
        13478,
        22756,
        909,
        347,
        593,
        2991,
        24575,
        72,
        1930,
        45352,
        2183,
        45189,
        1120,
        4018
      ],
      "temperature": 0,
      "avg_logprob": -0.20175572002635284,
      "compression_ratio": 1.6139705882352942,
      "no_speech_prob": 2.3222931133659586e-8
    },
    {
      "id": 357,
      "seek": 213296,
      "start": 2138.96,
      "end": 2147.5,
      "text": " rispetto a creare una tabella su DynamoDB DynamoDB ci metti 0,5 minuti a far partire",
      "tokens": [
        2253,
        42801,
        257,
        1197,
        543,
        2002,
        4421,
        9885,
        459,
        22947,
        78,
        27735,
        22947,
        78,
        27735,
        6983,
        1131,
        7317,
        1958,
        11,
        20,
        13951,
        72,
        257,
        1400,
        644,
        621
      ],
      "temperature": 0,
      "avg_logprob": -0.20175572002635284,
      "compression_ratio": 1.6139705882352942,
      "no_speech_prob": 2.3222931133659586e-8
    },
    {
      "id": 358,
      "seek": 213296,
      "start": 2147.5,
      "end": 2152.8,
      "text": " un'istanza RDS che già appunto c'è tanto managed ci vuole almeno mezz'ora quindi secondo",
      "tokens": [
        517,
        6,
        7559,
        2394,
        497,
        11844,
        947,
        30469,
        724,
        24052,
        269,
        6,
        1462,
        10331,
        6453,
        6983,
        9732,
        4812,
        419,
        43232,
        385,
        4313,
        6,
        3252,
        15727,
        41601
      ],
      "temperature": 0,
      "avg_logprob": -0.20175572002635284,
      "compression_ratio": 1.6139705882352942,
      "no_speech_prob": 2.3222931133659586e-8
    },
    {
      "id": 359,
      "seek": 213296,
      "start": 2152.8,
      "end": 2156.7200000000003,
      "text": " me è più quello il tipo di ragionamento in un mondo che è sempre più agile sempre",
      "tokens": [
        385,
        4873,
        10589,
        22813,
        1930,
        9746,
        1026,
        17539,
        313,
        8824,
        294,
        517,
        40499,
        947,
        4873,
        9553,
        10589,
        30072,
        9553
      ],
      "temperature": 0,
      "avg_logprob": -0.20175572002635284,
      "compression_ratio": 1.6139705882352942,
      "no_speech_prob": 2.3222931133659586e-8
    },
    {
      "id": 360,
      "seek": 213296,
      "start": 2156.7200000000003,
      "end": 2161.32,
      "text": " più dinamico in cui le aziende devono riuscire a sperimentare e mettere in piedi i servizi",
      "tokens": [
        10589,
        3791,
        335,
        2789,
        294,
        22929,
        476,
        7883,
        45816,
        1905,
        8957,
        367,
        4872,
        537,
        265,
        257,
        24152,
        2328,
        543,
        308,
        27812,
        323,
        294,
        24186,
        72,
        741,
        1658,
        24300
      ],
      "temperature": 0,
      "avg_logprob": -0.20175572002635284,
      "compression_ratio": 1.6139705882352942,
      "no_speech_prob": 2.3222931133659586e-8
    },
    {
      "id": 361,
      "seek": 216132,
      "start": 2161.32,
      "end": 2166.84,
      "text": " in modo quanto più veloce possibile lì secondo me la promessa di serverless e di questi servizi",
      "tokens": [
        294,
        16664,
        17820,
        10589,
        1241,
        752,
        384,
        50184,
        287,
        4749,
        41601,
        385,
        635,
        2234,
        8391,
        1026,
        7154,
        1832,
        308,
        1026,
        29729,
        1658,
        24300
      ],
      "temperature": 0,
      "avg_logprob": -0.22911900165034274,
      "compression_ratio": 1.555084745762712,
      "no_speech_prob": 1.3652061703339768e-8
    },
    {
      "id": 362,
      "seek": 216132,
      "start": 2166.84,
      "end": 2172.76,
      "text": " managed diventa un po' più importante benché secondo me la strazione perfetta ancora non",
      "tokens": [
        6453,
        3414,
        8938,
        517,
        714,
        6,
        10589,
        9416,
        10638,
        526,
        41601,
        385,
        635,
        2148,
        19706,
        13826,
        16593,
        30656,
        2107
      ],
      "temperature": 0,
      "avg_logprob": -0.22911900165034274,
      "compression_ratio": 1.555084745762712,
      "no_speech_prob": 1.3652061703339768e-8
    },
    {
      "id": 363,
      "seek": 216132,
      "start": 2172.76,
      "end": 2180.0800000000004,
      "text": " si è raggiunta. Però io sono uno stronzo e tu lo sai bene no? E adesso arriva la prima",
      "tokens": [
        1511,
        4873,
        17539,
        7834,
        46380,
        13,
        20533,
        19785,
        9259,
        8526,
        45766,
        4765,
        308,
        2604,
        450,
        32417,
        2537,
        572,
        30,
        462,
        39552,
        3399,
        2757,
        635,
        19507
      ],
      "temperature": 0,
      "avg_logprob": -0.22911900165034274,
      "compression_ratio": 1.555084745762712,
      "no_speech_prob": 1.3652061703339768e-8
    },
    {
      "id": 364,
      "seek": 216132,
      "start": 2180.0800000000004,
      "end": 2187.92,
      "text": " domanda cattiva alla quale io in realtà non so dare risposta è una domanda che mi pongo",
      "tokens": [
        3285,
        5575,
        269,
        1591,
        5931,
        11591,
        421,
        1220,
        19785,
        294,
        47512,
        2107,
        370,
        8955,
        2253,
        79,
        8638,
        4873,
        2002,
        3285,
        5575,
        947,
        2752,
        280,
        25729
      ],
      "temperature": 0,
      "avg_logprob": -0.22911900165034274,
      "compression_ratio": 1.555084745762712,
      "no_speech_prob": 1.3652061703339768e-8
    },
    {
      "id": 365,
      "seek": 218792,
      "start": 2187.92,
      "end": 2196.48,
      "text": " sempre ma sono bloccato là e dico sì vabbè abbiamo detto che in qualche modo il mondo",
      "tokens": [
        9553,
        463,
        9259,
        1749,
        1914,
        2513,
        3684,
        308,
        274,
        2789,
        49267,
        371,
        10797,
        1462,
        22815,
        41031,
        947,
        294,
        38737,
        16664,
        1930,
        40499
      ],
      "temperature": 0,
      "avg_logprob": -0.2387804680682243,
      "compression_ratio": 1.6807511737089202,
      "no_speech_prob": 2.7577927497191013e-8
    },
    {
      "id": 366,
      "seek": 218792,
      "start": 2196.48,
      "end": 2201.88,
      "text": " serverless l'ecosistema serverless al di là del provider proprio in modo astratto più",
      "tokens": [
        7154,
        1832,
        287,
        6,
        3045,
        329,
        468,
        5619,
        7154,
        1832,
        419,
        1026,
        3684,
        1103,
        12398,
        28203,
        294,
        16664,
        5357,
        4481,
        1353,
        10589
      ],
      "temperature": 0,
      "avg_logprob": -0.2387804680682243,
      "compression_ratio": 1.6807511737089202,
      "no_speech_prob": 2.7577927497191013e-8
    },
    {
      "id": 367,
      "seek": 218792,
      "start": 2201.88,
      "end": 2209.12,
      "text": " generale sta in qualche modo cambiando il modo che abbiamo di vedere il software perché",
      "tokens": [
        1337,
        1220,
        11135,
        294,
        38737,
        16664,
        19569,
        1806,
        1930,
        16664,
        947,
        22815,
        1026,
        35373,
        1930,
        4722,
        14303
      ],
      "temperature": 0,
      "avg_logprob": -0.2387804680682243,
      "compression_ratio": 1.6807511737089202,
      "no_speech_prob": 2.7577927497191013e-8
    },
    {
      "id": 368,
      "seek": 218792,
      "start": 2209.12,
      "end": 2215.96,
      "text": " fondamentalmente quello che noi facevamo quando scrivere scrivevamo il codice erano due cose",
      "tokens": [
        9557,
        44538,
        4082,
        22813,
        947,
        22447,
        1851,
        85,
        10502,
        7770,
        5545,
        5887,
        5545,
        303,
        85,
        10502,
        1930,
        17656,
        573,
        1189,
        3730,
        3462,
        30261
      ],
      "temperature": 0,
      "avg_logprob": -0.2387804680682243,
      "compression_ratio": 1.6807511737089202,
      "no_speech_prob": 2.7577927497191013e-8
    },
    {
      "id": 369,
      "seek": 221596,
      "start": 2215.96,
      "end": 2221.76,
      "text": " la nostra applicazione aveva due importanti funzioni forse sto riducendo un po' ma secondo",
      "tokens": [
        635,
        34311,
        2580,
        12928,
        3472,
        2757,
        3462,
        1021,
        72,
        49345,
        15273,
        337,
        405,
        22784,
        3973,
        1311,
        3999,
        517,
        714,
        6,
        463,
        41601
      ],
      "temperature": 0,
      "avg_logprob": -0.22371683401219986,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 1.522997727931852e-8
    },
    {
      "id": 370,
      "seek": 221596,
      "start": 2221.76,
      "end": 2228,
      "text": " me i due le due grandi responsabilità di qualunque tipo di applicazione scritta sono",
      "tokens": [
        385,
        741,
        3462,
        476,
        3462,
        45155,
        29829,
        12445,
        1026,
        4101,
        409,
        1077,
        9746,
        1026,
        2580,
        12928,
        5918,
        21870,
        9259
      ],
      "temperature": 0,
      "avg_logprob": -0.22371683401219986,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 1.522997727931852e-8
    },
    {
      "id": 371,
      "seek": 221596,
      "start": 2228,
      "end": 2237.04,
      "text": " eseguire business logic quindi logica specifica collegata al business di contesto e avere",
      "tokens": [
        785,
        1146,
        43612,
        1606,
        9952,
        15727,
        3565,
        2262,
        2685,
        64,
        13300,
        3274,
        419,
        1606,
        1026,
        10287,
        78,
        308,
        37914
      ],
      "temperature": 0,
      "avg_logprob": -0.22371683401219986,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 1.522997727931852e-8
    },
    {
      "id": 372,
      "seek": 223704,
      "start": 2237.04,
      "end": 2246.16,
      "text": " una sorta di glue code che metteva insieme una serie di elementi e lato codice si occupava",
      "tokens": [
        2002,
        33425,
        1026,
        8998,
        3089,
        947,
        1131,
        975,
        2757,
        1028,
        44940,
        2002,
        23030,
        1026,
        4478,
        72,
        308,
        287,
        2513,
        17656,
        573,
        1511,
        8073,
        4061
      ],
      "temperature": 0,
      "avg_logprob": -0.21686043677391945,
      "compression_ratio": 1.6181818181818182,
      "no_speech_prob": 9.988053051301904e-9
    },
    {
      "id": 373,
      "seek": 223704,
      "start": 2246.16,
      "end": 2251.52,
      "text": " dell'orchestrazione di queste componenti quindi la connessione al database piuttosto che la",
      "tokens": [
        19781,
        6,
        284,
        11762,
        424,
        19706,
        1026,
        35455,
        6542,
        72,
        15727,
        635,
        416,
        1287,
        5328,
        419,
        8149,
        3895,
        13478,
        22756,
        947,
        635
      ],
      "temperature": 0,
      "avg_logprob": -0.21686043677391945,
      "compression_ratio": 1.6181818181818182,
      "no_speech_prob": 9.988053051301904e-9
    },
    {
      "id": 374,
      "seek": 223704,
      "start": 2251.52,
      "end": 2257.72,
      "text": " connessione al sistema di caching il redis della situazione. L'ecosistema serverless",
      "tokens": [
        416,
        1287,
        5328,
        419,
        13245,
        1026,
        269,
        2834,
        1930,
        2182,
        271,
        11618,
        2054,
        12928,
        13,
        441,
        6,
        3045,
        329,
        468,
        5619,
        7154,
        1832
      ],
      "temperature": 0,
      "avg_logprob": -0.21686043677391945,
      "compression_ratio": 1.6181818181818182,
      "no_speech_prob": 9.988053051301904e-9
    },
    {
      "id": 375,
      "seek": 225772,
      "start": 2257.72,
      "end": 2268.2,
      "text": " ha un po' spostato purgato tutto il concetto di glue code fuori dal concetto di applicazione",
      "tokens": [
        324,
        517,
        714,
        6,
        637,
        555,
        2513,
        1864,
        70,
        2513,
        23048,
        1930,
        1588,
        23778,
        1026,
        8998,
        3089,
        8536,
        7386,
        11702,
        1588,
        23778,
        1026,
        2580,
        12928
      ],
      "temperature": 0,
      "avg_logprob": -0.2209417367283302,
      "compression_ratio": 1.5657142857142856,
      "no_speech_prob": 1.4532538727962674e-8
    },
    {
      "id": 376,
      "seek": 225772,
      "start": 2268.2,
      "end": 2276.2,
      "text": " o perlomeno questa è la tendenza no? A questo punto il focus è sulla logica di business",
      "tokens": [
        277,
        680,
        75,
        4726,
        78,
        16540,
        4873,
        635,
        3928,
        23691,
        572,
        30,
        316,
        10263,
        14326,
        1930,
        1879,
        4873,
        33625,
        3565,
        2262,
        1026,
        1606
      ],
      "temperature": 0,
      "avg_logprob": -0.2209417367283302,
      "compression_ratio": 1.5657142857142856,
      "no_speech_prob": 1.4532538727962674e-8
    },
    {
      "id": 377,
      "seek": 225772,
      "start": 2276.2,
      "end": 2283.04,
      "text": " che ha come concetto principale rannare workflow se insieme al glue code purghiamo anche il",
      "tokens": [
        947,
        324,
        808,
        1588,
        23778,
        6959,
        1220,
        5872,
        77,
        543,
        20993,
        369,
        1028,
        44940,
        419,
        8998,
        3089,
        1864,
        70,
        4954,
        10502,
        11585,
        1930
      ],
      "temperature": 0,
      "avg_logprob": -0.2209417367283302,
      "compression_ratio": 1.5657142857142856,
      "no_speech_prob": 1.4532538727962674e-8
    },
    {
      "id": 378,
      "seek": 228304,
      "start": 2283.04,
      "end": 2288.64,
      "text": " crude della situazione rimangono veramente i workflow che sono delle funzioni e là il",
      "tokens": [
        30796,
        11618,
        2054,
        12928,
        15982,
        656,
        8957,
        50079,
        741,
        20993,
        947,
        9259,
        16485,
        49345,
        15273,
        308,
        3684,
        1930
      ],
      "temperature": 0,
      "avg_logprob": -0.26197435981348943,
      "compression_ratio": 1.5561797752808988,
      "no_speech_prob": 1.2824929562782472e-8
    },
    {
      "id": 379,
      "seek": 228304,
      "start": 2288.64,
      "end": 2295.2,
      "text": " concetto fitta one to one proprio col concetto di computazione serverless. Nel contesto però",
      "tokens": [
        1588,
        23778,
        283,
        21870,
        472,
        281,
        472,
        28203,
        1173,
        1588,
        23778,
        1026,
        2807,
        12928,
        7154,
        1832,
        13,
        426,
        338,
        10287,
        78,
        12673
      ],
      "temperature": 0,
      "avg_logprob": -0.26197435981348943,
      "compression_ratio": 1.5561797752808988,
      "no_speech_prob": 1.2824929562782472e-8
    },
    {
      "id": 380,
      "seek": 228304,
      "start": 2295.2,
      "end": 2305,
      "text": " c'è tutta un'altra orchestra di servizi serverless che ha solvono problemi diversi e c'è tutto",
      "tokens": [
        269,
        6,
        1462,
        3672,
        1328,
        517,
        6,
        38865,
        25280,
        1026,
        1658,
        24300,
        7154,
        1832,
        947,
        324,
        1404,
        85,
        8957,
        1154,
        72,
        6111,
        72,
        308,
        269,
        6,
        1462,
        23048
      ],
      "temperature": 0,
      "avg_logprob": -0.26197435981348943,
      "compression_ratio": 1.5561797752808988,
      "no_speech_prob": 1.2824929562782472e-8
    },
    {
      "id": 381,
      "seek": 230500,
      "start": 2305,
      "end": 2314.92,
      "text": " il mondo dell'orchestrazione parliamo di AWS in ambiente AWS con cloud formation o lo strumento",
      "tokens": [
        1930,
        40499,
        19781,
        6,
        284,
        11762,
        424,
        19706,
        971,
        49926,
        1026,
        17650,
        294,
        34957,
        17650,
        416,
        4588,
        11723,
        277,
        450,
        1056,
        2206,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.21091461181640625,
      "compression_ratio": 1.510752688172043,
      "no_speech_prob": 1.9667663053724027e-9
    },
    {
      "id": 382,
      "seek": 230500,
      "start": 2314.92,
      "end": 2322.28,
      "text": " della situazione che si occupa proprio di scriverti questo glue code spostando le responsabilità",
      "tokens": [
        11618,
        2054,
        12928,
        947,
        1511,
        8073,
        64,
        28203,
        1026,
        5545,
        3281,
        72,
        10263,
        8998,
        3089,
        637,
        555,
        1806,
        476,
        29829,
        12445
      ],
      "temperature": 0,
      "avg_logprob": -0.21091461181640625,
      "compression_ratio": 1.510752688172043,
      "no_speech_prob": 1.9667663053724027e-9
    },
    {
      "id": 383,
      "seek": 230500,
      "start": 2322.28,
      "end": 2330.82,
      "text": " tutte sull'infrastruttura per cui a questo punto la vera ownership del team di sviluppo",
      "tokens": [
        38632,
        459,
        285,
        6,
        19920,
        4148,
        81,
        13478,
        2991,
        680,
        22929,
        257,
        10263,
        14326,
        635,
        1306,
        64,
        15279,
        1103,
        1469,
        1026,
        17342,
        388,
        10504,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.21091461181640625,
      "compression_ratio": 1.510752688172043,
      "no_speech_prob": 1.9667663053724027e-9
    },
    {
      "id": 384,
      "seek": 233082,
      "start": 2330.82,
      "end": 2336.28,
      "text": " rimane la logica di business e dico la logica di business purgando anche il crude perché",
      "tokens": [
        15982,
        1929,
        635,
        3565,
        2262,
        1026,
        1606,
        308,
        274,
        2789,
        635,
        3565,
        2262,
        1026,
        1606,
        1864,
        70,
        1806,
        11585,
        1930,
        30796,
        14303
      ],
      "temperature": 0,
      "avg_logprob": -0.20810710793674583,
      "compression_ratio": 1.6,
      "no_speech_prob": 2.5109978096793384e-8
    },
    {
      "id": 385,
      "seek": 233082,
      "start": 2336.28,
      "end": 2344.1200000000003,
      "text": " AWS ha tutta una serie di sistemi che semplificano anche le azioni di create, delete e quant'altro",
      "tokens": [
        17650,
        324,
        3672,
        1328,
        2002,
        23030,
        1026,
        10555,
        13372,
        947,
        4361,
        564,
        1089,
        3730,
        11585,
        476,
        7883,
        15273,
        1026,
        1884,
        11,
        12097,
        308,
        4426,
        6,
        47484
      ],
      "temperature": 0,
      "avg_logprob": -0.20810710793674583,
      "compression_ratio": 1.6,
      "no_speech_prob": 2.5109978096793384e-8
    },
    {
      "id": 386,
      "seek": 233082,
      "start": 2344.1200000000003,
      "end": 2351,
      "text": " all'interno di una certa data source. Per cui la mia domanda è posto che tutto questo",
      "tokens": [
        439,
        6,
        5106,
        1771,
        1026,
        2002,
        44438,
        1412,
        4009,
        13,
        3026,
        22929,
        635,
        21290,
        3285,
        5575,
        4873,
        2183,
        78,
        947,
        23048,
        10263
      ],
      "temperature": 0,
      "avg_logprob": -0.20810710793674583,
      "compression_ratio": 1.6,
      "no_speech_prob": 2.5109978096793384e-8
    },
    {
      "id": 387,
      "seek": 233082,
      "start": 2351,
      "end": 2359.2000000000003,
      "text": " è fighissimo perché ti riduce ai minimi termini il time to market riduce il numero",
      "tokens": [
        4873,
        283,
        910,
        34966,
        14303,
        8757,
        3973,
        4176,
        9783,
        4464,
        72,
        1433,
        3812,
        1930,
        565,
        281,
        2142,
        3973,
        4176,
        1930,
        46839
      ],
      "temperature": 0,
      "avg_logprob": -0.20810710793674583,
      "compression_ratio": 1.6,
      "no_speech_prob": 2.5109978096793384e-8
    },
    {
      "id": 388,
      "seek": 235920,
      "start": 2359.2,
      "end": 2367.7599999999998,
      "text": " di sistemi stiche tutti lì dentro. A livello sviluppatore ha senso a questo punto preoccuparsi",
      "tokens": [
        1026,
        10555,
        13372,
        342,
        299,
        675,
        19822,
        287,
        4749,
        10856,
        13,
        316,
        1621,
        1913,
        17342,
        388,
        10504,
        43148,
        324,
        3151,
        539,
        257,
        10263,
        14326,
        44388,
        32742
      ],
      "temperature": 0,
      "avg_logprob": -0.29913582521326404,
      "compression_ratio": 1.292857142857143,
      "no_speech_prob": 9.329490069376334e-8
    },
    {
      "id": 389,
      "seek": 235920,
      "start": 2367.7599999999998,
      "end": 2381.9199999999996,
      "text": " della ownership della propria applicazione? Quanta complessità vedi su tool o quanto",
      "tokens": [
        11618,
        15279,
        11618,
        2365,
        4668,
        2580,
        12928,
        30,
        2326,
        5983,
        1209,
        442,
        12445,
        371,
        10323,
        459,
        2290,
        277,
        17820
      ],
      "temperature": 0,
      "avg_logprob": -0.29913582521326404,
      "compression_ratio": 1.292857142857143,
      "no_speech_prob": 9.329490069376334e-8
    },
    {
      "id": 390,
      "seek": 238192,
      "start": 2381.92,
      "end": 2391.08,
      "text": " vedi funzionare dei tool cloud agnostic che in qualche modo astragano questo tipo di dipendenza?",
      "tokens": [
        371,
        10323,
        49345,
        313,
        543,
        13874,
        2290,
        4588,
        623,
        77,
        19634,
        947,
        294,
        38737,
        16664,
        5357,
        424,
        35255,
        10263,
        9746,
        1026,
        10460,
        8896,
        2394,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.2721032036675347,
      "compression_ratio": 1.6133333333333333,
      "no_speech_prob": 1.6119879830966966e-7
    },
    {
      "id": 391,
      "seek": 238192,
      "start": 2391.08,
      "end": 2399.32,
      "text": " Ok porti un bel argomento quindi cerco di risponderti un po' in ordine e sperando di",
      "tokens": [
        3477,
        2436,
        72,
        517,
        989,
        3882,
        298,
        15467,
        15727,
        10146,
        1291,
        1026,
        2253,
        79,
        684,
        911,
        72,
        517,
        714,
        6,
        294,
        4792,
        533,
        308,
        24152,
        1806,
        1026
      ],
      "temperature": 0,
      "avg_logprob": -0.2721032036675347,
      "compression_ratio": 1.6133333333333333,
      "no_speech_prob": 1.6119879830966966e-7
    },
    {
      "id": 392,
      "seek": 238192,
      "start": 2399.32,
      "end": 2405.44,
      "text": " darsi una risposta sensata. Da una parte mi viene in mente ad esempio il discorso step",
      "tokens": [
        4072,
        7691,
        2002,
        2253,
        79,
        8638,
        2923,
        3274,
        13,
        3933,
        2002,
        6975,
        2752,
        19561,
        294,
        26577,
        614,
        33627,
        1930,
        2983,
        284,
        539,
        1823
      ],
      "temperature": 0,
      "avg_logprob": -0.2721032036675347,
      "compression_ratio": 1.6133333333333333,
      "no_speech_prob": 1.6119879830966966e-7
    },
    {
      "id": 393,
      "seek": 238192,
      "start": 2405.44,
      "end": 2410.96,
      "text": " functions basato su quello che hai detto ovvero che su AWS uno strumento ti permette di creare",
      "tokens": [
        6828,
        987,
        2513,
        459,
        22813,
        947,
        21822,
        41031,
        14187,
        39332,
        947,
        459,
        17650,
        8526,
        1056,
        2206,
        78,
        8757,
        4784,
        3007,
        1026,
        1197,
        543
      ],
      "temperature": 0,
      "avg_logprob": -0.2721032036675347,
      "compression_ratio": 1.6133333333333333,
      "no_speech_prob": 1.6119879830966966e-7
    },
    {
      "id": 394,
      "seek": 241096,
      "start": 2410.96,
      "end": 2416.08,
      "text": " anche in modo visuale esiste pure un editor visuale tra l'altro l'ultima release pure",
      "tokens": [
        11585,
        294,
        16664,
        5056,
        68,
        785,
        8375,
        6075,
        517,
        9839,
        5056,
        68,
        944,
        287,
        6,
        47484,
        287,
        6,
        723,
        4775,
        4374,
        6075
      ],
      "temperature": 0,
      "avg_logprob": -0.26257177654065583,
      "compression_ratio": 1.662037037037037,
      "no_speech_prob": 0.000006854269940959057
    },
    {
      "id": 395,
      "seek": 241096,
      "start": 2416.08,
      "end": 2422.94,
      "text": " fatta abbastanza bene per gli standard di AWS che ti permette proprio di dire quasi",
      "tokens": [
        4046,
        1328,
        16903,
        525,
        20030,
        2537,
        680,
        17161,
        3832,
        1026,
        17650,
        947,
        8757,
        4784,
        3007,
        28203,
        1026,
        1264,
        20954
      ],
      "temperature": 0,
      "avg_logprob": -0.26257177654065583,
      "compression_ratio": 1.662037037037037,
      "no_speech_prob": 0.000006854269940959057
    },
    {
      "id": 396,
      "seek": 241096,
      "start": 2422.94,
      "end": 2429.76,
      "text": " con logica no code o comunque low code voglio combinare tutta una serie di step fare degli",
      "tokens": [
        416,
        3565,
        2262,
        572,
        3089,
        277,
        45736,
        2295,
        3089,
        31273,
        19987,
        38514,
        543,
        3672,
        1328,
        2002,
        23030,
        1026,
        1823,
        11994,
        32079
      ],
      "temperature": 0,
      "avg_logprob": -0.26257177654065583,
      "compression_ratio": 1.662037037037037,
      "no_speech_prob": 0.000006854269940959057
    },
    {
      "id": 397,
      "seek": 241096,
      "start": 2429.76,
      "end": 2436.16,
      "text": " if fare dei retry fare delle azioni in parallelo e poi effettivamente andare a creare dei workflow",
      "tokens": [
        498,
        11994,
        13874,
        1533,
        627,
        11994,
        16485,
        7883,
        15273,
        294,
        8069,
        10590,
        308,
        19260,
        1244,
        3093,
        23957,
        42742,
        257,
        1197,
        543,
        13874,
        20993
      ],
      "temperature": 0,
      "avg_logprob": -0.26257177654065583,
      "compression_ratio": 1.662037037037037,
      "no_speech_prob": 0.000006854269940959057
    },
    {
      "id": 398,
      "seek": 243616,
      "start": 2436.16,
      "end": 2441.92,
      "text": " pure abbastanza complessi con una quantità di codice veramente minimale e soprattutto",
      "tokens": [
        6075,
        16903,
        525,
        20030,
        1209,
        442,
        72,
        416,
        2002,
        4426,
        12445,
        1026,
        17656,
        573,
        50079,
        4464,
        1220,
        308,
        50002
      ],
      "temperature": 0,
      "avg_logprob": -0.23881218113850072,
      "compression_ratio": 1.6133333333333333,
      "no_speech_prob": 0.0000016280339423246915
    },
    {
      "id": 399,
      "seek": 243616,
      "start": 2441.92,
      "end": 2447.24,
      "text": " facendo rigirare su un ambiente che è totalmente managed in cui non ti devi preoccupare del",
      "tokens": [
        1915,
        3999,
        8329,
        347,
        543,
        459,
        517,
        34957,
        947,
        4873,
        30865,
        6453,
        294,
        22929,
        2107,
        8757,
        31219,
        44388,
        543,
        1103
      ],
      "temperature": 0,
      "avg_logprob": -0.23881218113850072,
      "compression_ratio": 1.6133333333333333,
      "no_speech_prob": 0.0000016280339423246915
    },
    {
      "id": 400,
      "seek": 243616,
      "start": 2447.24,
      "end": 2453.44,
      "text": " fatto che non ci fosse se la capacità o che non riesce a scalare o altri problemi di natura",
      "tokens": [
        23228,
        947,
        2107,
        6983,
        24528,
        369,
        635,
        4637,
        12445,
        277,
        947,
        2107,
        23932,
        384,
        257,
        15664,
        543,
        277,
        33707,
        1154,
        72,
        1026,
        2249,
        2991
      ],
      "temperature": 0,
      "avg_logprob": -0.23881218113850072,
      "compression_ratio": 1.6133333333333333,
      "no_speech_prob": 0.0000016280339423246915
    },
    {
      "id": 401,
      "seek": 243616,
      "start": 2453.44,
      "end": 2461.2799999999997,
      "text": " puramente infrastrutturale. Quindi assolutamente vero il fatto che c'è molto una tendenza",
      "tokens": [
        1864,
        3439,
        6534,
        81,
        13478,
        374,
        1220,
        13,
        32534,
        1256,
        2308,
        3439,
        1306,
        78,
        1930,
        23228,
        947,
        269,
        6,
        1462,
        16394,
        2002,
        3928,
        23691
      ],
      "temperature": 0,
      "avg_logprob": -0.23881218113850072,
      "compression_ratio": 1.6133333333333333,
      "no_speech_prob": 0.0000016280339423246915
    },
    {
      "id": 402,
      "seek": 246128,
      "start": 2461.28,
      "end": 2467.1600000000003,
      "text": " a cercare di darti quanta più roba as a service possibile e tra l'altro proprio parlando",
      "tokens": [
        257,
        10146,
        5685,
        1026,
        39010,
        72,
        4426,
        64,
        10589,
        3870,
        64,
        382,
        257,
        2643,
        50184,
        308,
        944,
        287,
        6,
        47484,
        28203,
        971,
        16201
      ],
      "temperature": 0,
      "avg_logprob": -0.23601471505514005,
      "compression_ratio": 1.6867924528301887,
      "no_speech_prob": 9.422405469194928e-7
    },
    {
      "id": 403,
      "seek": 246128,
      "start": 2467.1600000000003,
      "end": 2471.5,
      "text": " step function una delle cose che hanno introdotto anche abbastanza recente credo sia a meno",
      "tokens": [
        1823,
        2445,
        2002,
        16485,
        30261,
        947,
        26595,
        560,
        11452,
        18838,
        11585,
        16903,
        525,
        20030,
        850,
        1576,
        3864,
        78,
        25176,
        257,
        40236
      ],
      "temperature": 0,
      "avg_logprob": -0.23601471505514005,
      "compression_ratio": 1.6867924528301887,
      "no_speech_prob": 9.422405469194928e-7
    },
    {
      "id": 404,
      "seek": 246128,
      "start": 2471.5,
      "end": 2478.3,
      "text": " di un anno è il fatto che ad esempio l'SDK di AWS quindi tutte le chiamate che ti permettono",
      "tokens": [
        1026,
        517,
        46277,
        4873,
        1930,
        23228,
        947,
        614,
        33627,
        287,
        6,
        23969,
        42,
        1026,
        17650,
        15727,
        38632,
        476,
        417,
        2918,
        473,
        947,
        8757,
        20696,
        1756,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.23601471505514005,
      "compression_ratio": 1.6867924528301887,
      "no_speech_prob": 9.422405469194928e-7
    },
    {
      "id": 405,
      "seek": 246128,
      "start": 2478.3,
      "end": 2484.0400000000004,
      "text": " di invocare tutti gli altri servizi di AWS adesso sono disponibili nelle step function",
      "tokens": [
        1026,
        1048,
        78,
        5685,
        19822,
        17161,
        33707,
        1658,
        24300,
        1026,
        17650,
        39552,
        9259,
        23311,
        897,
        2312,
        46350,
        1823,
        2445
      ],
      "temperature": 0,
      "avg_logprob": -0.23601471505514005,
      "compression_ratio": 1.6867924528301887,
      "no_speech_prob": 9.422405469194928e-7
    },
    {
      "id": 406,
      "seek": 246128,
      "start": 2484.0400000000004,
      "end": 2488.1600000000003,
      "text": " come step nativi quindi in tutta una serie di circostanze non devi neanche andarti a",
      "tokens": [
        808,
        1823,
        2249,
        33448,
        15727,
        294,
        3672,
        1328,
        2002,
        23030,
        1026,
        3510,
        555,
        282,
        1381,
        2107,
        31219,
        408,
        22806,
        293,
        40155,
        257
      ],
      "temperature": 0,
      "avg_logprob": -0.23601471505514005,
      "compression_ratio": 1.6867924528301887,
      "no_speech_prob": 9.422405469194928e-7
    },
    {
      "id": 407,
      "seek": 248816,
      "start": 2488.16,
      "end": 2492.2,
      "text": " scrivere una lambda per dire voglio chiamare quest'altro servizio ma semplicemente c'è",
      "tokens": [
        5545,
        5887,
        2002,
        13607,
        680,
        1264,
        31273,
        19987,
        417,
        2918,
        543,
        866,
        6,
        47484,
        1658,
        590,
        1004,
        463,
        4361,
        4770,
        16288,
        269,
        6,
        1462
      ],
      "temperature": 0,
      "avg_logprob": -0.23392416825935022,
      "compression_ratio": 1.69921875,
      "no_speech_prob": 0.0000017330488617517403
    },
    {
      "id": 408,
      "seek": 248816,
      "start": 2492.2,
      "end": 2496.8399999999997,
      "text": " il blocchettino che dice vabbè i dati che sono venuti fuori da qui metti direttamente",
      "tokens": [
        1930,
        1749,
        66,
        339,
        3093,
        2982,
        947,
        10313,
        371,
        10797,
        1462,
        741,
        1137,
        72,
        947,
        9259,
        6138,
        29161,
        8536,
        7386,
        1120,
        1956,
        1131,
        7317,
        1026,
        14313,
        3439
      ],
      "temperature": 0,
      "avg_logprob": -0.23392416825935022,
      "compression_ratio": 1.69921875,
      "no_speech_prob": 0.0000017330488617517403
    },
    {
      "id": 409,
      "seek": 248816,
      "start": 2496.8399999999997,
      "end": 2503.3199999999997,
      "text": " su DynamoDB oppure leggi da DynamoDB fai questo filtro e poi manda i dati da un'altra",
      "tokens": [
        459,
        22947,
        78,
        27735,
        1458,
        540,
        476,
        22771,
        1120,
        22947,
        78,
        27735,
        283,
        1301,
        10263,
        29148,
        340,
        308,
        19260,
        7411,
        64,
        741,
        1137,
        72,
        1120,
        517,
        6,
        38865
      ],
      "temperature": 0,
      "avg_logprob": -0.23392416825935022,
      "compression_ratio": 1.69921875,
      "no_speech_prob": 0.0000017330488617517403
    },
    {
      "id": 410,
      "seek": 248816,
      "start": 2503.3199999999997,
      "end": 2509.16,
      "text": " parte e tutta questa cosa è estremamente managed nel senso che magari non è scritto",
      "tokens": [
        6975,
        308,
        3672,
        1328,
        16540,
        10163,
        4873,
        871,
        2579,
        3439,
        6453,
        15373,
        3151,
        539,
        947,
        49932,
        2107,
        4873,
        5918,
        34924
      ],
      "temperature": 0,
      "avg_logprob": -0.23392416825935022,
      "compression_ratio": 1.69921875,
      "no_speech_prob": 0.0000017330488617517403
    },
    {
      "id": 411,
      "seek": 248816,
      "start": 2509.16,
      "end": 2514.56,
      "text": " una riga di codice per quello intendo codice business logic però d'altra parte c'è una",
      "tokens": [
        2002,
        8329,
        64,
        1026,
        17656,
        573,
        680,
        22813,
        560,
        3999,
        17656,
        573,
        1606,
        9952,
        12673,
        274,
        6,
        38865,
        6975,
        269,
        6,
        1462,
        2002
      ],
      "temperature": 0,
      "avg_logprob": -0.23392416825935022,
      "compression_ratio": 1.69921875,
      "no_speech_prob": 0.0000017330488617517403
    },
    {
      "id": 412,
      "seek": 251456,
      "start": 2514.56,
      "end": 2520.12,
      "text": " tendenza che forse viene un po' sottovalutata che è forse pure una buona pratica ma forse",
      "tokens": [
        3928,
        23691,
        947,
        337,
        405,
        19561,
        517,
        714,
        6,
        43754,
        3337,
        325,
        3274,
        947,
        4873,
        337,
        405,
        6075,
        2002,
        758,
        4037,
        28844,
        2262,
        463,
        337,
        405
      ],
      "temperature": 0,
      "avg_logprob": -0.22574829636958607,
      "compression_ratio": 1.8284518828451883,
      "no_speech_prob": 2.0494164587603336e-8
    },
    {
      "id": 413,
      "seek": 251456,
      "start": 2520.12,
      "end": 2526.04,
      "text": " ne viene sottovalutata l'importanza che tutto quello che fai in modo visuale o comunque",
      "tokens": [
        408,
        19561,
        43754,
        3337,
        325,
        3274,
        287,
        6,
        20737,
        20030,
        947,
        23048,
        22813,
        947,
        283,
        1301,
        294,
        16664,
        5056,
        68,
        277,
        45736
      ],
      "temperature": 0,
      "avg_logprob": -0.22574829636958607,
      "compression_ratio": 1.8284518828451883,
      "no_speech_prob": 2.0494164587603336e-8
    },
    {
      "id": 414,
      "seek": 251456,
      "start": 2526.04,
      "end": 2531.4,
      "text": " manage o comunque generato con tutta una serie di tool alla fine se lo devi fare in modo",
      "tokens": [
        3067,
        277,
        45736,
        1337,
        2513,
        416,
        3672,
        1328,
        2002,
        23030,
        1026,
        2290,
        11591,
        2489,
        369,
        450,
        31219,
        11994,
        294,
        16664
      ],
      "temperature": 0,
      "avg_logprob": -0.22574829636958607,
      "compression_ratio": 1.8284518828451883,
      "no_speech_prob": 2.0494164587603336e-8
    },
    {
      "id": 415,
      "seek": 251456,
      "start": 2531.4,
      "end": 2536.2799999999997,
      "text": " enterprise è tutto infrastructure as code che da qualche parte devi scrivere quindi",
      "tokens": [
        14132,
        4873,
        23048,
        6896,
        382,
        3089,
        947,
        1120,
        38737,
        6975,
        31219,
        5545,
        5887,
        15727
      ],
      "temperature": 0,
      "avg_logprob": -0.22574829636958607,
      "compression_ratio": 1.8284518828451883,
      "no_speech_prob": 2.0494164587603336e-8
    },
    {
      "id": 416,
      "seek": 251456,
      "start": 2536.2799999999997,
      "end": 2541.82,
      "text": " secondo me si sta shiftando molto il fatto che una volta scriviamo tutto un sacco di",
      "tokens": [
        41601,
        385,
        1511,
        11135,
        5513,
        1806,
        16394,
        1930,
        23228,
        947,
        2002,
        18765,
        5545,
        85,
        7415,
        23048,
        517,
        4899,
        1291,
        1026
      ],
      "temperature": 0,
      "avg_logprob": -0.22574829636958607,
      "compression_ratio": 1.8284518828451883,
      "no_speech_prob": 2.0494164587603336e-8
    },
    {
      "id": 417,
      "seek": 254182,
      "start": 2541.82,
      "end": 2546.2400000000002,
      "text": " business logic che non era necessariamente business nel senso funzionale al business",
      "tokens": [
        1606,
        9952,
        947,
        2107,
        4249,
        2688,
        45149,
        1606,
        15373,
        3151,
        539,
        49345,
        313,
        1220,
        419,
        1606
      ],
      "temperature": 0,
      "avg_logprob": -0.22025666795335375,
      "compression_ratio": 1.8099173553719008,
      "no_speech_prob": 5.0223132319615615e-9
    },
    {
      "id": 418,
      "seek": 254182,
      "start": 2546.2400000000002,
      "end": 2550.8,
      "text": " ma era più funzionale all'infrastruttura però la scrive sottoforma di codice adesso",
      "tokens": [
        463,
        4249,
        10589,
        49345,
        313,
        1220,
        439,
        6,
        19920,
        4148,
        81,
        13478,
        2991,
        12673,
        635,
        5545,
        303,
        43754,
        837,
        64,
        1026,
        17656,
        573,
        39552
      ],
      "temperature": 0,
      "avg_logprob": -0.22025666795335375,
      "compression_ratio": 1.8099173553719008,
      "no_speech_prob": 5.0223132319615615e-9
    },
    {
      "id": 419,
      "seek": 254182,
      "start": 2550.8,
      "end": 2555,
      "text": " tutto quello lo stiamo delegando al cloud provider però in qualche modo al cloud provider",
      "tokens": [
        23048,
        22813,
        450,
        342,
        7415,
        15824,
        1806,
        419,
        4588,
        12398,
        12673,
        294,
        38737,
        16664,
        419,
        4588,
        12398
      ],
      "temperature": 0,
      "avg_logprob": -0.22025666795335375,
      "compression_ratio": 1.8099173553719008,
      "no_speech_prob": 5.0223132319615615e-9
    },
    {
      "id": 420,
      "seek": 254182,
      "start": 2555,
      "end": 2559.8,
      "text": " dobbiamo dire come mettere insieme tutti questi pezzi e quello diventa tutta infrastructure",
      "tokens": [
        360,
        6692,
        7415,
        1264,
        808,
        27812,
        323,
        1028,
        44940,
        19822,
        29729,
        520,
        89,
        3992,
        308,
        22813,
        3414,
        8938,
        3672,
        1328,
        6896
      ],
      "temperature": 0,
      "avg_logprob": -0.22025666795335375,
      "compression_ratio": 1.8099173553719008,
      "no_speech_prob": 5.0223132319615615e-9
    },
    {
      "id": 421,
      "seek": 254182,
      "start": 2559.8,
      "end": 2564.1600000000003,
      "text": " as code che da una parte bisogna imparare tutti gli strumenti dall'altra è comunque",
      "tokens": [
        382,
        3089,
        947,
        1120,
        2002,
        6975,
        40505,
        629,
        704,
        289,
        543,
        19822,
        17161,
        1056,
        2206,
        72,
        43351,
        6,
        38865,
        4873,
        45736
      ],
      "temperature": 0,
      "avg_logprob": -0.22025666795335375,
      "compression_ratio": 1.8099173553719008,
      "no_speech_prob": 5.0223132319615615e-9
    },
    {
      "id": 422,
      "seek": 256416,
      "start": 2564.16,
      "end": 2572.3999999999996,
      "text": " codice benché non codice logico ma più codice di diciamo dichiarativo insomma più di configurazione",
      "tokens": [
        17656,
        573,
        10638,
        526,
        2107,
        17656,
        573,
        3565,
        2789,
        463,
        10589,
        17656,
        573,
        1026,
        14285,
        7415,
        10390,
        9448,
        18586,
        1028,
        30243,
        10589,
        1026,
        22192,
        12928
      ],
      "temperature": 0,
      "avg_logprob": -0.2504043193778606,
      "compression_ratio": 1.6233183856502242,
      "no_speech_prob": 1.0693118612792318e-9
    },
    {
      "id": 423,
      "seek": 256416,
      "start": 2572.3999999999996,
      "end": 2576.92,
      "text": " che però va comunque messo su repository va mantenuto vanno fatte le CICD basate su",
      "tokens": [
        947,
        12673,
        2773,
        45736,
        2082,
        78,
        459,
        25841,
        2773,
        38417,
        8262,
        371,
        13484,
        4046,
        975,
        476,
        383,
        2532,
        35,
        987,
        473,
        459
      ],
      "temperature": 0,
      "avg_logprob": -0.2504043193778606,
      "compression_ratio": 1.6233183856502242,
      "no_speech_prob": 1.0693118612792318e-9
    },
    {
      "id": 424,
      "seek": 256416,
      "start": 2576.92,
      "end": 2582.52,
      "text": " quel codice vanno fatti i test eccetera eccetera quindi non so se sto andando per una tangente",
      "tokens": [
        7178,
        17656,
        573,
        371,
        13484,
        283,
        21515,
        741,
        1500,
        29613,
        20269,
        29613,
        20269,
        15727,
        2107,
        370,
        369,
        22784,
        293,
        1806,
        680,
        2002,
        10266,
        1576
      ],
      "temperature": 0,
      "avg_logprob": -0.2504043193778606,
      "compression_ratio": 1.6233183856502242,
      "no_speech_prob": 1.0693118612792318e-9
    },
    {
      "id": 425,
      "seek": 256416,
      "start": 2582.52,
      "end": 2585.8399999999997,
      "text": " invece di rispondere alla tua domanda ma questo è quello che mi viene in mente",
      "tokens": [
        36344,
        1026,
        2253,
        79,
        33447,
        11591,
        33578,
        3285,
        5575,
        463,
        10263,
        4873,
        22813,
        947,
        2752,
        19561,
        294,
        26577
      ],
      "temperature": 0,
      "avg_logprob": -0.2504043193778606,
      "compression_ratio": 1.6233183856502242,
      "no_speech_prob": 1.0693118612792318e-9
    },
    {
      "id": 426,
      "seek": 258584,
      "start": 2585.84,
      "end": 2601,
      "text": " ma scusate ti tiro in ballo un'altra un'altra cosa che di cui sto cercando una risposta",
      "tokens": [
        463,
        795,
        301,
        473,
        8757,
        44188,
        294,
        2594,
        78,
        517,
        6,
        38865,
        517,
        6,
        38865,
        10163,
        947,
        1026,
        22929,
        22784,
        36099,
        1806,
        2002,
        2253,
        79,
        8638
      ],
      "temperature": 0,
      "avg_logprob": -0.2111330765944261,
      "compression_ratio": 1.5976331360946745,
      "no_speech_prob": 1.646748160055722e-8
    },
    {
      "id": 427,
      "seek": 258584,
      "start": 2601,
      "end": 2608.2000000000003,
      "text": " in tutto questo i test come vengono fatti perché tralasciando i unit test quindi quando",
      "tokens": [
        294,
        23048,
        10263,
        741,
        1500,
        808,
        371,
        1501,
        8957,
        283,
        21515,
        14303,
        504,
        304,
        296,
        537,
        1806,
        741,
        4985,
        1500,
        15727,
        7770
      ],
      "temperature": 0,
      "avg_logprob": -0.2111330765944261,
      "compression_ratio": 1.5976331360946745,
      "no_speech_prob": 1.646748160055722e-8
    },
    {
      "id": 428,
      "seek": 258584,
      "start": 2608.2000000000003,
      "end": 2614.2000000000003,
      "text": " riesci a testare i singoli componenti le singole funzioni con tutte le best practice del caso",
      "tokens": [
        23932,
        537,
        257,
        1500,
        543,
        741,
        1522,
        9384,
        6542,
        72,
        476,
        1522,
        4812,
        49345,
        15273,
        416,
        38632,
        476,
        1151,
        3124,
        1103,
        9666
      ],
      "temperature": 0,
      "avg_logprob": -0.2111330765944261,
      "compression_ratio": 1.5976331360946745,
      "no_speech_prob": 1.646748160055722e-8
    },
    {
      "id": 429,
      "seek": 261420,
      "start": 2614.2,
      "end": 2623.7999999999997,
      "text": " però poi come fai a testare tutto tutto insieme come fai a testare il tutto il giro tutto",
      "tokens": [
        12673,
        19260,
        808,
        283,
        1301,
        257,
        1500,
        543,
        23048,
        23048,
        1028,
        44940,
        808,
        283,
        1301,
        257,
        1500,
        543,
        1930,
        23048,
        1930,
        1735,
        340,
        23048
      ],
      "temperature": 0,
      "avg_logprob": -0.22700584766476653,
      "compression_ratio": 1.5909090909090908,
      "no_speech_prob": 2.4720669955513586e-8
    },
    {
      "id": 430,
      "seek": 261420,
      "start": 2623.7999999999997,
      "end": 2633.08,
      "text": " il workflow che bisogna seguire che strategia ci si può adottare o si deve adottare con",
      "tokens": [
        1930,
        20993,
        947,
        40505,
        629,
        8878,
        621,
        947,
        5464,
        654,
        6983,
        1511,
        26526,
        614,
        1521,
        543,
        277,
        1511,
        17761,
        614,
        1521,
        543,
        416
      ],
      "temperature": 0,
      "avg_logprob": -0.22700584766476653,
      "compression_ratio": 1.5909090909090908,
      "no_speech_prob": 2.4720669955513586e-8
    },
    {
      "id": 431,
      "seek": 261420,
      "start": 2633.08,
      "end": 2634.96,
      "text": " AWS o in generale",
      "tokens": [
        17650,
        277,
        294,
        1337,
        1220
      ],
      "temperature": 0,
      "avg_logprob": -0.22700584766476653,
      "compression_ratio": 1.5909090909090908,
      "no_speech_prob": 2.4720669955513586e-8
    },
    {
      "id": 432,
      "seek": 261420,
      "start": 2634.96,
      "end": 2639.7599999999998,
      "text": " sì tra l'altro mi sono appena ricordato che non ho risposto alla domanda riguardo",
      "tokens": [
        49267,
        944,
        287,
        6,
        47484,
        2752,
        9259,
        724,
        4118,
        21040,
        765,
        2513,
        947,
        2107,
        1106,
        2253,
        79,
        22756,
        11591,
        3285,
        5575,
        8329,
        84,
        12850
      ],
      "temperature": 0,
      "avg_logprob": -0.22700584766476653,
      "compression_ratio": 1.5909090909090908,
      "no_speech_prob": 2.4720669955513586e-8
    },
    {
      "id": 433,
      "seek": 263976,
      "start": 2639.76,
      "end": 2645.44,
      "text": " la cloud abstraction quindi magari dei servizi che riescono a strarre il fatto che tu possa",
      "tokens": [
        635,
        4588,
        10823,
        26766,
        15727,
        49932,
        13874,
        1658,
        24300,
        947,
        23932,
        45846,
        257,
        1056,
        15531,
        1930,
        23228,
        947,
        2604,
        41564
      ],
      "temperature": 0,
      "avg_logprob": -0.23614436290303215,
      "compression_ratio": 1.744186046511628,
      "no_speech_prob": 1.0407752171204265e-7
    },
    {
      "id": 434,
      "seek": 263976,
      "start": 2645.44,
      "end": 2649.84,
      "text": " essere su AWS piuttosto che azure piuttosto che su google quindi cercherò di rispondere",
      "tokens": [
        19799,
        459,
        17650,
        3895,
        13478,
        22756,
        947,
        7883,
        540,
        3895,
        13478,
        22756,
        947,
        459,
        20742,
        15727,
        10146,
        6759,
        4293,
        1026,
        2253,
        79,
        33447
      ],
      "temperature": 0,
      "avg_logprob": -0.23614436290303215,
      "compression_ratio": 1.744186046511628,
      "no_speech_prob": 1.0407752171204265e-7
    },
    {
      "id": 435,
      "seek": 263976,
      "start": 2649.84,
      "end": 2655.2000000000003,
      "text": " anche includendo questo o ne riparliamo dopo però in generale quello del testing è uno",
      "tokens": [
        11585,
        1637,
        3999,
        10263,
        277,
        408,
        12782,
        6843,
        7415,
        35196,
        12673,
        294,
        1337,
        1220,
        22813,
        1103,
        4997,
        4873,
        8526
      ],
      "temperature": 0,
      "avg_logprob": -0.23614436290303215,
      "compression_ratio": 1.744186046511628,
      "no_speech_prob": 1.0407752171204265e-7
    },
    {
      "id": 436,
      "seek": 263976,
      "start": 2655.2000000000003,
      "end": 2661.0400000000004,
      "text": " dei temi sui quali secondo me ad oggi cioè ci sono varie pratiche però secondo non c'è",
      "tokens": [
        13874,
        1383,
        72,
        459,
        72,
        4101,
        72,
        41601,
        385,
        614,
        34768,
        41827,
        6983,
        9259,
        1374,
        414,
        28844,
        9304,
        12673,
        41601,
        2107,
        269,
        6,
        1462
      ],
      "temperature": 0,
      "avg_logprob": -0.23614436290303215,
      "compression_ratio": 1.744186046511628,
      "no_speech_prob": 1.0407752171204265e-7
    },
    {
      "id": 437,
      "seek": 263976,
      "start": 2661.0400000000004,
      "end": 2666.6800000000003,
      "text": " una pratica che è quella che su cui tutti diciamo sono d'accordo che sia il modo migliore",
      "tokens": [
        2002,
        28844,
        2262,
        947,
        4873,
        32234,
        947,
        459,
        22929,
        19822,
        14285,
        7415,
        9259,
        274,
        6,
        19947,
        78,
        947,
        25176,
        1930,
        16664,
        6186,
        2081,
        418
      ],
      "temperature": 0,
      "avg_logprob": -0.23614436290303215,
      "compression_ratio": 1.744186046511628,
      "no_speech_prob": 1.0407752171204265e-7
    },
    {
      "id": 438,
      "seek": 266668,
      "start": 2666.68,
      "end": 2672.8399999999997,
      "text": " di fare i test e di test parla in senso molto lato cioè banalmente non parliamo di test",
      "tokens": [
        1026,
        11994,
        741,
        1500,
        308,
        1026,
        1500,
        971,
        875,
        294,
        3151,
        539,
        16394,
        287,
        2513,
        41827,
        5643,
        304,
        4082,
        2107,
        971,
        49926,
        1026,
        1500
      ],
      "temperature": 0,
      "avg_logprob": -0.20198141683743695,
      "compression_ratio": 1.8214285714285714,
      "no_speech_prob": 4.075752357834972e-8
    },
    {
      "id": 439,
      "seek": 266668,
      "start": 2672.8399999999997,
      "end": 2678.72,
      "text": " automatizzati ma del fatto che tu hai scritto una riga di codice aggiuntiva e prima di deploiarla",
      "tokens": [
        28034,
        8072,
        6908,
        463,
        1103,
        23228,
        947,
        2604,
        21822,
        5918,
        34924,
        2002,
        8329,
        64,
        1026,
        17656,
        573,
        42254,
        2760,
        5931,
        308,
        19507,
        1026,
        368,
        21132,
        9448,
        875
      ],
      "temperature": 0,
      "avg_logprob": -0.20198141683743695,
      "compression_ratio": 1.8214285714285714,
      "no_speech_prob": 4.075752357834972e-8
    },
    {
      "id": 440,
      "seek": 266668,
      "start": 2678.72,
      "end": 2684.14,
      "text": " a qualche parte ti chiedi ma funziona fa quello che deve fare come la testo anche manualmente",
      "tokens": [
        257,
        38737,
        6975,
        8757,
        417,
        1091,
        72,
        463,
        49345,
        21758,
        2050,
        22813,
        947,
        17761,
        11994,
        808,
        635,
        1500,
        78,
        11585,
        9688,
        4082
      ],
      "temperature": 0,
      "avg_logprob": -0.20198141683743695,
      "compression_ratio": 1.8214285714285714,
      "no_speech_prob": 4.075752357834972e-8
    },
    {
      "id": 441,
      "seek": 266668,
      "start": 2684.14,
      "end": 2688.12,
      "text": " cioè non voglio necessariamente scrivere un test automatizzato ma banalmente voglio",
      "tokens": [
        41827,
        2107,
        31273,
        19987,
        2688,
        45149,
        5545,
        5887,
        517,
        1500,
        28034,
        8072,
        2513,
        463,
        5643,
        304,
        4082,
        31273,
        19987
      ],
      "temperature": 0,
      "avg_logprob": -0.20198141683743695,
      "compression_ratio": 1.8214285714285714,
      "no_speech_prob": 4.075752357834972e-8
    },
    {
      "id": 442,
      "seek": 266668,
      "start": 2688.12,
      "end": 2693.12,
      "text": " eseguire questo codice che ho cambiato nella mia macchina locale per vedere se effettivamente",
      "tokens": [
        785,
        1146,
        43612,
        10263,
        17656,
        573,
        947,
        1106,
        19569,
        2513,
        23878,
        21290,
        7912,
        339,
        1426,
        1628,
        1220,
        680,
        35373,
        369,
        1244,
        3093,
        23957
      ],
      "temperature": 0,
      "avg_logprob": -0.20198141683743695,
      "compression_ratio": 1.8214285714285714,
      "no_speech_prob": 4.075752357834972e-8
    },
    {
      "id": 443,
      "seek": 269312,
      "start": 2693.12,
      "end": 2700.56,
      "text": " fa quello che io penso che debba fare e banalmente questo è un tema che su cui ci sono 50 anni",
      "tokens": [
        2050,
        22813,
        947,
        19785,
        48005,
        947,
        3001,
        4231,
        11994,
        308,
        5643,
        304,
        4082,
        10263,
        4873,
        517,
        15854,
        947,
        459,
        22929,
        6983,
        9259,
        2625,
        31164
      ],
      "temperature": 0,
      "avg_logprob": -0.22940988893862124,
      "compression_ratio": 1.6630434782608696,
      "no_speech_prob": 3.71101442908639e-8
    },
    {
      "id": 444,
      "seek": 269312,
      "start": 2700.56,
      "end": 2706.2,
      "text": " di storia nel senso da quando esiste l'informatica si scrivono cose locale le esegui vedi se",
      "tokens": [
        1026,
        5967,
        654,
        15373,
        3151,
        539,
        1120,
        7770,
        785,
        8375,
        287,
        6,
        37811,
        267,
        2262,
        1511,
        5545,
        85,
        8957,
        30261,
        1628,
        1220,
        476,
        785,
        1146,
        3077,
        371,
        10323,
        369
      ],
      "temperature": 0,
      "avg_logprob": -0.22940988893862124,
      "compression_ratio": 1.6630434782608696,
      "no_speech_prob": 3.71101442908639e-8
    },
    {
      "id": 445,
      "seek": 269312,
      "start": 2706.2,
      "end": 2711.56,
      "text": " funzionano poi puoi anche scrivere test automatizzati ma è sempre stata quasi una cosa ovvia il",
      "tokens": [
        49345,
        313,
        3730,
        19260,
        2362,
        4869,
        11585,
        5545,
        5887,
        1500,
        28034,
        8072,
        6908,
        463,
        4873,
        9553,
        49554,
        20954,
        2002,
        10163,
        14187,
        11617,
        1930
      ],
      "temperature": 0,
      "avg_logprob": -0.22940988893862124,
      "compression_ratio": 1.6630434782608696,
      "no_speech_prob": 3.71101442908639e-8
    },
    {
      "id": 446,
      "seek": 269312,
      "start": 2711.56,
      "end": 2717.04,
      "text": " fatto di poter eseguire le cose locale a meno che magari facciamo un mega passi indietro",
      "tokens": [
        23228,
        1026,
        1847,
        260,
        785,
        1146,
        43612,
        476,
        30261,
        1628,
        1220,
        257,
        40236,
        947,
        49932,
        1915,
        42052,
        517,
        17986,
        1320,
        72,
        1016,
        1684,
        340
      ],
      "temperature": 0,
      "avg_logprob": -0.22940988893862124,
      "compression_ratio": 1.6630434782608696,
      "no_speech_prob": 3.71101442908639e-8
    },
    {
      "id": 447,
      "seek": 269312,
      "start": 2717.04,
      "end": 2722.3599999999997,
      "text": " quando c'erano i mainframe dovevi mandare il job però va beh dimentichiamoci magari",
      "tokens": [
        7770,
        269,
        6,
        260,
        3730,
        741,
        2135,
        17265,
        23287,
        4917,
        7411,
        543,
        1930,
        1691,
        12673,
        2773,
        1540,
        274,
        2328,
        480,
        7415,
        537,
        49932
      ],
      "temperature": 0,
      "avg_logprob": -0.22940988893862124,
      "compression_ratio": 1.6630434782608696,
      "no_speech_prob": 3.71101442908639e-8
    },
    {
      "id": 448,
      "seek": 272236,
      "start": 2722.36,
      "end": 2727.84,
      "text": " quella fase iniziale della storia dell'informatica e pensiamo magari anni un po' più recenti",
      "tokens": [
        32234,
        33931,
        294,
        590,
        25051,
        11618,
        5967,
        654,
        19781,
        6,
        37811,
        267,
        2262,
        308,
        6099,
        7415,
        49932,
        31164,
        517,
        714,
        6,
        10589,
        5162,
        72
      ],
      "temperature": 0,
      "avg_logprob": -0.2279042830834022,
      "compression_ratio": 1.6851851851851851,
      "no_speech_prob": 9.833211578325063e-9
    },
    {
      "id": 449,
      "seek": 272236,
      "start": 2727.84,
      "end": 2733.88,
      "text": " da sistemi operativi un po' più moderni e secondo me con serverless si va un po' a",
      "tokens": [
        1120,
        10555,
        13372,
        2208,
        10662,
        72,
        517,
        714,
        6,
        10589,
        4363,
        72,
        308,
        41601,
        385,
        416,
        7154,
        1832,
        1511,
        2773,
        517,
        714,
        6,
        257
      ],
      "temperature": 0,
      "avg_logprob": -0.2279042830834022,
      "compression_ratio": 1.6851851851851851,
      "no_speech_prob": 9.833211578325063e-9
    },
    {
      "id": 450,
      "seek": 272236,
      "start": 2733.88,
      "end": 2740.56,
      "text": " perdere quel tipo di abilità di eseguire le cose localmente nel senso che più deleghiamo",
      "tokens": [
        12611,
        323,
        7178,
        9746,
        1026,
        410,
        388,
        12445,
        1026,
        785,
        1146,
        43612,
        476,
        30261,
        2654,
        4082,
        15373,
        3151,
        539,
        947,
        10589,
        15824,
        71,
        7415
      ],
      "temperature": 0,
      "avg_logprob": -0.2279042830834022,
      "compression_ratio": 1.6851851851851851,
      "no_speech_prob": 9.833211578325063e-9
    },
    {
      "id": 451,
      "seek": 272236,
      "start": 2740.56,
      "end": 2746.8,
      "text": " cose al cloud provider più ci troviamo ad avere meno roba che scriviamo noi che effettivamente",
      "tokens": [
        30261,
        419,
        4588,
        12398,
        10589,
        6983,
        35449,
        7415,
        614,
        37914,
        40236,
        3870,
        64,
        947,
        5545,
        85,
        7415,
        22447,
        947,
        1244,
        3093,
        23957
      ],
      "temperature": 0,
      "avg_logprob": -0.2279042830834022,
      "compression_ratio": 1.6851851851851851,
      "no_speech_prob": 9.833211578325063e-9
    },
    {
      "id": 452,
      "seek": 274680,
      "start": 2746.8,
      "end": 2752.36,
      "text": " possiamo eseguire nel nostro ambiente locale perché per quando il cloud provider o terzi",
      "tokens": [
        44758,
        785,
        1146,
        43612,
        15373,
        35779,
        34957,
        1628,
        1220,
        14303,
        680,
        7770,
        1930,
        4588,
        12398,
        277,
        1796,
        3992
      ],
      "temperature": 0,
      "avg_logprob": -0.23640816898669226,
      "compression_ratio": 1.846774193548387,
      "no_speech_prob": 3.028839401508776e-8
    },
    {
      "id": 453,
      "seek": 274680,
      "start": 2752.36,
      "end": 2757.0800000000004,
      "text": " ti possono dare degli strumenti per simulare quello che andrà a fare il cloud provider",
      "tokens": [
        8757,
        43857,
        8955,
        32079,
        1056,
        2206,
        72,
        680,
        1034,
        425,
        543,
        22813,
        947,
        293,
        39212,
        257,
        11994,
        1930,
        4588,
        12398
      ],
      "temperature": 0,
      "avg_logprob": -0.23640816898669226,
      "compression_ratio": 1.846774193548387,
      "no_speech_prob": 3.028839401508776e-8
    },
    {
      "id": 454,
      "seek": 274680,
      "start": 2757.0800000000004,
      "end": 2763,
      "text": " comunque spesso sono delle simulazioni e comunque chiaramente non puoi eseguire un intero cloud",
      "tokens": [
        45736,
        637,
        5557,
        9259,
        16485,
        1034,
        425,
        27569,
        308,
        45736,
        47454,
        3439,
        2107,
        2362,
        4869,
        785,
        1146,
        43612,
        517,
        728,
        78,
        4588
      ],
      "temperature": 0,
      "avg_logprob": -0.23640816898669226,
      "compression_ratio": 1.846774193548387,
      "no_speech_prob": 3.028839401508776e-8
    },
    {
      "id": 455,
      "seek": 274680,
      "start": 2763,
      "end": 2768.2000000000003,
      "text": " provider nella tua macchina quindi ti ritroverai ad avere delle astrazioni che non necessariamente",
      "tokens": [
        12398,
        23878,
        33578,
        7912,
        339,
        1426,
        15727,
        8757,
        11289,
        340,
        331,
        1301,
        614,
        37914,
        16485,
        5357,
        424,
        89,
        15273,
        947,
        2107,
        2688,
        45149
      ],
      "temperature": 0,
      "avg_logprob": -0.23640816898669226,
      "compression_ratio": 1.846774193548387,
      "no_speech_prob": 3.028839401508776e-8
    },
    {
      "id": 456,
      "seek": 274680,
      "start": 2768.2000000000003,
      "end": 2772.36,
      "text": " vanno a compaciare al 100% con quello che poi ti troverai in produzione come ambiente",
      "tokens": [
        371,
        13484,
        257,
        715,
        64,
        537,
        543,
        419,
        2319,
        4,
        416,
        22813,
        947,
        19260,
        8757,
        4495,
        331,
        1301,
        294,
        1082,
        19706,
        808,
        34957
      ],
      "temperature": 0,
      "avg_logprob": -0.23640816898669226,
      "compression_ratio": 1.846774193548387,
      "no_speech_prob": 3.028839401508776e-8
    },
    {
      "id": 457,
      "seek": 277236,
      "start": 2772.36,
      "end": 2778.32,
      "text": " di esecuzione quindi ci sono tutta una serie di approcci anche un po' ibridi che sto vedendo",
      "tokens": [
        1026,
        785,
        3045,
        3334,
        5328,
        15727,
        6983,
        9259,
        3672,
        1328,
        2002,
        23030,
        1026,
        2075,
        66,
        537,
        11585,
        517,
        714,
        6,
        741,
        11349,
        72,
        947,
        22784,
        14267,
        3999
      ],
      "temperature": 0,
      "avg_logprob": -0.19307337783453032,
      "compression_ratio": 1.641025641025641,
      "no_speech_prob": 6.550328723875509e-9
    },
    {
      "id": 458,
      "seek": 277236,
      "start": 2778.32,
      "end": 2785.08,
      "text": " nel senso che c'è chi ancora apprezza il fatto di poter eseguire qualcosa localmente",
      "tokens": [
        15373,
        3151,
        539,
        947,
        269,
        6,
        1462,
        13228,
        30656,
        724,
        17693,
        2394,
        1930,
        23228,
        1026,
        1847,
        260,
        785,
        1146,
        43612,
        42400,
        2654,
        4082
      ],
      "temperature": 0,
      "avg_logprob": -0.19307337783453032,
      "compression_ratio": 1.641025641025641,
      "no_speech_prob": 6.550328723875509e-9
    },
    {
      "id": 459,
      "seek": 277236,
      "start": 2785.08,
      "end": 2791.3,
      "text": " benché il livello di fidelità con l'ambiente finale è sempre più distante quindi magari",
      "tokens": [
        10638,
        526,
        1930,
        1621,
        1913,
        1026,
        283,
        16189,
        12445,
        416,
        287,
        6,
        2173,
        8413,
        23510,
        4873,
        9553,
        10589,
        1483,
        2879,
        15727,
        49932
      ],
      "temperature": 0,
      "avg_logprob": -0.19307337783453032,
      "compression_ratio": 1.641025641025641,
      "no_speech_prob": 6.550328723875509e-9
    },
    {
      "id": 460,
      "seek": 277236,
      "start": 2791.3,
      "end": 2796.4,
      "text": " accetti che l'ambiente locale non è perfetto rispetto a quello che avrai su AWS o su un",
      "tokens": [
        1317,
        12495,
        947,
        287,
        6,
        2173,
        8413,
        1628,
        1220,
        2107,
        4873,
        13826,
        23778,
        2253,
        42801,
        257,
        22813,
        947,
        1305,
        34554,
        459,
        17650,
        277,
        459,
        517
      ],
      "temperature": 0,
      "avg_logprob": -0.19307337783453032,
      "compression_ratio": 1.641025641025641,
      "no_speech_prob": 6.550328723875509e-9
    },
    {
      "id": 461,
      "seek": 277236,
      "start": 2796.4,
      "end": 2800.84,
      "text": " altro cloud provider però comunque una prima astrazione mi permette di vedere se il mio",
      "tokens": [
        40924,
        4588,
        12398,
        12673,
        45736,
        2002,
        19507,
        5357,
        424,
        19706,
        2752,
        4784,
        3007,
        1026,
        35373,
        369,
        1930,
        29908
      ],
      "temperature": 0,
      "avg_logprob": -0.19307337783453032,
      "compression_ratio": 1.641025641025641,
      "no_speech_prob": 6.550328723875509e-9
    },
    {
      "id": 462,
      "seek": 280084,
      "start": 2800.84,
      "end": 2805.76,
      "text": " codice più o meno fa quello che deve fare dopodiché sto vedendo che c'è una tendenza",
      "tokens": [
        17656,
        573,
        10589,
        277,
        40236,
        2050,
        22813,
        947,
        17761,
        11994,
        21900,
        378,
        480,
        526,
        22784,
        14267,
        3999,
        269,
        675,
        269,
        6,
        1462,
        2002,
        3928,
        23691
      ],
      "temperature": 0,
      "avg_logprob": -0.20150874555110931,
      "compression_ratio": 1.8048780487804879,
      "no_speech_prob": 9.184845595200386e-8
    },
    {
      "id": 463,
      "seek": 280084,
      "start": 2805.76,
      "end": 2812.6800000000003,
      "text": " a cercare di ridurre quanto più possibile i tempi di deployment e far sì che l'ambiente",
      "tokens": [
        257,
        10146,
        5685,
        1026,
        3973,
        374,
        265,
        17820,
        10589,
        50184,
        741,
        18274,
        72,
        1026,
        19317,
        308,
        1400,
        49267,
        947,
        287,
        6,
        2173,
        8413
      ],
      "temperature": 0,
      "avg_logprob": -0.20150874555110931,
      "compression_ratio": 1.8048780487804879,
      "no_speech_prob": 9.184845595200386e-8
    },
    {
      "id": 464,
      "seek": 280084,
      "start": 2812.6800000000003,
      "end": 2817.2000000000003,
      "text": " cloud diventa il tuo ambiente di sviluppo chiaramente non stiamo parlando di rilasciare",
      "tokens": [
        4588,
        3414,
        8938,
        1930,
        45352,
        34957,
        1026,
        17342,
        388,
        10504,
        78,
        47454,
        3439,
        2107,
        342,
        7415,
        971,
        16201,
        1026,
        367,
        388,
        296,
        537,
        543
      ],
      "temperature": 0,
      "avg_logprob": -0.20150874555110931,
      "compression_ratio": 1.8048780487804879,
      "no_speech_prob": 9.184845595200386e-8
    },
    {
      "id": 465,
      "seek": 280084,
      "start": 2817.2000000000003,
      "end": 2822.4,
      "text": " di continuo in produzione ma di avere un ambiente cloud di sviluppo che è molto più simile",
      "tokens": [
        1026,
        2993,
        78,
        294,
        1082,
        19706,
        463,
        1026,
        37914,
        517,
        34957,
        4588,
        1026,
        17342,
        388,
        10504,
        78,
        947,
        4873,
        16394,
        10589,
        1034,
        794
      ],
      "temperature": 0,
      "avg_logprob": -0.20150874555110931,
      "compression_ratio": 1.8048780487804879,
      "no_speech_prob": 9.184845595200386e-8
    },
    {
      "id": 466,
      "seek": 280084,
      "start": 2822.4,
      "end": 2828.7200000000003,
      "text": " all'ambiente che avrai in produzione e il problema a quel punto dipende quanto riesci",
      "tokens": [
        439,
        6,
        2173,
        8413,
        947,
        1305,
        34554,
        294,
        1082,
        19706,
        308,
        1930,
        12395,
        257,
        7178,
        14326,
        10460,
        5445,
        17820,
        23932,
        537
      ],
      "temperature": 0,
      "avg_logprob": -0.20150874555110931,
      "compression_ratio": 1.8048780487804879,
      "no_speech_prob": 9.184845595200386e-8
    },
    {
      "id": 467,
      "seek": 282872,
      "start": 2828.72,
      "end": 2834.3199999999997,
      "text": " a aggiornare quel codice in cloud velocemente così da avere un feedback loop che più vicino",
      "tokens": [
        257,
        42254,
        1865,
        543,
        7178,
        17656,
        573,
        294,
        4588,
        1241,
        752,
        384,
        4082,
        23278,
        1120,
        37914,
        517,
        5824,
        6367,
        947,
        10589,
        26031,
        2982
      ],
      "temperature": 0,
      "avg_logprob": -0.17762356234672375,
      "compression_ratio": 1.6134751773049645,
      "no_speech_prob": 1.1793572696205956e-7
    },
    {
      "id": 468,
      "seek": 282872,
      "start": 2834.3199999999997,
      "end": 2839.12,
      "text": " possibile a quello di eseguire tutto localmente e ad oggi secondo me non c'è una soluzione",
      "tokens": [
        50184,
        257,
        22813,
        1026,
        785,
        1146,
        43612,
        23048,
        2654,
        4082,
        308,
        614,
        34768,
        41601,
        385,
        2107,
        269,
        6,
        1462,
        2002,
        1404,
        3334,
        5328
      ],
      "temperature": 0,
      "avg_logprob": -0.17762356234672375,
      "compression_ratio": 1.6134751773049645,
      "no_speech_prob": 1.1793572696205956e-7
    },
    {
      "id": 469,
      "seek": 282872,
      "start": 2839.12,
      "end": 2844.1,
      "text": " perfetta benché se andiamo a vedere alcuni nuovi tool che hanno inserito all'interno",
      "tokens": [
        13826,
        16593,
        10638,
        526,
        369,
        293,
        7415,
        257,
        35373,
        20005,
        24307,
        37802,
        4917,
        2290,
        947,
        26595,
        1028,
        260,
        3528,
        439,
        6,
        5106,
        1771
      ],
      "temperature": 0,
      "avg_logprob": -0.17762356234672375,
      "compression_ratio": 1.6134751773049645,
      "no_speech_prob": 1.1793572696205956e-7
    },
    {
      "id": 470,
      "seek": 282872,
      "start": 2844.1,
      "end": 2850.72,
      "text": " di SAM o CDK cercano in qualche modo di farti rilasciare il codice o addirittura di sincronizzartelo",
      "tokens": [
        1026,
        9617,
        277,
        6743,
        42,
        36099,
        3730,
        294,
        38737,
        16664,
        1026,
        24575,
        72,
        367,
        388,
        296,
        537,
        543,
        1930,
        17656,
        573,
        277,
        909,
        347,
        593,
        2991,
        1026,
        3343,
        66,
        2044,
        8072,
        446,
        10590
      ],
      "temperature": 0,
      "avg_logprob": -0.17762356234672375,
      "compression_ratio": 1.6134751773049645,
      "no_speech_prob": 1.1793572696205956e-7
    },
    {
      "id": 471,
      "seek": 282872,
      "start": 2850.72,
      "end": 2855.14,
      "text": " quasi come se fosse un watch live in modo più veloce possibile in modo che riduci",
      "tokens": [
        20954,
        808,
        369,
        24528,
        517,
        1159,
        1621,
        294,
        16664,
        10589,
        1241,
        752,
        384,
        50184,
        294,
        16664,
        947,
        3973,
        34144
      ],
      "temperature": 0,
      "avg_logprob": -0.17762356234672375,
      "compression_ratio": 1.6134751773049645,
      "no_speech_prob": 1.1793572696205956e-7
    },
    {
      "id": 472,
      "seek": 285514,
      "start": 2855.14,
      "end": 2859.8799999999997,
      "text": " quel tipo di feedback loop e quello è un altro approccio l'altro approccio ancora è",
      "tokens": [
        7178,
        9746,
        1026,
        5824,
        6367,
        308,
        22813,
        4873,
        517,
        40924,
        2075,
        66,
        8529,
        287,
        6,
        47484,
        2075,
        66,
        8529,
        30656,
        4873
      ],
      "temperature": 0,
      "avg_logprob": -0.20411379807660368,
      "compression_ratio": 1.8838028169014085,
      "no_speech_prob": 3.274959325949567e-8
    },
    {
      "id": 473,
      "seek": 285514,
      "start": 2859.8799999999997,
      "end": 2865.3599999999997,
      "text": " quello di creare appunto dei test automatizzati che prima di fare un rilascio in produzione",
      "tokens": [
        22813,
        1026,
        1197,
        543,
        724,
        24052,
        13874,
        1500,
        28034,
        8072,
        6908,
        947,
        19507,
        1026,
        11994,
        517,
        367,
        388,
        296,
        8529,
        294,
        1082,
        19706
      ],
      "temperature": 0,
      "avg_logprob": -0.20411379807660368,
      "compression_ratio": 1.8838028169014085,
      "no_speech_prob": 3.274959325949567e-8
    },
    {
      "id": 474,
      "seek": 285514,
      "start": 2865.3599999999997,
      "end": 2870.8799999999997,
      "text": " effettivamente stanno testando tutto quello che tu hai fatto in un ambiente che è totalmente",
      "tokens": [
        1244,
        3093,
        23957,
        342,
        13484,
        1500,
        1806,
        23048,
        22813,
        947,
        2604,
        21822,
        23228,
        294,
        517,
        34957,
        947,
        4873,
        30865
      ],
      "temperature": 0,
      "avg_logprob": -0.20411379807660368,
      "compression_ratio": 1.8838028169014085,
      "no_speech_prob": 3.274959325949567e-8
    },
    {
      "id": 475,
      "seek": 285514,
      "start": 2870.8799999999997,
      "end": 2874.3599999999997,
      "text": " uguale a quello che avrai in produzione e ti danno un feedback sì tutti i test sono",
      "tokens": [
        10743,
        901,
        68,
        257,
        22813,
        947,
        1305,
        34554,
        294,
        1082,
        19706,
        308,
        8757,
        3594,
        78,
        517,
        5824,
        49267,
        19822,
        741,
        1500,
        9259
      ],
      "temperature": 0,
      "avg_logprob": -0.20411379807660368,
      "compression_ratio": 1.8838028169014085,
      "no_speech_prob": 3.274959325949567e-8
    },
    {
      "id": 476,
      "seek": 285514,
      "start": 2874.3599999999997,
      "end": 2879.2799999999997,
      "text": " passati allora procedo con il rilascio in produzione oppure no e secondo me non c'è",
      "tokens": [
        1320,
        6908,
        44141,
        6682,
        78,
        416,
        1930,
        367,
        388,
        296,
        8529,
        294,
        1082,
        19706,
        1458,
        540,
        572,
        308,
        41601,
        385,
        2107,
        269,
        6,
        1462
      ],
      "temperature": 0,
      "avg_logprob": -0.20411379807660368,
      "compression_ratio": 1.8838028169014085,
      "no_speech_prob": 3.274959325949567e-8
    },
    {
      "id": 477,
      "seek": 285514,
      "start": 2879.2799999999997,
      "end": 2884.2799999999997,
      "text": " una pratica perfetta ribadisco questo l'insieme di tutte queste pratiche ti può dare un buon",
      "tokens": [
        2002,
        28844,
        2262,
        13826,
        16593,
        9162,
        345,
        8610,
        10263,
        287,
        6,
        1292,
        44940,
        1026,
        38632,
        35455,
        28844,
        9304,
        8757,
        26526,
        8955,
        517,
        758,
        266
      ],
      "temperature": 0,
      "avg_logprob": -0.20411379807660368,
      "compression_ratio": 1.8838028169014085,
      "no_speech_prob": 3.274959325949567e-8
    },
    {
      "id": 478,
      "seek": 288428,
      "start": 2884.28,
      "end": 2888.84,
      "text": " livello di fiducia nel fatto che se tu fai una modifica poi quando andrai a portare in",
      "tokens": [
        1621,
        1913,
        1026,
        24553,
        84,
        2755,
        15373,
        23228,
        947,
        369,
        2604,
        283,
        1301,
        2002,
        1072,
        43377,
        19260,
        7770,
        293,
        34554,
        257,
        2436,
        543,
        294
      ],
      "temperature": 0,
      "avg_logprob": -0.3197355637183556,
      "compression_ratio": 1.6889952153110048,
      "no_speech_prob": 3.6534789416009517e-8
    },
    {
      "id": 479,
      "seek": 288428,
      "start": 2888.84,
      "end": 2895.84,
      "text": " produzione non hai sorprese particolari e giusto per inserirmi nel discorso di cloud",
      "tokens": [
        1082,
        19706,
        2107,
        21822,
        9359,
        3712,
        405,
        1276,
        401,
        3504,
        308,
        1735,
        48260,
        680,
        1028,
        260,
        49110,
        15373,
        2983,
        284,
        539,
        1026,
        4588
      ],
      "temperature": 0,
      "avg_logprob": -0.3197355637183556,
      "compression_ratio": 1.6889952153110048,
      "no_speech_prob": 3.6534789416009517e-8
    },
    {
      "id": 480,
      "seek": 288428,
      "start": 2895.84,
      "end": 2902.88,
      "text": " abstraction tutto questo è molto cloud specifica ad oggi nel senso noi andiamo a utilizzare",
      "tokens": [
        10823,
        26766,
        23048,
        10263,
        4873,
        16394,
        4588,
        2685,
        64,
        614,
        34768,
        15373,
        3151,
        539,
        22447,
        293,
        7415,
        257,
        40355,
        543
      ],
      "temperature": 0,
      "avg_logprob": -0.3197355637183556,
      "compression_ratio": 1.6889952153110048,
      "no_speech_prob": 3.6534789416009517e-8
    },
    {
      "id": 481,
      "seek": 288428,
      "start": 2902.88,
      "end": 2909.0400000000004,
      "text": " step function piuttosto che lambda piuttosto che dynamo db piuttosto che sqs oss e nesso",
      "tokens": [
        1823,
        2445,
        3895,
        13478,
        22756,
        947,
        13607,
        3895,
        13478,
        22756,
        947,
        5999,
        78,
        274,
        65,
        3895,
        13478,
        22756,
        947,
        262,
        80,
        82,
        3003,
        82,
        308,
        39787,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.3197355637183556,
      "compression_ratio": 1.6889952153110048,
      "no_speech_prob": 3.6534789416009517e-8
    },
    {
      "id": 482,
      "seek": 290904,
      "start": 2909.04,
      "end": 2914.8,
      "text": " questi servizi che diciamo sono tra l'altro da quelli più base che un po' tutti utilizzano",
      "tokens": [
        29729,
        1658,
        24300,
        947,
        14285,
        7415,
        9259,
        944,
        287,
        6,
        47484,
        1120,
        631,
        16320,
        10589,
        3096,
        947,
        517,
        714,
        6,
        19822,
        40355,
        3730
      ],
      "temperature": 0,
      "avg_logprob": -0.2948855209350586,
      "compression_ratio": 1.625,
      "no_speech_prob": 9.833207137432964e-9
    },
    {
      "id": 483,
      "seek": 290904,
      "start": 2914.8,
      "end": 2919.8,
      "text": " sqs sono fondamentalmente diversi se vai a utilizzare gli equivalenti su azure o su google",
      "tokens": [
        262,
        80,
        82,
        9259,
        9557,
        44538,
        4082,
        6111,
        72,
        369,
        4405,
        257,
        40355,
        543,
        17161,
        10344,
        72,
        459,
        7883,
        540,
        277,
        459,
        20742
      ],
      "temperature": 0,
      "avg_logprob": -0.2948855209350586,
      "compression_ratio": 1.625,
      "no_speech_prob": 9.833207137432964e-9
    },
    {
      "id": 484,
      "seek": 290904,
      "start": 2919.8,
      "end": 2928,
      "text": " proprio a livello di api quindi banalmente voler utilizzare una abstrazione e sì magari",
      "tokens": [
        28203,
        257,
        1621,
        1913,
        1026,
        1882,
        72,
        15727,
        5643,
        304,
        4082,
        1996,
        260,
        40355,
        543,
        2002,
        410,
        9733,
        12928,
        308,
        49267,
        49932
      ],
      "temperature": 0,
      "avg_logprob": -0.2948855209350586,
      "compression_ratio": 1.625,
      "no_speech_prob": 9.833207137432964e-9
    },
    {
      "id": 485,
      "seek": 290904,
      "start": 2928,
      "end": 2936.06,
      "text": " ne esistono ma praticamente ti vai a a portare il tuo problema un minimo comune denominatore",
      "tokens": [
        408,
        785,
        468,
        8957,
        463,
        45734,
        8757,
        4405,
        257,
        257,
        2436,
        543,
        1930,
        45352,
        12395,
        517,
        4464,
        78,
        395,
        2613,
        16244,
        43148
      ],
      "temperature": 0,
      "avg_logprob": -0.2948855209350586,
      "compression_ratio": 1.625,
      "no_speech_prob": 9.833207137432964e-9
    },
    {
      "id": 486,
      "seek": 293606,
      "start": 2936.06,
      "end": 2941,
      "text": " di funzionalità che tutti supportano e ti stai perdendo i vantaggi specifici ogni cloud",
      "tokens": [
        1026,
        49345,
        1966,
        12445,
        947,
        19822,
        1406,
        3730,
        308,
        8757,
        342,
        1301,
        12611,
        3999,
        741,
        371,
        394,
        46893,
        2685,
        72,
        33189,
        4588
      ],
      "temperature": 0,
      "avg_logprob": -0.22274025150986967,
      "compression_ratio": 1.693798449612403,
      "no_speech_prob": 1.0907238845447864e-7
    },
    {
      "id": 487,
      "seek": 293606,
      "start": 2941,
      "end": 2946.88,
      "text": " provider quindi forse un discorso che da una parte sconsiglierei dall'altra possiamo pure",
      "tokens": [
        12398,
        15727,
        337,
        405,
        517,
        2983,
        284,
        539,
        947,
        1120,
        2002,
        6975,
        795,
        892,
        328,
        2081,
        40256,
        43351,
        6,
        38865,
        44758,
        6075
      ],
      "temperature": 0,
      "avg_logprob": -0.22274025150986967,
      "compression_ratio": 1.693798449612403,
      "no_speech_prob": 1.0907238845447864e-7
    },
    {
      "id": 488,
      "seek": 293606,
      "start": 2946.88,
      "end": 2950.7599999999998,
      "text": " andare a parlare di kubernetes di tutto quel tipo di abstrazione lì che un po' cerca di",
      "tokens": [
        42742,
        257,
        13734,
        543,
        1026,
        350,
        22457,
        1026,
        23048,
        7178,
        9746,
        1026,
        410,
        9733,
        12928,
        287,
        4749,
        947,
        517,
        714,
        6,
        26770,
        1026
      ],
      "temperature": 0,
      "avg_logprob": -0.22274025150986967,
      "compression_ratio": 1.693798449612403,
      "no_speech_prob": 1.0907238845447864e-7
    },
    {
      "id": 489,
      "seek": 293606,
      "start": 2950.7599999999998,
      "end": 2956.08,
      "text": " risolvere quel problema di un ambiente un po' più universale che è più semplice da",
      "tokens": [
        2253,
        401,
        5887,
        7178,
        12395,
        1026,
        517,
        34957,
        517,
        714,
        6,
        10589,
        5950,
        1220,
        947,
        4873,
        10589,
        4361,
        564,
        573,
        1120
      ],
      "temperature": 0,
      "avg_logprob": -0.22274025150986967,
      "compression_ratio": 1.693798449612403,
      "no_speech_prob": 1.0907238845447864e-7
    },
    {
      "id": 490,
      "seek": 293606,
      "start": 2956.08,
      "end": 2959.7999999999997,
      "text": " emulare localmente ed è anche un po' più uniforme quando poi lo andiamo a portare",
      "tokens": [
        846,
        425,
        543,
        2654,
        4082,
        1257,
        4873,
        11585,
        517,
        714,
        6,
        10589,
        9452,
        68,
        7770,
        19260,
        450,
        293,
        7415,
        257,
        2436,
        543
      ],
      "temperature": 0,
      "avg_logprob": -0.22274025150986967,
      "compression_ratio": 1.693798449612403,
      "no_speech_prob": 1.0907238845447864e-7
    },
    {
      "id": 491,
      "seek": 295980,
      "start": 2959.8,
      "end": 2967.7200000000003,
      "text": " in produzione sul cloud spero di aver risposto senza dire cosa no no no hai risposto benissimo",
      "tokens": [
        294,
        1082,
        19706,
        17603,
        4588,
        24152,
        78,
        1026,
        18247,
        2253,
        79,
        22756,
        36208,
        1264,
        10163,
        572,
        572,
        572,
        21822,
        2253,
        79,
        22756,
        3271,
        34966
      ],
      "temperature": 0,
      "avg_logprob": -0.28455473737018866,
      "compression_ratio": 1.6453488372093024,
      "no_speech_prob": 1.3363813877731445e-7
    },
    {
      "id": 492,
      "seek": 295980,
      "start": 2967.7200000000003,
      "end": 2976.84,
      "text": " che secondo me quello che evidenziate è importante cioè per diventare cloud agnostic andiamo",
      "tokens": [
        947,
        41601,
        385,
        22813,
        947,
        43699,
        3992,
        473,
        4873,
        9416,
        41827,
        680,
        3414,
        317,
        543,
        4588,
        623,
        77,
        19634,
        293,
        7415
      ],
      "temperature": 0,
      "avg_logprob": -0.28455473737018866,
      "compression_ratio": 1.6453488372093024,
      "no_speech_prob": 1.3363813877731445e-7
    },
    {
      "id": 493,
      "seek": 295980,
      "start": 2976.84,
      "end": 2983.44,
      "text": " a costruire una un ulteriore livello d'astrazione sopra una serie di livelli d'astrazione che",
      "tokens": [
        257,
        2063,
        894,
        621,
        2002,
        517,
        20352,
        34345,
        418,
        1621,
        1913,
        274,
        6,
        525,
        424,
        19706,
        370,
        43255,
        2002,
        23030,
        1026,
        1621,
        16320,
        274,
        6,
        525,
        424,
        19706,
        947
      ],
      "temperature": 0,
      "avg_logprob": -0.28455473737018866,
      "compression_ratio": 1.6453488372093024,
      "no_speech_prob": 1.3363813877731445e-7
    },
    {
      "id": 494,
      "seek": 298344,
      "start": 2983.44,
      "end": 2989.84,
      "text": " alla fine diventa astrale all'astratto per cui si può con tool come kubernetes in modo",
      "tokens": [
        11591,
        2489,
        3414,
        8938,
        5357,
        2155,
        68,
        419,
        75,
        6,
        525,
        4481,
        1353,
        680,
        22929,
        1511,
        26526,
        416,
        2290,
        808,
        350,
        22457,
        294,
        16664
      ],
      "temperature": 0,
      "avg_logprob": -0.29829174617551407,
      "compression_ratio": 1.5411255411255411,
      "no_speech_prob": 2.1355269552714162e-7
    },
    {
      "id": 495,
      "seek": 298344,
      "start": 2989.84,
      "end": 2996.44,
      "text": " più pragmatico eliminiamo una serie di livelli d'astrazione creandone uno unico o comunque",
      "tokens": [
        10589,
        46904,
        78,
        7892,
        7415,
        2002,
        23030,
        1026,
        1621,
        16320,
        274,
        6,
        525,
        424,
        19706,
        1197,
        474,
        546,
        8526,
        517,
        2789,
        277,
        45736
      ],
      "temperature": 0,
      "avg_logprob": -0.29829174617551407,
      "compression_ratio": 1.5411255411255411,
      "no_speech_prob": 2.1355269552714162e-7
    },
    {
      "id": 496,
      "seek": 298344,
      "start": 2996.44,
      "end": 3003.12,
      "text": " un quasi layer unico d'astrazione. La ricerca del cloud agnostic è più una cosa che i",
      "tokens": [
        517,
        20954,
        4583,
        517,
        2789,
        274,
        6,
        525,
        424,
        19706,
        13,
        2369,
        21040,
        36127,
        1103,
        4588,
        623,
        77,
        19634,
        4873,
        10589,
        2002,
        10163,
        947,
        741
      ],
      "temperature": 0,
      "avg_logprob": -0.29829174617551407,
      "compression_ratio": 1.5411255411255411,
      "no_speech_prob": 2.1355269552714162e-7
    },
    {
      "id": 497,
      "seek": 298344,
      "start": 3003.12,
      "end": 3010.2000000000003,
      "text": " dev o i devops cercano perché dice io vorrei deployare questo su AWS e poi domani senza",
      "tokens": [
        1905,
        277,
        741,
        1905,
        3370,
        36099,
        3730,
        14303,
        10313,
        19785,
        4245,
        10271,
        1367,
        752,
        88,
        543,
        10263,
        459,
        17650,
        308,
        19260,
        3285,
        3782,
        36208
      ],
      "temperature": 0,
      "avg_logprob": -0.29829174617551407,
      "compression_ratio": 1.5411255411255411,
      "no_speech_prob": 2.1355269552714162e-7
    },
    {
      "id": 498,
      "seek": 301020,
      "start": 3010.2,
      "end": 3015.64,
      "text": " cambiare nulla voglio deploiarlo su google cloud però nel frattempo amazon e google",
      "tokens": [
        19569,
        543,
        18184,
        64,
        31273,
        19987,
        368,
        21132,
        9448,
        752,
        459,
        20742,
        4588,
        12673,
        15373,
        431,
        1591,
        443,
        2259,
        47010,
        308,
        20742
      ],
      "temperature": 0,
      "avg_logprob": -0.4133160909016927,
      "compression_ratio": 1.697674418604651,
      "no_speech_prob": 2.3588620834402718e-8
    },
    {
      "id": 499,
      "seek": 301020,
      "start": 3015.64,
      "end": 3021.12,
      "text": " fanno in modo che questa cosa non sia possibile perché loro vogliono il lock in quindi io",
      "tokens": [
        283,
        13484,
        294,
        16664,
        947,
        16540,
        10163,
        2107,
        25176,
        50184,
        14303,
        28810,
        31273,
        75,
        49020,
        1930,
        4017,
        294,
        15727,
        19785
      ],
      "temperature": 0,
      "avg_logprob": -0.4133160909016927,
      "compression_ratio": 1.697674418604651,
      "no_speech_prob": 2.3588620834402718e-8
    },
    {
      "id": 500,
      "seek": 301020,
      "start": 3021.12,
      "end": 3026.8599999999997,
      "text": " quando avevo negli ultimi mesi in near form sono passato a fare il devops avevo sentito",
      "tokens": [
        7770,
        3472,
        3080,
        2485,
        2081,
        3725,
        10121,
        3813,
        72,
        294,
        2651,
        1254,
        9259,
        1320,
        2513,
        257,
        11994,
        1930,
        1905,
        3370,
        3472,
        3080,
        2279,
        3528
      ],
      "temperature": 0,
      "avg_logprob": -0.4133160909016927,
      "compression_ratio": 1.697674418604651,
      "no_speech_prob": 2.3588620834402718e-8
    },
    {
      "id": 501,
      "seek": 301020,
      "start": 3026.8599999999997,
      "end": 3032.68,
      "text": " di questa terra fanno detto posso deployare tutto dove mi pare e no sei su AWS fai la",
      "tokens": [
        1026,
        16540,
        26298,
        283,
        13484,
        368,
        83,
        1353,
        22501,
        368,
        21132,
        88,
        543,
        23048,
        23287,
        2752,
        7448,
        308,
        572,
        10842,
        459,
        17650,
        283,
        1301,
        635
      ],
      "temperature": 0,
      "avg_logprob": -0.4133160909016927,
      "compression_ratio": 1.697674418604651,
      "no_speech_prob": 2.3588620834402718e-8
    },
    {
      "id": 502,
      "seek": 301020,
      "start": 3032.68,
      "end": 3038.6,
      "text": " lambda e fai la mia game, sei su google fai altre cose e ti perdi i vantaggi quindi devi",
      "tokens": [
        13607,
        308,
        283,
        1301,
        220,
        875,
        21290,
        1216,
        11,
        10842,
        459,
        20742,
        283,
        1301,
        34983,
        30261,
        308,
        8757,
        680,
        4504,
        741,
        371,
        394,
        46893,
        15727,
        31219
      ],
      "temperature": 0,
      "avg_logprob": -0.4133160909016927,
      "compression_ratio": 1.697674418604651,
      "no_speech_prob": 2.3588620834402718e-8
    },
    {
      "id": 503,
      "seek": 303860,
      "start": 3038.6,
      "end": 3044.04,
      "text": " scrivere sempre due volte il codice però è chiaro che amazon ha tutto l'interesse",
      "tokens": [
        5545,
        5887,
        9553,
        3462,
        37801,
        1930,
        17656,
        573,
        12673,
        4873,
        47454,
        78,
        947,
        47010,
        324,
        23048,
        287,
        6,
        5106,
        7357
      ],
      "temperature": 0,
      "avg_logprob": -0.2911062849328873,
      "compression_ratio": 1.5701357466063348,
      "no_speech_prob": 3.307580698219681e-7
    },
    {
      "id": 504,
      "seek": 303860,
      "start": 3044.04,
      "end": 3053.36,
      "text": " per marketizzare i propri vantaggi e fare in modo che siamo diversi da quelli di google",
      "tokens": [
        680,
        2142,
        8072,
        543,
        741,
        40465,
        371,
        394,
        46893,
        308,
        11994,
        294,
        16664,
        947,
        33459,
        6111,
        72,
        1120,
        631,
        16320,
        1026,
        20742
      ],
      "temperature": 0,
      "avg_logprob": -0.2911062849328873,
      "compression_ratio": 1.5701357466063348,
      "no_speech_prob": 3.307580698219681e-7
    },
    {
      "id": 505,
      "seek": 303860,
      "start": 3053.36,
      "end": 3058.6,
      "text": " perché poi dopo deve essere più difficile nella loro ottica per il cliente spostarsi",
      "tokens": [
        14303,
        19260,
        35196,
        17761,
        19799,
        10589,
        26607,
        23878,
        28810,
        42772,
        2262,
        680,
        1930,
        6423,
        68,
        637,
        555,
        32742
      ],
      "temperature": 0,
      "avg_logprob": -0.2911062849328873,
      "compression_ratio": 1.5701357466063348,
      "no_speech_prob": 3.307580698219681e-7
    },
    {
      "id": 506,
      "seek": 303860,
      "start": 3058.6,
      "end": 3065.7599999999998,
      "text": " su google perché se no non ci sarebbe business quindi è un po' una lotta un po' ibari.",
      "tokens": [
        459,
        20742,
        14303,
        369,
        572,
        2107,
        6983,
        38706,
        39042,
        1606,
        15727,
        4873,
        517,
        714,
        6,
        2002,
        38144,
        517,
        714,
        6,
        741,
        5356,
        72,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2911062849328873,
      "compression_ratio": 1.5701357466063348,
      "no_speech_prob": 3.307580698219681e-7
    },
    {
      "id": 507,
      "seek": 306576,
      "start": 3065.76,
      "end": 3078.0400000000004,
      "text": " Devo dire che spostando un po' il focus se dovessi fermarmi e pensare al serverless",
      "tokens": [
        1346,
        3080,
        1264,
        947,
        637,
        555,
        1806,
        517,
        714,
        6,
        1930,
        1879,
        369,
        360,
        977,
        7691,
        26558,
        289,
        3057,
        308,
        6099,
        543,
        419,
        7154,
        1832
      ],
      "temperature": 0,
      "avg_logprob": -0.2899032984024439,
      "compression_ratio": 1.4406779661016949,
      "no_speech_prob": 2.8616278235915615e-9
    },
    {
      "id": 508,
      "seek": 306576,
      "start": 3078.0400000000004,
      "end": 3088.5200000000004,
      "text": " oggi credo che molto del boost è stato anche dato dall'apparire nel mercato di tutto",
      "tokens": [
        34768,
        3864,
        78,
        947,
        16394,
        1103,
        9194,
        4873,
        29657,
        11585,
        46971,
        43351,
        6,
        1746,
        289,
        621,
        15373,
        10811,
        2513,
        1026,
        23048
      ],
      "temperature": 0,
      "avg_logprob": -0.2899032984024439,
      "compression_ratio": 1.4406779661016949,
      "no_speech_prob": 2.8616278235915615e-9
    },
    {
      "id": 509,
      "seek": 306576,
      "start": 3088.5200000000004,
      "end": 3094.48,
      "text": " ciò che riguarda il gem stack quindi city stati, ship building, ridurre al minimo la",
      "tokens": [
        6983,
        4293,
        947,
        8329,
        16981,
        64,
        1930,
        7173,
        8630,
        15727,
        2307,
        2219,
        72,
        11,
        5374,
        2390,
        11,
        3973,
        374,
        265,
        419,
        4464,
        78,
        635
      ],
      "temperature": 0,
      "avg_logprob": -0.2899032984024439,
      "compression_ratio": 1.4406779661016949,
      "no_speech_prob": 2.8616278235915615e-9
    },
    {
      "id": 510,
      "seek": 309448,
      "start": 3094.48,
      "end": 3101.12,
      "text": " logica di business, non far girare tutto il sito ma solo quello che veramente serve quindi",
      "tokens": [
        3565,
        2262,
        1026,
        1606,
        11,
        2107,
        1400,
        14703,
        543,
        23048,
        1930,
        1394,
        78,
        463,
        6944,
        22813,
        947,
        50079,
        4596,
        15727
      ],
      "temperature": 0,
      "avg_logprob": -0.2603398712588028,
      "compression_ratio": 1.6235294117647059,
      "no_speech_prob": 2.0816910861753968e-8
    },
    {
      "id": 511,
      "seek": 309448,
      "start": 3101.12,
      "end": 3106.76,
      "text": " ridurre computazione da quel punto di vista, spostare molta computazione che andava prima",
      "tokens": [
        3973,
        374,
        265,
        2807,
        12928,
        1120,
        7178,
        14326,
        1026,
        22553,
        11,
        637,
        555,
        543,
        48564,
        2807,
        12928,
        947,
        293,
        4061,
        19507
      ],
      "temperature": 0,
      "avg_logprob": -0.2603398712588028,
      "compression_ratio": 1.6235294117647059,
      "no_speech_prob": 2.0816910861753968e-8
    },
    {
      "id": 512,
      "seek": 309448,
      "start": 3106.76,
      "end": 3115.2400000000002,
      "text": " nei nostri backend monolitici a build time quindi da un'altra parte il trend della computazione",
      "tokens": [
        34517,
        10397,
        470,
        38087,
        1108,
        401,
        270,
        8787,
        257,
        1322,
        565,
        15727,
        1120,
        517,
        6,
        38865,
        6975,
        1930,
        6028,
        11618,
        2807,
        12928
      ],
      "temperature": 0,
      "avg_logprob": -0.2603398712588028,
      "compression_ratio": 1.6235294117647059,
      "no_speech_prob": 2.0816910861753968e-8
    },
    {
      "id": 513,
      "seek": 311524,
      "start": 3115.24,
      "end": 3126.16,
      "text": " serverless ci ha portato in modo positivo anche a ottimizzare energia diciamola anche",
      "tokens": [
        7154,
        1832,
        6983,
        324,
        2436,
        2513,
        294,
        16664,
        44710,
        11585,
        257,
        4337,
        31208,
        8072,
        543,
        29469,
        14285,
        2918,
        4711,
        11585
      ],
      "temperature": 0,
      "avg_logprob": -0.2804891548904718,
      "compression_ratio": 1.4173228346456692,
      "no_speech_prob": 1.4532544057033192e-8
    },
    {
      "id": 514,
      "seek": 311524,
      "start": 3126.16,
      "end": 3145.2,
      "text": " qua però nel contempo più creiamo nuovi livelli di astrazione più ci allontaniamo da quello",
      "tokens": [
        24159,
        12673,
        15373,
        660,
        443,
        2259,
        10589,
        1197,
        7415,
        37802,
        4917,
        1621,
        16320,
        1026,
        5357,
        424,
        19706,
        10589,
        6983,
        439,
        896,
        282,
        7415,
        1120,
        22813
      ],
      "temperature": 0,
      "avg_logprob": -0.2804891548904718,
      "compression_ratio": 1.4173228346456692,
      "no_speech_prob": 1.4532544057033192e-8
    },
    {
      "id": 515,
      "seek": 314520,
      "start": 3145.2,
      "end": 3155.6,
      "text": " che in realtà è fisicamente quello che facciamo e questo ha un certo effetto anche se ci connettiamo",
      "tokens": [
        947,
        294,
        47512,
        4873,
        36609,
        23653,
        22813,
        947,
        1915,
        42052,
        308,
        10263,
        324,
        517,
        22261,
        1244,
        23778,
        11585,
        369,
        6983,
        46264,
        3093,
        7415
      ],
      "temperature": 0,
      "avg_logprob": -0.2157172578753847,
      "compression_ratio": 1.8578680203045685,
      "no_speech_prob": 7.153169434559459e-8
    },
    {
      "id": 516,
      "seek": 314520,
      "start": 3155.6,
      "end": 3161.04,
      "text": " a un ragionamento o a un concetto di tipo ambientale cioè il fatto di essere così",
      "tokens": [
        257,
        517,
        17539,
        313,
        8824,
        277,
        257,
        517,
        1588,
        23778,
        1026,
        9746,
        22997,
        1220,
        41827,
        1930,
        23228,
        1026,
        19799,
        23278
      ],
      "temperature": 0,
      "avg_logprob": -0.2157172578753847,
      "compression_ratio": 1.8578680203045685,
      "no_speech_prob": 7.153169434559459e-8
    },
    {
      "id": 517,
      "seek": 314520,
      "start": 3161.04,
      "end": 3167.56,
      "text": " lontano dal ferro probabilmente ci fa perdere consapevolezza di quello che è il consumo",
      "tokens": [
        287,
        896,
        3730,
        11702,
        7202,
        340,
        31959,
        4082,
        6983,
        2050,
        12611,
        323,
        1014,
        41153,
        3080,
        20336,
        2394,
        1026,
        22813,
        947,
        4873,
        1930,
        42505
      ],
      "temperature": 0,
      "avg_logprob": -0.2157172578753847,
      "compression_ratio": 1.8578680203045685,
      "no_speech_prob": 7.153169434559459e-8
    },
    {
      "id": 518,
      "seek": 314520,
      "start": 3167.56,
      "end": 3174.3199999999997,
      "text": " energetico un altro elemento che ci fa perdere consapevolezza del consumo energetico è il",
      "tokens": [
        2043,
        847,
        2789,
        517,
        40924,
        47961,
        947,
        6983,
        2050,
        12611,
        323,
        1014,
        41153,
        3080,
        20336,
        2394,
        1103,
        42505,
        2043,
        847,
        2789,
        4873,
        1930
      ],
      "temperature": 0,
      "avg_logprob": -0.2157172578753847,
      "compression_ratio": 1.8578680203045685,
      "no_speech_prob": 7.153169434559459e-8
    },
    {
      "id": 519,
      "seek": 317432,
      "start": 3174.32,
      "end": 3182.28,
      "text": " gratis. Adesso signori di AWS per favore chiudete le orecchie non sto parlando con voi quindi",
      "tokens": [
        10158,
        271,
        13,
        1999,
        5557,
        1465,
        7386,
        1026,
        17650,
        680,
        33801,
        418,
        13228,
        532,
        3498,
        476,
        277,
        13867,
        339,
        414,
        2107,
        22784,
        971,
        16201,
        416,
        20931,
        15727
      ],
      "temperature": 0,
      "avg_logprob": -0.20225472109658377,
      "compression_ratio": 1.326086956521739,
      "no_speech_prob": 2.181592684280531e-8
    },
    {
      "id": 520,
      "seek": 317432,
      "start": 3182.28,
      "end": 3193.48,
      "text": " lasciate quello che c'è come vi prego ma quanto il free tier è stato trigger meccanismo",
      "tokens": [
        48451,
        473,
        22813,
        947,
        269,
        6,
        1462,
        808,
        1932,
        659,
        1571,
        463,
        17820,
        1930,
        1737,
        12362,
        4873,
        29657,
        7875,
        385,
        1914,
        282,
        6882
      ],
      "temperature": 0,
      "avg_logprob": -0.20225472109658377,
      "compression_ratio": 1.326086956521739,
      "no_speech_prob": 2.181592684280531e-8
    },
    {
      "id": 521,
      "seek": 319348,
      "start": 3193.48,
      "end": 3206.8,
      "text": " di successo di questi servizi serverless e quanto in realtà lo stesso free tier ha triggerato",
      "tokens": [
        1026,
        2245,
        78,
        1026,
        29729,
        1658,
        24300,
        7154,
        1832,
        308,
        17820,
        294,
        47512,
        450,
        44413,
        1737,
        12362,
        324,
        7875,
        2513
      ],
      "temperature": 0,
      "avg_logprob": -0.23074600219726563,
      "compression_ratio": 1.4863387978142077,
      "no_speech_prob": 2.308997011368774e-7
    },
    {
      "id": 522,
      "seek": 319348,
      "start": 3206.8,
      "end": 3214.3,
      "text": " ha stimolato il misuso l'uso sbagliato di questi strumenti. Ah però scusa una parentesi",
      "tokens": [
        324,
        8983,
        401,
        2513,
        1930,
        3346,
        24431,
        287,
        6,
        24431,
        262,
        17282,
        2081,
        2513,
        1026,
        29729,
        1056,
        2206,
        72,
        13,
        2438,
        12673,
        795,
        20318,
        2002,
        2596,
        21181
      ],
      "temperature": 0,
      "avg_logprob": -0.23074600219726563,
      "compression_ratio": 1.4863387978142077,
      "no_speech_prob": 2.308997011368774e-7
    },
    {
      "id": 523,
      "seek": 319348,
      "start": 3214.3,
      "end": 3222.1,
      "text": " che ho sentito oggi su continuous delivery che salutiamo che chat gpt spendono 3 milioni",
      "tokens": [
        947,
        1106,
        2279,
        3528,
        34768,
        459,
        10957,
        8982,
        947,
        45184,
        7415,
        947,
        5081,
        290,
        662,
        3496,
        8957,
        805,
        1962,
        15273
      ],
      "temperature": 0,
      "avg_logprob": -0.23074600219726563,
      "compression_ratio": 1.4863387978142077,
      "no_speech_prob": 2.308997011368774e-7
    },
    {
      "id": 524,
      "seek": 322210,
      "start": 3222.1,
      "end": 3233.24,
      "text": " di dollari al giorno di data center. Sì vabbè ma c'è microsoft che pagala quindi. Quindi",
      "tokens": [
        1026,
        2722,
        3504,
        419,
        42202,
        1026,
        1412,
        3056,
        13,
        318,
        4749,
        371,
        10797,
        1462,
        463,
        269,
        6,
        1462,
        3123,
        7856,
        947,
        11812,
        5159,
        15727,
        13,
        32534
      ],
      "temperature": 0,
      "avg_logprob": -0.2523108588324653,
      "compression_ratio": 1.5380434782608696,
      "no_speech_prob": 4.1399331962566066e-8
    },
    {
      "id": 525,
      "seek": 322210,
      "start": 3233.24,
      "end": 3240.08,
      "text": " mi ripeti la domanda e me la so persa in quest'ultima osservazione. No l'impatto che ha avuto il",
      "tokens": [
        2752,
        12782,
        24566,
        635,
        3285,
        5575,
        308,
        385,
        635,
        370,
        868,
        64,
        294,
        866,
        6,
        723,
        4775,
        19508,
        1978,
        12928,
        13,
        883,
        287,
        6,
        8814,
        37491,
        947,
        324,
        1305,
        8262,
        1930
      ],
      "temperature": 0,
      "avg_logprob": -0.2523108588324653,
      "compression_ratio": 1.5380434782608696,
      "no_speech_prob": 4.1399331962566066e-8
    },
    {
      "id": 526,
      "seek": 322210,
      "start": 3240.08,
      "end": 3250.44,
      "text": " concetto di free tier nell'adozione dei servizi serverless è l'impatto che ha avuto lo stesso",
      "tokens": [
        1588,
        23778,
        1026,
        1737,
        12362,
        44666,
        6,
        1573,
        19706,
        13874,
        1658,
        24300,
        7154,
        1832,
        4873,
        287,
        6,
        8814,
        37491,
        947,
        324,
        1305,
        8262,
        450,
        44413
      ],
      "temperature": 0,
      "avg_logprob": -0.2523108588324653,
      "compression_ratio": 1.5380434782608696,
      "no_speech_prob": 4.1399331962566066e-8
    },
    {
      "id": 527,
      "seek": 325044,
      "start": 3250.44,
      "end": 3257.6,
      "text": " free tier nel misuso l'uso sbagliato di questi servizi. E' una bella domanda non so se è",
      "tokens": [
        1737,
        12362,
        15373,
        3346,
        24431,
        287,
        6,
        24431,
        262,
        17282,
        2081,
        2513,
        1026,
        29729,
        1658,
        24300,
        13,
        462,
        6,
        2002,
        312,
        3505,
        3285,
        5575,
        2107,
        370,
        369,
        4873
      ],
      "temperature": 0,
      "avg_logprob": -0.23364091107225793,
      "compression_ratio": 1.6793893129770991,
      "no_speech_prob": 0.0000010845138831427903
    },
    {
      "id": 528,
      "seek": 325044,
      "start": 3257.6,
      "end": 3263.2000000000003,
      "text": " una cosa che potrebbe essere facile da calcolare io poi ho un'opinione molto pro free tier",
      "tokens": [
        2002,
        10163,
        947,
        1847,
        39487,
        19799,
        23670,
        1120,
        2104,
        8768,
        543,
        19785,
        19260,
        1106,
        517,
        6,
        404,
        259,
        5328,
        16394,
        447,
        1737,
        12362
      ],
      "temperature": 0,
      "avg_logprob": -0.23364091107225793,
      "compression_ratio": 1.6793893129770991,
      "no_speech_prob": 0.0000010845138831427903
    },
    {
      "id": 529,
      "seek": 325044,
      "start": 3263.2000000000003,
      "end": 3268.56,
      "text": " nel senso che anzi vorrei che AWS facesse di più nel senso rendesse più semplice per",
      "tokens": [
        15373,
        3151,
        539,
        947,
        364,
        3992,
        4245,
        10271,
        947,
        17650,
        1915,
        7357,
        1026,
        10589,
        15373,
        3151,
        539,
        6125,
        7357,
        10589,
        4361,
        564,
        573,
        680
      ],
      "temperature": 0,
      "avg_logprob": -0.23364091107225793,
      "compression_ratio": 1.6793893129770991,
      "no_speech_prob": 0.0000010845138831427903
    },
    {
      "id": 530,
      "seek": 325044,
      "start": 3268.56,
      "end": 3272.52,
      "text": " chi magari uno studente universitario che non si può permettere di avere una carta",
      "tokens": [
        13228,
        49932,
        8526,
        972,
        1576,
        5950,
        3981,
        1004,
        947,
        2107,
        1511,
        26526,
        21540,
        323,
        1026,
        37914,
        2002,
        41815
      ],
      "temperature": 0,
      "avg_logprob": -0.23364091107225793,
      "compression_ratio": 1.6793893129770991,
      "no_speech_prob": 0.0000010845138831427903
    },
    {
      "id": 531,
      "seek": 325044,
      "start": 3272.52,
      "end": 3277.26,
      "text": " di credito di essere in grado comunque di provare a utilizzare questi servizi e imparare",
      "tokens": [
        1026,
        3864,
        3528,
        1026,
        19799,
        294,
        677,
        1573,
        45736,
        1026,
        1439,
        543,
        257,
        40355,
        543,
        29729,
        1658,
        24300,
        308,
        704,
        289,
        543
      ],
      "temperature": 0,
      "avg_logprob": -0.23364091107225793,
      "compression_ratio": 1.6793893129770991,
      "no_speech_prob": 0.0000010845138831427903
    },
    {
      "id": 532,
      "seek": 327726,
      "start": 3277.26,
      "end": 3283.5200000000004,
      "text": " e ad oggi secondo me AWS da questo punto di vista non fa un ottimo lavoro. Capisco il",
      "tokens": [
        308,
        614,
        34768,
        41601,
        385,
        17650,
        1120,
        10263,
        14326,
        1026,
        22553,
        2107,
        2050,
        517,
        42772,
        6934,
        42060,
        13,
        8363,
        8610,
        1930
      ],
      "temperature": 0,
      "avg_logprob": -0.2637974642967993,
      "compression_ratio": 1.7333333333333334,
      "no_speech_prob": 0.000016964231690508313
    },
    {
      "id": 533,
      "seek": 327726,
      "start": 3283.5200000000004,
      "end": 3288.2000000000003,
      "text": " tuo punto di vista nel senso che è vero che c'è molto la logica del free molto la logica",
      "tokens": [
        45352,
        14326,
        1026,
        22553,
        15373,
        3151,
        539,
        947,
        4873,
        1306,
        78,
        947,
        269,
        6,
        1462,
        16394,
        635,
        3565,
        2262,
        1103,
        1737,
        16394,
        635,
        3565,
        2262
      ],
      "temperature": 0,
      "avg_logprob": -0.2637974642967993,
      "compression_ratio": 1.7333333333333334,
      "no_speech_prob": 0.000016964231690508313
    },
    {
      "id": 534,
      "seek": 327726,
      "start": 3288.2000000000003,
      "end": 3293.0800000000004,
      "text": " di buttare online tanto costa poco e a volte ci ritroviamo a mettere in piedi roba che",
      "tokens": [
        1026,
        6660,
        543,
        2950,
        10331,
        2063,
        64,
        10639,
        308,
        257,
        37801,
        6983,
        11289,
        24088,
        7415,
        257,
        27812,
        323,
        294,
        1730,
        4504,
        3870,
        64,
        947
      ],
      "temperature": 0,
      "avg_logprob": -0.2637974642967993,
      "compression_ratio": 1.7333333333333334,
      "no_speech_prob": 0.000016964231690508313
    },
    {
      "id": 535,
      "seek": 327726,
      "start": 3293.0800000000004,
      "end": 3297.0800000000004,
      "text": " effettivamente o è fatta male nel senso che non è abbastanza ottimizzata o non è neanche",
      "tokens": [
        1244,
        3093,
        23957,
        277,
        4873,
        4046,
        1328,
        7133,
        15373,
        3151,
        539,
        947,
        2107,
        4873,
        16903,
        525,
        20030,
        4337,
        31208,
        8072,
        3274,
        277,
        2107,
        4873,
        408,
        22806
      ],
      "temperature": 0,
      "avg_logprob": -0.2637974642967993,
      "compression_ratio": 1.7333333333333334,
      "no_speech_prob": 0.000016964231690508313
    },
    {
      "id": 536,
      "seek": 327726,
      "start": 3297.0800000000004,
      "end": 3302.88,
      "text": " necessaria tanto costa poco tanto è gratis quindi nessuno si preoccupa. Però d'altro",
      "tokens": [
        2688,
        9831,
        10331,
        2063,
        64,
        10639,
        10331,
        4873,
        10158,
        271,
        15727,
        39787,
        12638,
        1511,
        44388,
        64,
        13,
        20533,
        274,
        6,
        47484
      ],
      "temperature": 0,
      "avg_logprob": -0.2637974642967993,
      "compression_ratio": 1.7333333333333334,
      "no_speech_prob": 0.000016964231690508313
    },
    {
      "id": 537,
      "seek": 330288,
      "start": 3302.88,
      "end": 3308.4,
      "text": " canto va pure osservato il fatto e questo l'hai detto pure tu che serverless come paradigma",
      "tokens": [
        393,
        1353,
        2773,
        6075,
        19508,
        1978,
        2513,
        1930,
        23228,
        308,
        10263,
        287,
        6,
        18230,
        41031,
        6075,
        2604,
        947,
        7154,
        1832,
        808,
        13480,
        16150
      ],
      "temperature": 0,
      "avg_logprob": -0.23054208358128866,
      "compression_ratio": 1.655813953488372,
      "no_speech_prob": 2.5907034739702794e-8
    },
    {
      "id": 538,
      "seek": 330288,
      "start": 3308.4,
      "end": 3315.6,
      "text": " è un po' più eco friendly dei paradigmi un po' più tradizionali cloud o anche on",
      "tokens": [
        4873,
        517,
        714,
        6,
        10589,
        30226,
        9208,
        13874,
        13480,
        328,
        3057,
        517,
        714,
        6,
        10589,
        2479,
        590,
        1966,
        72,
        4588,
        277,
        11585,
        322
      ],
      "temperature": 0,
      "avg_logprob": -0.23054208358128866,
      "compression_ratio": 1.655813953488372,
      "no_speech_prob": 2.5907034739702794e-8
    },
    {
      "id": 539,
      "seek": 330288,
      "start": 3315.6,
      "end": 3321.12,
      "text": " premise nel senso che tipicamente quando vai a mettere in piedi una macchina virtuale o",
      "tokens": [
        22045,
        15373,
        3151,
        539,
        947,
        4125,
        23653,
        7770,
        4405,
        257,
        27812,
        323,
        294,
        24186,
        72,
        2002,
        7912,
        339,
        1426,
        6374,
        68,
        277
      ],
      "temperature": 0,
      "avg_logprob": -0.23054208358128866,
      "compression_ratio": 1.655813953488372,
      "no_speech_prob": 2.5907034739702794e-8
    },
    {
      "id": 540,
      "seek": 330288,
      "start": 3321.12,
      "end": 3328.32,
      "text": " cloud on premise che sia devi sempre dargli molto più buffer di quello che ti serve perché",
      "tokens": [
        4588,
        322,
        22045,
        947,
        25176,
        31219,
        9553,
        4072,
        41443,
        16394,
        10589,
        21762,
        1026,
        22813,
        947,
        8757,
        4596,
        14303
      ],
      "temperature": 0,
      "avg_logprob": -0.23054208358128866,
      "compression_ratio": 1.655813953488372,
      "no_speech_prob": 2.5907034739702794e-8
    },
    {
      "id": 541,
      "seek": 332832,
      "start": 3328.32,
      "end": 3333.32,
      "text": " non riesce a scalare in modo così dinamico quindi all'atto pratico magari tu c'hai una",
      "tokens": [
        2107,
        23932,
        384,
        257,
        15664,
        543,
        294,
        16664,
        23278,
        3791,
        335,
        2789,
        15727,
        439,
        6,
        37491,
        33852,
        78,
        49932,
        2604,
        269,
        6,
        18230,
        2002
      ],
      "temperature": 0,
      "avg_logprob": -0.19822045259697493,
      "compression_ratio": 1.746031746031746,
      "no_speech_prob": 1.715947774982851e-7
    },
    {
      "id": 542,
      "seek": 332832,
      "start": 3333.32,
      "end": 3339.88,
      "text": " macchina che consuma teoricamente 100 quando ti serve due e quel 100 magari lo raggiunge",
      "tokens": [
        7912,
        339,
        1426,
        947,
        3978,
        64,
        535,
        16345,
        3439,
        2319,
        7770,
        8757,
        4596,
        3462,
        308,
        7178,
        2319,
        49932,
        450,
        17539,
        7834,
        27588
      ],
      "temperature": 0,
      "avg_logprob": -0.19822045259697493,
      "compression_ratio": 1.746031746031746,
      "no_speech_prob": 1.715947774982851e-7
    },
    {
      "id": 543,
      "seek": 332832,
      "start": 3339.88,
      "end": 3344.7200000000003,
      "text": " una volta al mese in un picco ben preciso quindi stai pagando per un mese 100 tutti",
      "tokens": [
        2002,
        18765,
        419,
        275,
        1130,
        294,
        517,
        13363,
        1291,
        3271,
        30109,
        15727,
        342,
        1301,
        11812,
        1806,
        680,
        517,
        275,
        1130,
        2319,
        19822
      ],
      "temperature": 0,
      "avg_logprob": -0.19822045259697493,
      "compression_ratio": 1.746031746031746,
      "no_speech_prob": 1.715947774982851e-7
    },
    {
      "id": 544,
      "seek": 332832,
      "start": 3344.7200000000003,
      "end": 3350.26,
      "text": " i giorni quando magari quel 100 ti serve un'ora al mese. Con serverless riesce un po' quella",
      "tokens": [
        741,
        36937,
        72,
        7770,
        49932,
        7178,
        2319,
        8757,
        4596,
        517,
        6,
        3252,
        419,
        275,
        1130,
        13,
        2656,
        7154,
        1832,
        23932,
        384,
        517,
        714,
        6,
        32234
      ],
      "temperature": 0,
      "avg_logprob": -0.19822045259697493,
      "compression_ratio": 1.746031746031746,
      "no_speech_prob": 1.715947774982851e-7
    },
    {
      "id": 545,
      "seek": 332832,
      "start": 3350.26,
      "end": 3355.26,
      "text": " curva di utilizzo a ottimizzarla e questo teoricamente dovrebbe dare un modello un po'",
      "tokens": [
        1262,
        2757,
        1026,
        19906,
        4765,
        257,
        4337,
        31208,
        8072,
        34148,
        308,
        10263,
        535,
        16345,
        3439,
        30870,
        39487,
        8955,
        517,
        1072,
        11216,
        517,
        714,
        6
      ],
      "temperature": 0,
      "avg_logprob": -0.19822045259697493,
      "compression_ratio": 1.746031746031746,
      "no_speech_prob": 1.715947774982851e-7
    },
    {
      "id": 546,
      "seek": 335526,
      "start": 3355.26,
      "end": 3359.94,
      "text": " più eco sostenibile ora tutti i cloud provider quando si parla di eco sostenibilità secondo",
      "tokens": [
        10589,
        30226,
        262,
        18946,
        30898,
        33714,
        19822,
        741,
        4588,
        12398,
        7770,
        1511,
        971,
        875,
        1026,
        30226,
        262,
        18946,
        11607,
        12445,
        41601
      ],
      "temperature": 0,
      "avg_logprob": -0.23663809942820715,
      "compression_ratio": 1.7041198501872659,
      "no_speech_prob": 1.143071415299346e-7
    },
    {
      "id": 547,
      "seek": 335526,
      "start": 3359.94,
      "end": 3364.26,
      "text": " noi fanno un po' di fuffa cioè è difficile avere delle metriche chiare perché poi magari",
      "tokens": [
        22447,
        283,
        13484,
        517,
        714,
        6,
        1026,
        283,
        1245,
        64,
        41827,
        4873,
        26607,
        37914,
        16485,
        1131,
        81,
        9304,
        13228,
        543,
        14303,
        19260,
        49932
      ],
      "temperature": 0,
      "avg_logprob": -0.23663809942820715,
      "compression_ratio": 1.7041198501872659,
      "no_speech_prob": 1.143071415299346e-7
    },
    {
      "id": 548,
      "seek": 335526,
      "start": 3364.26,
      "end": 3368.92,
      "text": " dovrebbero tirare fuori tutta una serie di dettagli tecnici che non vogliono tirare fuori",
      "tokens": [
        30870,
        22692,
        46659,
        13807,
        543,
        8536,
        7386,
        3672,
        1328,
        2002,
        23030,
        1026,
        1141,
        25030,
        2081,
        535,
        66,
        7692,
        72,
        947,
        2107,
        31273,
        75,
        49020,
        13807,
        543,
        8536,
        7386
      ],
      "temperature": 0,
      "avg_logprob": -0.23663809942820715,
      "compression_ratio": 1.7041198501872659,
      "no_speech_prob": 1.143071415299346e-7
    },
    {
      "id": 549,
      "seek": 335526,
      "start": 3368.92,
      "end": 3373.6800000000003,
      "text": " però per fortuna questo discorso dell'eco sostenibilità sta diventando un tema sempre",
      "tokens": [
        12673,
        680,
        5009,
        5051,
        10263,
        2983,
        284,
        539,
        19781,
        6,
        68,
        1291,
        262,
        18946,
        11607,
        12445,
        11135,
        3414,
        317,
        1806,
        517,
        15854,
        9553
      ],
      "temperature": 0,
      "avg_logprob": -0.23663809942820715,
      "compression_ratio": 1.7041198501872659,
      "no_speech_prob": 1.143071415299346e-7
    },
    {
      "id": 550,
      "seek": 335526,
      "start": 3373.6800000000003,
      "end": 3380.76,
      "text": " più importante al punto che non so se sapete che AWS ha questi pillar del well architected",
      "tokens": [
        10589,
        9416,
        419,
        14326,
        947,
        2107,
        370,
        369,
        18985,
        3498,
        947,
        17650,
        324,
        29729,
        27592,
        1103,
        731,
        6331,
        292
      ],
      "temperature": 0,
      "avg_logprob": -0.23663809942820715,
      "compression_ratio": 1.7041198501872659,
      "no_speech_prob": 1.143071415299346e-7
    },
    {
      "id": 551,
      "seek": 338076,
      "start": 3380.76,
      "end": 3385.82,
      "text": " framework di recente hanno proprio introdotto un pillar che è quello che cerca di capire",
      "tokens": [
        8388,
        1026,
        850,
        1576,
        26595,
        28203,
        560,
        11452,
        18838,
        517,
        27592,
        947,
        4873,
        22813,
        947,
        26770,
        1026,
        1410,
        621
      ],
      "temperature": 0,
      "avg_logprob": -0.22159424424171448,
      "compression_ratio": 1.8,
      "no_speech_prob": 1.3652049268841893e-8
    },
    {
      "id": 552,
      "seek": 338076,
      "start": 3385.82,
      "end": 3391.26,
      "text": " qual è l'impatto da un punto di vista ambientale delle soluzioni cloud e come cercare di ottimizzare",
      "tokens": [
        4101,
        4873,
        287,
        6,
        8814,
        37491,
        1120,
        517,
        14326,
        1026,
        22553,
        22997,
        1220,
        16485,
        1404,
        3334,
        15273,
        4588,
        308,
        808,
        10146,
        5685,
        1026,
        4337,
        31208,
        8072,
        543
      ],
      "temperature": 0,
      "avg_logprob": -0.22159424424171448,
      "compression_ratio": 1.8,
      "no_speech_prob": 1.3652049268841893e-8
    },
    {
      "id": 553,
      "seek": 338076,
      "start": 3391.26,
      "end": 3397.2000000000003,
      "text": " anche da quel punto di vista. Discorso che secondo me andrebbe su cui andrebbe fatta",
      "tokens": [
        11585,
        1120,
        7178,
        14326,
        1026,
        22553,
        13,
        4208,
        19558,
        539,
        947,
        41601,
        385,
        293,
        39487,
        459,
        22929,
        293,
        39487,
        4046,
        1328
      ],
      "temperature": 0,
      "avg_logprob": -0.22159424424171448,
      "compression_ratio": 1.8,
      "no_speech_prob": 1.3652049268841893e-8
    },
    {
      "id": 554,
      "seek": 338076,
      "start": 3397.2000000000003,
      "end": 3401.32,
      "text": " più enfasi su cui andrebbero sviluppati più strumenti su cui andrebbe fatta più trasparenza",
      "tokens": [
        10589,
        10667,
        8483,
        459,
        22929,
        293,
        22692,
        46659,
        17342,
        388,
        10504,
        6908,
        10589,
        1056,
        2206,
        72,
        459,
        22929,
        293,
        39487,
        4046,
        1328,
        10589,
        504,
        9375,
        4484,
        2394
      ],
      "temperature": 0,
      "avg_logprob": -0.22159424424171448,
      "compression_ratio": 1.8,
      "no_speech_prob": 1.3652049268841893e-8
    },
    {
      "id": 555,
      "seek": 338076,
      "start": 3401.32,
      "end": 3405.46,
      "text": " però secondo me è già un buon passo avanti il fatto che se ne parli sempre di più e",
      "tokens": [
        12673,
        41601,
        385,
        4873,
        30469,
        517,
        758,
        266,
        38159,
        1305,
        11520,
        1930,
        23228,
        947,
        369,
        408,
        971,
        2081,
        9553,
        1026,
        10589,
        308
      ],
      "temperature": 0,
      "avg_logprob": -0.22159424424171448,
      "compression_ratio": 1.8,
      "no_speech_prob": 1.3652049268841893e-8
    },
    {
      "id": 556,
      "seek": 340546,
      "start": 3405.46,
      "end": 3411.46,
      "text": " che diventi un argomento sempre più importante sia per aziende piccole tanto quanto per aziende",
      "tokens": [
        947,
        3414,
        23012,
        517,
        3882,
        298,
        15467,
        9553,
        10589,
        9416,
        25176,
        680,
        7883,
        45816,
        13363,
        27247,
        10331,
        17820,
        680,
        7883,
        45816
      ],
      "temperature": 0,
      "avg_logprob": -0.24245938618977864,
      "compression_ratio": 1.4864864864864864,
      "no_speech_prob": 2.801207976688147e-8
    },
    {
      "id": 557,
      "seek": 340546,
      "start": 3411.46,
      "end": 3422.5,
      "text": " più grandi. Sei on mute. Sì stavo cercando il pulsante ve l'ho detto ormai sono bollito",
      "tokens": [
        10589,
        45155,
        13,
        49229,
        322,
        24523,
        13,
        318,
        4749,
        342,
        25713,
        36099,
        1806,
        1930,
        32295,
        2879,
        1241,
        287,
        6,
        1289,
        41031,
        420,
        76,
        1301,
        9259,
        748,
        285,
        3528
      ],
      "temperature": 0,
      "avg_logprob": -0.24245938618977864,
      "compression_ratio": 1.4864864864864864,
      "no_speech_prob": 2.801207976688147e-8
    },
    {
      "id": 558,
      "seek": 340546,
      "start": 3422.5,
      "end": 3430.2200000000003,
      "text": " tra l'altro hai citato la cosa interessante del well architected framework che devo dire",
      "tokens": [
        944,
        287,
        6,
        47484,
        21822,
        4814,
        2513,
        635,
        10163,
        24372,
        1103,
        731,
        6331,
        292,
        8388,
        947,
        49717,
        1264
      ],
      "temperature": 0,
      "avg_logprob": -0.24245938618977864,
      "compression_ratio": 1.4864864864864864,
      "no_speech_prob": 2.801207976688147e-8
    },
    {
      "id": 559,
      "seek": 343022,
      "start": 3430.22,
      "end": 3438.62,
      "text": " che ho scoperto solo stamattina ed è una figata pazzesca e all'interno del well architected",
      "tokens": [
        947,
        1106,
        795,
        404,
        13098,
        6944,
        29682,
        1591,
        1426,
        1257,
        4873,
        2002,
        2147,
        3274,
        280,
        9112,
        279,
        496,
        308,
        439,
        6,
        5106,
        1771,
        1103,
        731,
        6331,
        292
      ],
      "temperature": 0,
      "avg_logprob": -0.23726544013390174,
      "compression_ratio": 1.5414364640883977,
      "no_speech_prob": 5.07231909807615e-8
    },
    {
      "id": 560,
      "seek": 343022,
      "start": 3438.62,
      "end": 3446.2599999999998,
      "text": " framework c'è ho trovato un documento o comunque un gruppo di documenti che era il serverless",
      "tokens": [
        8388,
        269,
        6,
        1462,
        1106,
        35449,
        2513,
        517,
        4166,
        78,
        277,
        45736,
        517,
        47477,
        78,
        1026,
        4166,
        72,
        947,
        4249,
        1930,
        7154,
        1832
      ],
      "temperature": 0,
      "avg_logprob": -0.23726544013390174,
      "compression_ratio": 1.5414364640883977,
      "no_speech_prob": 5.07231909807615e-8
    },
    {
      "id": 561,
      "seek": 343022,
      "start": 3446.2599999999998,
      "end": 3454.98,
      "text": " application lens che è un documento che in qualche modo tra le varie cose che fa evidenzia",
      "tokens": [
        3861,
        6765,
        947,
        4873,
        517,
        4166,
        78,
        947,
        294,
        38737,
        16664,
        944,
        476,
        1374,
        414,
        30261,
        947,
        2050,
        43699,
        40395
      ],
      "temperature": 0,
      "avg_logprob": -0.23726544013390174,
      "compression_ratio": 1.5414364640883977,
      "no_speech_prob": 5.07231909807615e-8
    },
    {
      "id": 562,
      "seek": 345498,
      "start": 3454.98,
      "end": 3462.38,
      "text": " anche delle topologie di architettura serverless e delle best practice per la creazione di",
      "tokens": [
        11585,
        16485,
        1192,
        20121,
        1026,
        3912,
        270,
        3093,
        2991,
        7154,
        1832,
        308,
        16485,
        1151,
        3124,
        680,
        635,
        1197,
        12928,
        1026
      ],
      "temperature": 0,
      "avg_logprob": -0.2436962890625,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 5.871678254720791e-9
    },
    {
      "id": 563,
      "seek": 345498,
      "start": 3462.38,
      "end": 3470.5,
      "text": " architetture specifiche. Ad oggi secondo te quali sono se dovessi portare sul tavolo tre",
      "tokens": [
        3912,
        270,
        3093,
        540,
        1608,
        351,
        9304,
        13,
        1999,
        34768,
        41601,
        535,
        4101,
        72,
        9259,
        369,
        30870,
        442,
        72,
        2436,
        543,
        17603,
        23214,
        7902,
        2192
      ],
      "temperature": 0,
      "avg_logprob": -0.2436962890625,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 5.871678254720791e-9
    },
    {
      "id": 564,
      "seek": 345498,
      "start": 3470.5,
      "end": 3476.92,
      "text": " casi d'uso dove veramente il serverless in senso ampio e quindi non solo lambda dà il",
      "tokens": [
        22567,
        274,
        6,
        24431,
        23287,
        50079,
        1930,
        7154,
        1832,
        294,
        3151,
        539,
        18648,
        1004,
        308,
        15727,
        2107,
        6944,
        13607,
        274,
        1467,
        1930
      ],
      "temperature": 0,
      "avg_logprob": -0.2436962890625,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 5.871678254720791e-9
    },
    {
      "id": 565,
      "seek": 347692,
      "start": 3476.92,
      "end": 3485.82,
      "text": " meglio di sé. Quali sono i casi dove veramente dici sei fatto proprio per questo? Guarda",
      "tokens": [
        48911,
        1026,
        7910,
        13,
        13616,
        72,
        9259,
        741,
        22567,
        23287,
        50079,
        274,
        8787,
        10842,
        23228,
        28203,
        680,
        10263,
        30,
        11549,
        64
      ],
      "temperature": 0,
      "avg_logprob": -0.2368509750957637,
      "compression_ratio": 1.6802973977695168,
      "no_speech_prob": 3.711011942186815e-8
    },
    {
      "id": 566,
      "seek": 347692,
      "start": 3485.82,
      "end": 3490.06,
      "text": " ne parlavo proprio di recente con un amico che mi ha chiesto una serie di opinioni lui",
      "tokens": [
        408,
        13734,
        25713,
        28203,
        1026,
        850,
        1576,
        416,
        517,
        669,
        2789,
        947,
        2752,
        324,
        417,
        6495,
        78,
        2002,
        23030,
        1026,
        4800,
        72,
        8783
      ],
      "temperature": 0,
      "avg_logprob": -0.2368509750957637,
      "compression_ratio": 1.6802973977695168,
      "no_speech_prob": 3.711011942186815e-8
    },
    {
      "id": 567,
      "seek": 347692,
      "start": 3490.06,
      "end": 3495.06,
      "text": " doveva sviluppare un nuovo progetto all'interno della propria azienda e si chiedeva mi conviene",
      "tokens": [
        23287,
        2757,
        17342,
        388,
        10504,
        543,
        517,
        49348,
        447,
        847,
        1353,
        439,
        6,
        5106,
        1771,
        11618,
        2365,
        4668,
        7883,
        30498,
        308,
        1511,
        417,
        1091,
        68,
        2757,
        2752,
        3754,
        10174
      ],
      "temperature": 0,
      "avg_logprob": -0.2368509750957637,
      "compression_ratio": 1.6802973977695168,
      "no_speech_prob": 3.711011942186815e-8
    },
    {
      "id": 568,
      "seek": 347692,
      "start": 3495.06,
      "end": 3499.94,
      "text": " andare a provare un approccio serverless perché magari un qualcosa che andando avanti con",
      "tokens": [
        42742,
        257,
        1439,
        543,
        517,
        2075,
        66,
        8529,
        7154,
        1832,
        14303,
        49932,
        517,
        42400,
        947,
        293,
        1806,
        1305,
        11520,
        416
      ],
      "temperature": 0,
      "avg_logprob": -0.2368509750957637,
      "compression_ratio": 1.6802973977695168,
      "no_speech_prob": 3.711011942186815e-8
    },
    {
      "id": 569,
      "seek": 347692,
      "start": 3499.94,
      "end": 3504.26,
      "text": " la tecnologia e con l'adattazione cloud tutti si sposteranno su quel tipo di approccio e",
      "tokens": [
        635,
        44905,
        308,
        416,
        287,
        6,
        345,
        1591,
        12928,
        4588,
        19822,
        1511,
        637,
        555,
        260,
        13484,
        459,
        7178,
        9746,
        1026,
        2075,
        66,
        8529,
        308
      ],
      "temperature": 0,
      "avg_logprob": -0.2368509750957637,
      "compression_ratio": 1.6802973977695168,
      "no_speech_prob": 3.711011942186815e-8
    },
    {
      "id": 570,
      "seek": 350426,
      "start": 3504.26,
      "end": 3510.0200000000004,
      "text": " quindi naturalmente devo andare a finire lì o posso tenere un approccio più tradizionale",
      "tokens": [
        15727,
        3303,
        4082,
        49717,
        42742,
        257,
        962,
        621,
        287,
        4749,
        277,
        22501,
        2064,
        323,
        517,
        2075,
        66,
        8529,
        10589,
        2479,
        590,
        313,
        1220
      ],
      "temperature": 0,
      "avg_logprob": -0.23907284564282522,
      "compression_ratio": 1.4619565217391304,
      "no_speech_prob": 2.4720620217522082e-8
    },
    {
      "id": 571,
      "seek": 350426,
      "start": 3510.0200000000004,
      "end": 3516.34,
      "text": " e ovviamente non è che c'è una risposta binaria sì o no c'è il fantastico depends",
      "tokens": [
        308,
        14187,
        23347,
        2107,
        4873,
        947,
        269,
        6,
        1462,
        2002,
        2253,
        79,
        8638,
        5171,
        9831,
        49267,
        277,
        572,
        269,
        6,
        1462,
        1930,
        5456,
        78,
        5946
      ],
      "temperature": 0,
      "avg_logprob": -0.23907284564282522,
      "compression_ratio": 1.4619565217391304,
      "no_speech_prob": 2.4720620217522082e-8
    },
    {
      "id": 572,
      "seek": 350426,
      "start": 3516.34,
      "end": 3531.9,
      "text": " con cui risponde a tutte le domande da consulente. Però l'irraggionamento secondo me che è",
      "tokens": [
        416,
        22929,
        2253,
        79,
        7259,
        257,
        38632,
        476,
        3285,
        11123,
        1120,
        1014,
        425,
        1576,
        13,
        20533,
        287,
        6,
        347,
        424,
        1615,
        313,
        8824,
        41601,
        385,
        947,
        4873
      ],
      "temperature": 0,
      "avg_logprob": -0.23907284564282522,
      "compression_ratio": 1.4619565217391304,
      "no_speech_prob": 2.4720620217522082e-8
    },
    {
      "id": 573,
      "seek": 353190,
      "start": 3531.9,
      "end": 3537.06,
      "text": " poi interessante che è venuto fuori a quel tipo di conversazione è sempre il fatto di",
      "tokens": [
        19260,
        24372,
        947,
        4873,
        6138,
        8262,
        8536,
        7386,
        257,
        7178,
        9746,
        1026,
        2615,
        12928,
        4873,
        9553,
        1930,
        23228,
        1026
      ],
      "temperature": 0,
      "avg_logprob": -0.19974995422363281,
      "compression_ratio": 1.804,
      "no_speech_prob": 1.808604110919987e-8
    },
    {
      "id": 574,
      "seek": 353190,
      "start": 3537.06,
      "end": 3545.42,
      "text": " ma il tuo team che tipo di competenze ha e quanto vuole imparare roba nuova e ovviamente",
      "tokens": [
        463,
        1930,
        45352,
        1469,
        947,
        9746,
        1026,
        2850,
        268,
        1381,
        324,
        308,
        17820,
        9732,
        4812,
        704,
        289,
        543,
        3870,
        64,
        3822,
        27924,
        308,
        14187,
        23347
      ],
      "temperature": 0,
      "avg_logprob": -0.19974995422363281,
      "compression_ratio": 1.804,
      "no_speech_prob": 1.808604110919987e-8
    },
    {
      "id": 575,
      "seek": 353190,
      "start": 3545.42,
      "end": 3549.56,
      "text": " tutto ciò correlato al fatto quale sono le tue deadline che tipo di prodotto stai costruendo",
      "tokens": [
        23048,
        6983,
        4293,
        13983,
        2513,
        419,
        23228,
        421,
        1220,
        9259,
        476,
        256,
        622,
        20615,
        947,
        9746,
        1026,
        15792,
        18838,
        342,
        1301,
        2063,
        894,
        3999
      ],
      "temperature": 0,
      "avg_logprob": -0.19974995422363281,
      "compression_ratio": 1.804,
      "no_speech_prob": 1.808604110919987e-8
    },
    {
      "id": 576,
      "seek": 353190,
      "start": 3549.56,
      "end": 3555.2200000000003,
      "text": " e che tempistiche hai per andare sul mercato con questo nuovo prodotto quindi di nuovo",
      "tokens": [
        308,
        947,
        18274,
        468,
        9304,
        21822,
        680,
        42742,
        17603,
        10811,
        2513,
        416,
        10263,
        49348,
        15792,
        18838,
        15727,
        1026,
        49348
      ],
      "temperature": 0,
      "avg_logprob": -0.19974995422363281,
      "compression_ratio": 1.804,
      "no_speech_prob": 1.808604110919987e-8
    },
    {
      "id": 577,
      "seek": 353190,
      "start": 3555.2200000000003,
      "end": 3560.26,
      "text": " non c'è una risposta semplice ma devi andare a osservare tutto questo tipo di cose e cercare",
      "tokens": [
        2107,
        269,
        6,
        1462,
        2002,
        2253,
        79,
        8638,
        4361,
        564,
        573,
        463,
        31219,
        42742,
        257,
        19508,
        1978,
        543,
        23048,
        10263,
        9746,
        1026,
        30261,
        308,
        10146,
        5685
      ],
      "temperature": 0,
      "avg_logprob": -0.19974995422363281,
      "compression_ratio": 1.804,
      "no_speech_prob": 1.808604110919987e-8
    },
    {
      "id": 578,
      "seek": 356026,
      "start": 3560.26,
      "end": 3565.82,
      "text": " di capire quali sono le leve che ha a disposizione alla fine e tirare fuori una strategia pratica.",
      "tokens": [
        1026,
        1410,
        621,
        4101,
        72,
        9259,
        476,
        33076,
        947,
        324,
        257,
        15885,
        35740,
        11591,
        2489,
        308,
        13807,
        543,
        8536,
        7386,
        2002,
        5464,
        654,
        28844,
        2262,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.24379976093769073,
      "compression_ratio": 1.679245283018868,
      "no_speech_prob": 2.2732712068318506e-7
    },
    {
      "id": 579,
      "seek": 356026,
      "start": 3565.82,
      "end": 3571.5,
      "text": " E in quel caso una delle osservazioni che abbiamo notato è se vuoi provare serverless",
      "tokens": [
        462,
        294,
        7178,
        9666,
        2002,
        16485,
        19508,
        1978,
        27569,
        947,
        22815,
        406,
        2513,
        4873,
        369,
        9732,
        4869,
        1439,
        543,
        7154,
        1832
      ],
      "temperature": 0,
      "avg_logprob": -0.24379976093769073,
      "compression_ratio": 1.679245283018868,
      "no_speech_prob": 2.2732712068318506e-7
    },
    {
      "id": 580,
      "seek": 356026,
      "start": 3571.5,
      "end": 3575.1400000000003,
      "text": " perché è una cosa che i tuoi sviluppatori vogliono provare perché c'è anche un po'",
      "tokens": [
        14303,
        4873,
        2002,
        10163,
        947,
        741,
        2604,
        4869,
        17342,
        388,
        10504,
        39842,
        31273,
        75,
        49020,
        1439,
        543,
        14303,
        269,
        6,
        1462,
        11585,
        517,
        714,
        6
      ],
      "temperature": 0,
      "avg_logprob": -0.24379976093769073,
      "compression_ratio": 1.679245283018868,
      "no_speech_prob": 2.2732712068318506e-7
    },
    {
      "id": 581,
      "seek": 356026,
      "start": 3575.1400000000003,
      "end": 3579.7000000000003,
      "text": " di hype e loro si sentono che se non hanno fatto un po' di serverless magari stanno",
      "tokens": [
        1026,
        24144,
        308,
        28810,
        1511,
        2279,
        8957,
        947,
        369,
        2107,
        26595,
        23228,
        517,
        714,
        6,
        1026,
        7154,
        1832,
        49932,
        342,
        13484
      ],
      "temperature": 0,
      "avg_logprob": -0.24379976093769073,
      "compression_ratio": 1.679245283018868,
      "no_speech_prob": 2.2732712068318506e-7
    },
    {
      "id": 582,
      "seek": 356026,
      "start": 3579.7000000000003,
      "end": 3585.5800000000004,
      "text": " vendo roba obsoleta e non non gli piace. Uno dei casi che secondo me ideali è quello di",
      "tokens": [
        6138,
        2595,
        3870,
        64,
        43053,
        7664,
        308,
        2107,
        2107,
        17161,
        50062,
        13,
        37468,
        13874,
        22567,
        947,
        41601,
        385,
        1153,
        5103,
        4873,
        22813,
        1026
      ],
      "temperature": 0,
      "avg_logprob": -0.24379976093769073,
      "compression_ratio": 1.679245283018868,
      "no_speech_prob": 2.2732712068318506e-7
    },
    {
      "id": 583,
      "seek": 358558,
      "start": 3585.58,
      "end": 3591.2599999999998,
      "text": " quando devi andare a fare background processing e quindi sostanzialmente c'è magari un'applicazione",
      "tokens": [
        7770,
        31219,
        42742,
        257,
        11994,
        3678,
        9007,
        308,
        15727,
        41585,
        3910,
        831,
        4082,
        269,
        6,
        1462,
        49932,
        517,
        6,
        1746,
        1050,
        12928
      ],
      "temperature": 0,
      "avg_logprob": -0.21943260008288967,
      "compression_ratio": 1.6940298507462686,
      "no_speech_prob": 9.931184052902609e-8
    },
    {
      "id": 584,
      "seek": 358558,
      "start": 3591.2599999999998,
      "end": 3596.2599999999998,
      "text": " fatta in modo tradizionale facciamo finto un web server ad esempio c'è il tuo container",
      "tokens": [
        4046,
        1328,
        294,
        16664,
        2479,
        590,
        313,
        1220,
        1915,
        42052,
        962,
        1353,
        517,
        3670,
        7154,
        614,
        33627,
        269,
        6,
        1462,
        1930,
        45352,
        10129
      ],
      "temperature": 0,
      "avg_logprob": -0.21943260008288967,
      "compression_ratio": 1.6940298507462686,
      "no_speech_prob": 9.931184052902609e-8
    },
    {
      "id": 585,
      "seek": 358558,
      "start": 3596.2599999999998,
      "end": 3602.98,
      "text": " o virtual machine che sia gira un processo 24 ore su 24 arrivano richieste risponde se",
      "tokens": [
        277,
        6374,
        3479,
        947,
        25176,
        290,
        4271,
        517,
        27939,
        4022,
        20865,
        459,
        4022,
        30697,
        3730,
        4593,
        6495,
        68,
        2253,
        79,
        7259,
        369
      ],
      "temperature": 0,
      "avg_logprob": -0.21943260008288967,
      "compression_ratio": 1.6940298507462686,
      "no_speech_prob": 9.931184052902609e-8
    },
    {
      "id": 586,
      "seek": 358558,
      "start": 3602.98,
      "end": 3606.8199999999997,
      "text": " però c'è tutta una serie di roba che deve essere fatto in background non lo so mandare",
      "tokens": [
        12673,
        269,
        6,
        1462,
        3672,
        1328,
        2002,
        23030,
        1026,
        3870,
        64,
        947,
        17761,
        19799,
        23228,
        294,
        3678,
        2107,
        450,
        370,
        7411,
        543
      ],
      "temperature": 0,
      "avg_logprob": -0.21943260008288967,
      "compression_ratio": 1.6940298507462686,
      "no_speech_prob": 9.931184052902609e-8
    },
    {
      "id": 587,
      "seek": 358558,
      "start": 3606.8199999999997,
      "end": 3613.06,
      "text": " le mail mandare le notifiche ridimensionare immagini o quello che sia il fatto di andare",
      "tokens": [
        476,
        10071,
        7411,
        543,
        476,
        406,
        351,
        9304,
        3973,
        332,
        3378,
        543,
        3397,
        559,
        3812,
        277,
        22813,
        947,
        25176,
        1930,
        23228,
        1026,
        42742
      ],
      "temperature": 0,
      "avg_logprob": -0.21943260008288967,
      "compression_ratio": 1.6940298507462686,
      "no_speech_prob": 9.931184052902609e-8
    },
    {
      "id": 588,
      "seek": 361306,
      "start": 3613.06,
      "end": 3618.58,
      "text": " a utilizzare strumenti come sqs e lambda per fare questo tipo di lavoro secondo me uno",
      "tokens": [
        257,
        40355,
        543,
        1056,
        2206,
        72,
        808,
        262,
        80,
        82,
        308,
        13607,
        680,
        11994,
        10263,
        9746,
        1026,
        42060,
        41601,
        385,
        8526
      ],
      "temperature": 0,
      "avg_logprob": -0.22088375528350132,
      "compression_ratio": 1.836734693877551,
      "no_speech_prob": 3.653480362686423e-8
    },
    {
      "id": 589,
      "seek": 361306,
      "start": 3618.58,
      "end": 3625.34,
      "text": " dei casi d'uso più ideali perché ti leva una marea di complessità infinita e effettivamente",
      "tokens": [
        13874,
        22567,
        274,
        6,
        24431,
        10589,
        1153,
        5103,
        14303,
        8757,
        43410,
        2002,
        463,
        12057,
        1026,
        1209,
        442,
        12445,
        7193,
        2786,
        308,
        1244,
        3093,
        23957
      ],
      "temperature": 0,
      "avg_logprob": -0.22088375528350132,
      "compression_ratio": 1.836734693877551,
      "no_speech_prob": 3.653480362686423e-8
    },
    {
      "id": 590,
      "seek": 361306,
      "start": 3625.34,
      "end": 3630.64,
      "text": " secondo me sqs e lambda sono proprio ottimizzati per quel tipo di caso d'uso quindi quello",
      "tokens": [
        41601,
        385,
        262,
        80,
        82,
        308,
        13607,
        9259,
        28203,
        4337,
        31208,
        8072,
        6908,
        680,
        7178,
        9746,
        1026,
        9666,
        274,
        6,
        24431,
        15727,
        22813
      ],
      "temperature": 0,
      "avg_logprob": -0.22088375528350132,
      "compression_ratio": 1.836734693877551,
      "no_speech_prob": 3.653480362686423e-8
    },
    {
      "id": 591,
      "seek": 361306,
      "start": 3630.64,
      "end": 3635.34,
      "text": " è forse uno dei primissimi casi d'uso che consiglierei a chi vuole iniziare a utilizzare",
      "tokens": [
        4873,
        337,
        405,
        8526,
        13874,
        2886,
        891,
        10121,
        22567,
        274,
        6,
        24431,
        947,
        40233,
        2081,
        40256,
        257,
        13228,
        9732,
        4812,
        294,
        24300,
        543,
        257,
        40355,
        543
      ],
      "temperature": 0,
      "avg_logprob": -0.22088375528350132,
      "compression_ratio": 1.836734693877551,
      "no_speech_prob": 3.653480362686423e-8
    },
    {
      "id": 592,
      "seek": 361306,
      "start": 3635.34,
      "end": 3641.34,
      "text": " lambda se c'è quel tipo di problema inizia a spostare quel tipo di computazione su sqs",
      "tokens": [
        13607,
        369,
        269,
        6,
        1462,
        7178,
        9746,
        1026,
        12395,
        294,
        590,
        654,
        257,
        637,
        555,
        543,
        7178,
        9746,
        1026,
        2807,
        12928,
        459,
        262,
        80,
        82
      ],
      "temperature": 0,
      "avg_logprob": -0.22088375528350132,
      "compression_ratio": 1.836734693877551,
      "no_speech_prob": 3.653480362686423e-8
    },
    {
      "id": 593,
      "seek": 364134,
      "start": 3641.34,
      "end": 3646.42,
      "text": " e lambda e lì comincia a esplorare che vuol dire scrivere una lambda che vuol dire collegarla",
      "tokens": [
        308,
        13607,
        308,
        287,
        4749,
        35814,
        2755,
        257,
        785,
        564,
        284,
        543,
        947,
        9732,
        401,
        1264,
        5545,
        5887,
        2002,
        13607,
        947,
        9732,
        401,
        1264,
        13300,
        34148
      ],
      "temperature": 0,
      "avg_logprob": -0.21228181070356228,
      "compression_ratio": 1.7704280155642023,
      "no_speech_prob": 3.076539911717191e-8
    },
    {
      "id": 594,
      "seek": 364134,
      "start": 3646.42,
      "end": 3651.94,
      "text": " sqs che vuol dire il fatto che le lambda scalano in modo dinamico in base a quanti dati stanno",
      "tokens": [
        262,
        80,
        82,
        947,
        9732,
        401,
        1264,
        1930,
        23228,
        947,
        476,
        13607,
        15664,
        3730,
        294,
        16664,
        3791,
        335,
        2789,
        294,
        3096,
        257,
        4426,
        72,
        1137,
        72,
        342,
        13484
      ],
      "temperature": 0,
      "avg_logprob": -0.21228181070356228,
      "compression_ratio": 1.7704280155642023,
      "no_speech_prob": 3.076539911717191e-8
    },
    {
      "id": 595,
      "seek": 364134,
      "start": 3651.94,
      "end": 3657.1000000000004,
      "text": " su sqs e così via quindi quello è un tipo di architettura chiamiamolo non lo so background",
      "tokens": [
        459,
        262,
        80,
        82,
        308,
        23278,
        5766,
        15727,
        22813,
        4873,
        517,
        9746,
        1026,
        3912,
        270,
        3093,
        2991,
        417,
        2918,
        2918,
        7902,
        2107,
        450,
        370,
        3678
      ],
      "temperature": 0,
      "avg_logprob": -0.21228181070356228,
      "compression_ratio": 1.7704280155642023,
      "no_speech_prob": 3.076539911717191e-8
    },
    {
      "id": 596,
      "seek": 364134,
      "start": 3657.1000000000004,
      "end": 3663.2200000000003,
      "text": " processing processing asincrono non ti so dire se c'è un nome più più adeguato altri",
      "tokens": [
        9007,
        9007,
        382,
        4647,
        2044,
        78,
        2107,
        8757,
        370,
        1264,
        369,
        269,
        6,
        1462,
        517,
        19003,
        10589,
        10589,
        614,
        1146,
        84,
        2513,
        33707
      ],
      "temperature": 0,
      "avg_logprob": -0.21228181070356228,
      "compression_ratio": 1.7704280155642023,
      "no_speech_prob": 3.076539911717191e-8
    },
    {
      "id": 597,
      "seek": 364134,
      "start": 3663.2200000000003,
      "end": 3670.86,
      "text": " casi molto comuni sono quello di fare api con api gateway lambda lì secondo me può",
      "tokens": [
        22567,
        16394,
        11040,
        72,
        9259,
        22813,
        1026,
        11994,
        1882,
        72,
        416,
        1882,
        72,
        28532,
        13607,
        287,
        4749,
        41601,
        385,
        26526
      ],
      "temperature": 0,
      "avg_logprob": -0.21228181070356228,
      "compression_ratio": 1.7704280155642023,
      "no_speech_prob": 3.076539911717191e-8
    },
    {
      "id": 598,
      "seek": 367086,
      "start": 3670.86,
      "end": 3676.82,
      "text": " andare bene in tutta una serie di casi ma non va generalizzato lo uso sempre per tutto",
      "tokens": [
        42742,
        2537,
        294,
        3672,
        1328,
        2002,
        23030,
        1026,
        22567,
        463,
        2107,
        2773,
        2674,
        8072,
        2513,
        450,
        22728,
        9553,
        680,
        23048
      ],
      "temperature": 0,
      "avg_logprob": -0.25320808560240504,
      "compression_ratio": 1.6192660550458715,
      "no_speech_prob": 5.515932599564621e-9
    },
    {
      "id": 599,
      "seek": 367086,
      "start": 3676.82,
      "end": 3681.06,
      "text": " perché appunto come diciamo all'inizio della puntata se banalmente deve fare l'upload",
      "tokens": [
        14303,
        724,
        24052,
        808,
        14285,
        7415,
        439,
        6,
        9328,
        1004,
        11618,
        18212,
        3274,
        369,
        5643,
        304,
        4082,
        17761,
        11994,
        287,
        6,
        84,
        21132,
        345
      ],
      "temperature": 0,
      "avg_logprob": -0.25320808560240504,
      "compression_ratio": 1.6192660550458715,
      "no_speech_prob": 5.515932599564621e-9
    },
    {
      "id": 600,
      "seek": 367086,
      "start": 3681.06,
      "end": 3687.1,
      "text": " di un file non è la soluzione migliore farlo con api gateway lambda molto probabilmente",
      "tokens": [
        1026,
        517,
        3991,
        2107,
        4873,
        635,
        1404,
        3334,
        5328,
        6186,
        2081,
        418,
        1400,
        752,
        416,
        1882,
        72,
        28532,
        13607,
        16394,
        31959,
        4082
      ],
      "temperature": 0,
      "avg_logprob": -0.25320808560240504,
      "compression_ratio": 1.6192660550458715,
      "no_speech_prob": 5.515932599564621e-9
    },
    {
      "id": 601,
      "seek": 367086,
      "start": 3687.1,
      "end": 3694.5,
      "text": " non è una buona soluzione per niente quindi le piase con l'essere dopo aver letto il post",
      "tokens": [
        2107,
        4873,
        2002,
        758,
        4037,
        1404,
        3334,
        5328,
        680,
        297,
        8413,
        15727,
        476,
        3895,
        651,
        416,
        287,
        6,
        442,
        323,
        35196,
        18247,
        718,
        1353,
        1930,
        2183
      ],
      "temperature": 0,
      "avg_logprob": -0.25320808560240504,
      "compression_ratio": 1.6192660550458715,
      "no_speech_prob": 5.515932599564621e-9
    },
    {
      "id": 602,
      "seek": 369450,
      "start": 3694.5,
      "end": 3701.26,
      "text": " di luciano ok anche quello lo metteremo nei link grazie della pubblicità però banalmente",
      "tokens": [
        1026,
        10438,
        537,
        3730,
        3133,
        11585,
        22813,
        450,
        27812,
        323,
        3280,
        34517,
        2113,
        1295,
        3283,
        11618,
        1535,
        11489,
        12445,
        12673,
        5643,
        304,
        4082
      ],
      "temperature": 0,
      "avg_logprob": -0.23378370747421728,
      "compression_ratio": 1.6813186813186813,
      "no_speech_prob": 1.8953983271785546e-8
    },
    {
      "id": 603,
      "seek": 369450,
      "start": 3701.26,
      "end": 3705.78,
      "text": " se ad esempio devi fare un webbook cioè c'è un evento che t'arriva da qualche altro servizio",
      "tokens": [
        369,
        614,
        33627,
        31219,
        11994,
        517,
        3670,
        2939,
        41827,
        269,
        6,
        1462,
        517,
        40655,
        947,
        256,
        6,
        289,
        470,
        2757,
        1120,
        38737,
        40924,
        1658,
        590,
        1004
      ],
      "temperature": 0,
      "avg_logprob": -0.23378370747421728,
      "compression_ratio": 1.6813186813186813,
      "no_speech_prob": 1.8953983271785546e-8
    },
    {
      "id": 604,
      "seek": 369450,
      "start": 3705.78,
      "end": 3711.46,
      "text": " e vuoi avere un end point che riceve quell'evento e fa qualcosa fare una lambda è semplicissimo",
      "tokens": [
        308,
        9732,
        4869,
        37914,
        517,
        917,
        935,
        947,
        5090,
        303,
        631,
        285,
        6,
        68,
        2475,
        78,
        308,
        2050,
        42400,
        11994,
        2002,
        13607,
        4873,
        4361,
        4770,
        34966
      ],
      "temperature": 0,
      "avg_logprob": -0.23378370747421728,
      "compression_ratio": 1.6813186813186813,
      "no_speech_prob": 1.8953983271785546e-8
    },
    {
      "id": 605,
      "seek": 369450,
      "start": 3711.46,
      "end": 3717.18,
      "text": " piuttosto che andare a mettere in piedi un web server tradizionale quindi anche lì si",
      "tokens": [
        3895,
        13478,
        22756,
        947,
        42742,
        257,
        27812,
        323,
        294,
        24186,
        72,
        517,
        3670,
        7154,
        2479,
        590,
        313,
        1220,
        15727,
        11585,
        287,
        4749,
        1511
      ],
      "temperature": 0,
      "avg_logprob": -0.23378370747421728,
      "compression_ratio": 1.6813186813186813,
      "no_speech_prob": 1.8953983271785546e-8
    },
    {
      "id": 606,
      "seek": 369450,
      "start": 3717.18,
      "end": 3723.34,
      "text": " parla comunque di end point http però dipende il caso d'uso può essere ideale farlo con",
      "tokens": [
        971,
        875,
        45736,
        1026,
        917,
        935,
        37428,
        12673,
        10460,
        5445,
        1930,
        9666,
        274,
        6,
        24431,
        26526,
        19799,
        1153,
        1220,
        1400,
        752,
        416
      ],
      "temperature": 0,
      "avg_logprob": -0.23378370747421728,
      "compression_ratio": 1.6813186813186813,
      "no_speech_prob": 1.8953983271785546e-8
    },
    {
      "id": 607,
      "seek": 372334,
      "start": 3723.34,
      "end": 3728.6200000000003,
      "text": " lambda piuttosto che magari non sempre così ideale è un altro caso d'uso che se non è",
      "tokens": [
        13607,
        3895,
        13478,
        22756,
        947,
        49932,
        2107,
        9553,
        23278,
        1153,
        1220,
        4873,
        517,
        40924,
        9666,
        274,
        6,
        24431,
        947,
        369,
        2107,
        4873
      ],
      "temperature": 0,
      "avg_logprob": -0.21261569646399792,
      "compression_ratio": 1.7159090909090908,
      "no_speech_prob": 7.380225497399806e-8
    },
    {
      "id": 608,
      "seek": 372334,
      "start": 3728.6200000000003,
      "end": 3735.1000000000004,
      "text": " uno molto interessante su cui c'è secondo me tanto che vedremo negli anni futuri è",
      "tokens": [
        8526,
        16394,
        24372,
        459,
        22929,
        269,
        6,
        1462,
        41601,
        385,
        10331,
        947,
        14267,
        44172,
        2485,
        2081,
        31164,
        1877,
        9744,
        4873
      ],
      "temperature": 0,
      "avg_logprob": -0.21261569646399792,
      "compression_ratio": 1.7159090909090908,
      "no_speech_prob": 7.380225497399806e-8
    },
    {
      "id": 609,
      "seek": 372334,
      "start": 3735.1000000000004,
      "end": 3740.86,
      "text": " quello del big data e anche tu l'hai menzionato quasi come un caso in antitesi per il serverless",
      "tokens": [
        22813,
        1103,
        955,
        1412,
        308,
        11585,
        2604,
        287,
        6,
        18230,
        1706,
        89,
        313,
        2513,
        20954,
        808,
        517,
        9666,
        294,
        2511,
        3324,
        72,
        680,
        1930,
        7154,
        1832
      ],
      "temperature": 0,
      "avg_logprob": -0.21261569646399792,
      "compression_ratio": 1.7159090909090908,
      "no_speech_prob": 7.380225497399806e-8
    },
    {
      "id": 610,
      "seek": 372334,
      "start": 3740.86,
      "end": 3744.6600000000003,
      "text": " ti dirò che ho lavorato con un cliente tra l'altro è uno dei casi d'uso secondo me più",
      "tokens": [
        8757,
        4746,
        4293,
        947,
        1106,
        29241,
        2513,
        416,
        517,
        6423,
        68,
        944,
        287,
        6,
        47484,
        4873,
        8526,
        13874,
        22567,
        274,
        6,
        24431,
        41601,
        385,
        10589
      ],
      "temperature": 0,
      "avg_logprob": -0.21261569646399792,
      "compression_ratio": 1.7159090909090908,
      "no_speech_prob": 7.380225497399806e-8
    },
    {
      "id": 611,
      "seek": 372334,
      "start": 3744.6600000000003,
      "end": 3751.84,
      "text": " interessanti su cui ho lavorato in cui abbiamo costruito una pipeline che riesce a calcolare",
      "tokens": [
        12478,
        11520,
        459,
        22929,
        1106,
        29241,
        2513,
        294,
        22929,
        22815,
        2063,
        894,
        3528,
        2002,
        15517,
        947,
        23932,
        384,
        257,
        2104,
        8768,
        543
      ],
      "temperature": 0,
      "avg_logprob": -0.21261569646399792,
      "compression_ratio": 1.7159090909090908,
      "no_speech_prob": 7.380225497399806e-8
    },
    {
      "id": 612,
      "seek": 375184,
      "start": 3751.84,
      "end": 3758.46,
      "text": " veramente terabyte di dati ed è quasi tutta costruita su serverless e lì il vantaggio",
      "tokens": [
        50079,
        1796,
        34529,
        1026,
        1137,
        72,
        1257,
        4873,
        20954,
        3672,
        1328,
        2063,
        894,
        2786,
        459,
        7154,
        1832,
        308,
        287,
        4749,
        1930,
        371,
        394,
        30763
      ],
      "temperature": 0,
      "avg_logprob": -0.1944562255359087,
      "compression_ratio": 1.694980694980695,
      "no_speech_prob": 2.715036728773157e-8
    },
    {
      "id": 613,
      "seek": 375184,
      "start": 3758.46,
      "end": 3763.9,
      "text": " è che ci sono tutta una serie di workflow che in base a come vengono configurati c'hai",
      "tokens": [
        4873,
        947,
        6983,
        9259,
        3672,
        1328,
        2002,
        23030,
        1026,
        20993,
        947,
        294,
        3096,
        257,
        808,
        371,
        1501,
        8957,
        22192,
        6908,
        269,
        6,
        18230
      ],
      "temperature": 0,
      "avg_logprob": -0.1944562255359087,
      "compression_ratio": 1.694980694980695,
      "no_speech_prob": 2.715036728773157e-8
    },
    {
      "id": 614,
      "seek": 375184,
      "start": 3763.9,
      "end": 3769.1800000000003,
      "text": " uno spike iniziale di computazione e quindi se dovessi far partire delle virtual machine",
      "tokens": [
        8526,
        21053,
        294,
        590,
        25051,
        1026,
        2807,
        12928,
        308,
        15727,
        369,
        30870,
        442,
        72,
        1400,
        644,
        621,
        16485,
        6374,
        3479
      ],
      "temperature": 0,
      "avg_logprob": -0.1944562255359087,
      "compression_ratio": 1.694980694980695,
      "no_speech_prob": 2.715036728773157e-8
    },
    {
      "id": 615,
      "seek": 375184,
      "start": 3769.1800000000003,
      "end": 3775.1400000000003,
      "text": " o anche dei container il tempo iniziale di bootstrap è talmente alto che a far partire",
      "tokens": [
        277,
        11585,
        13874,
        10129,
        1930,
        8972,
        294,
        590,
        25051,
        1026,
        11450,
        372,
        4007,
        4873,
        4023,
        4082,
        21275,
        947,
        257,
        1400,
        644,
        621
      ],
      "temperature": 0,
      "avg_logprob": -0.1944562255359087,
      "compression_ratio": 1.694980694980695,
      "no_speech_prob": 2.715036728773157e-8
    },
    {
      "id": 616,
      "seek": 375184,
      "start": 3775.1400000000003,
      "end": 3779.42,
      "text": " le lambda benché alla fine la computazione ti costa di più però il cliente riesce a",
      "tokens": [
        476,
        13607,
        10638,
        526,
        11591,
        2489,
        635,
        2807,
        12928,
        8757,
        2063,
        64,
        1026,
        10589,
        12673,
        1930,
        6423,
        68,
        23932,
        384,
        257
      ],
      "temperature": 0,
      "avg_logprob": -0.1944562255359087,
      "compression_ratio": 1.694980694980695,
      "no_speech_prob": 2.715036728773157e-8
    },
    {
      "id": 617,
      "seek": 377942,
      "start": 3779.42,
      "end": 3784.94,
      "text": " avere una risposta nel minor tempo possibile per loro quella è la cosa più importante",
      "tokens": [
        37914,
        2002,
        2253,
        79,
        8638,
        15373,
        6696,
        8972,
        50184,
        680,
        28810,
        32234,
        4873,
        635,
        10163,
        10589,
        9416
      ],
      "temperature": 0,
      "avg_logprob": -0.23705985766498983,
      "compression_ratio": 1.6836363636363636,
      "no_speech_prob": 5.181739037851685e-9
    },
    {
      "id": 618,
      "seek": 377942,
      "start": 3784.94,
      "end": 3790.82,
      "text": " quindi pure lì ci sono dei trade off interessanti per cui benché anch'io sono abbastanza d'accordo",
      "tokens": [
        15727,
        6075,
        287,
        4749,
        6983,
        9259,
        13874,
        4923,
        766,
        12478,
        11520,
        680,
        22929,
        10638,
        526,
        12723,
        6,
        1004,
        9259,
        16903,
        525,
        20030,
        274,
        6,
        19947,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.23705985766498983,
      "compression_ratio": 1.6836363636363636,
      "no_speech_prob": 5.181739037851685e-9
    },
    {
      "id": 619,
      "seek": 377942,
      "start": 3790.82,
      "end": 3796.06,
      "text": " nel dire che se devi fare big data e magari ti servono delle macchine belle grosse che",
      "tokens": [
        15373,
        1264,
        947,
        369,
        31219,
        11994,
        955,
        1412,
        308,
        49932,
        8757,
        1658,
        8957,
        16485,
        7912,
        36675,
        28770,
        40009,
        947
      ],
      "temperature": 0,
      "avg_logprob": -0.23705985766498983,
      "compression_ratio": 1.6836363636363636,
      "no_speech_prob": 5.181739037851685e-9
    },
    {
      "id": 620,
      "seek": 377942,
      "start": 3796.06,
      "end": 3802.06,
      "text": " girano sempre nel 99% dei casi quella è la soluzione corretta ci possono essere le variazioni",
      "tokens": [
        14703,
        3730,
        9553,
        15373,
        11803,
        4,
        13874,
        22567,
        32234,
        4873,
        635,
        1404,
        3334,
        5328,
        1181,
        1505,
        1328,
        6983,
        43857,
        19799,
        476,
        1374,
        654,
        89,
        15273
      ],
      "temperature": 0,
      "avg_logprob": -0.23705985766498983,
      "compression_ratio": 1.6836363636363636,
      "no_speech_prob": 5.181739037851685e-9
    },
    {
      "id": 621,
      "seek": 377942,
      "start": 3802.06,
      "end": 3806.2200000000003,
      "text": " di quel tipo di problema in cui magari serverless risulta essere la cosa più ideale proprio",
      "tokens": [
        1026,
        7178,
        9746,
        1026,
        12395,
        294,
        22929,
        49932,
        7154,
        1832,
        2253,
        723,
        64,
        19799,
        635,
        10163,
        10589,
        1153,
        1220,
        28203
      ],
      "temperature": 0,
      "avg_logprob": -0.23705985766498983,
      "compression_ratio": 1.6836363636363636,
      "no_speech_prob": 5.181739037851685e-9
    },
    {
      "id": 622,
      "seek": 380622,
      "start": 3806.22,
      "end": 3813.3799999999997,
      "text": " per quella caratteristica che ha di scalare molto velocemente da 0 a 100 non so se ho",
      "tokens": [
        680,
        32234,
        1032,
        1161,
        468,
        2262,
        947,
        324,
        1026,
        15664,
        543,
        16394,
        1241,
        752,
        384,
        4082,
        1120,
        1958,
        257,
        2319,
        2107,
        370,
        369,
        1106
      ],
      "temperature": 0,
      "avg_logprob": -0.2425112907703106,
      "compression_ratio": 1.551111111111111,
      "no_speech_prob": 2.5505382694746004e-8
    },
    {
      "id": 623,
      "seek": 380622,
      "start": 3813.3799999999997,
      "end": 3820.7,
      "text": " risposto sì sì tra l'altro aggiungo una piccola parentesi la mia critica particolare",
      "tokens": [
        2253,
        79,
        22756,
        49267,
        49267,
        944,
        287,
        6,
        47484,
        42254,
        1063,
        78,
        2002,
        13363,
        66,
        4711,
        2596,
        21181,
        635,
        21290,
        3113,
        2262,
        1276,
        43141
      ],
      "temperature": 0,
      "avg_logprob": -0.2425112907703106,
      "compression_ratio": 1.551111111111111,
      "no_speech_prob": 2.5505382694746004e-8
    },
    {
      "id": 624,
      "seek": 380622,
      "start": 3820.7,
      "end": 3825.62,
      "text": " era verso lambda nel mondo big data tu hai tirato fuori un caso d'uso che funziona ma",
      "tokens": [
        4249,
        49786,
        13607,
        15373,
        40499,
        955,
        1412,
        2604,
        21822,
        13807,
        2513,
        8536,
        7386,
        517,
        9666,
        274,
        6,
        24431,
        947,
        49345,
        21758,
        463
      ],
      "temperature": 0,
      "avg_logprob": -0.2425112907703106,
      "compression_ratio": 1.551111111111111,
      "no_speech_prob": 2.5505382694746004e-8
    },
    {
      "id": 625,
      "seek": 380622,
      "start": 3825.62,
      "end": 3830.4599999999996,
      "text": " io ci tengo anche a evidenziare che AWS visto che stiamo parlando di AWS ha tutta un'altra",
      "tokens": [
        19785,
        6983,
        13989,
        11585,
        257,
        43699,
        3992,
        543,
        947,
        17650,
        17558,
        947,
        342,
        7415,
        971,
        16201,
        1026,
        17650,
        324,
        3672,
        1328,
        517,
        6,
        38865
      ],
      "temperature": 0,
      "avg_logprob": -0.2425112907703106,
      "compression_ratio": 1.551111111111111,
      "no_speech_prob": 2.5505382694746004e-8
    },
    {
      "id": 626,
      "seek": 383046,
      "start": 3830.46,
      "end": 3837.34,
      "text": " serie di servizi serverless per il mondo dei big data uno dei quali è per esempio Athena",
      "tokens": [
        23030,
        1026,
        1658,
        24300,
        7154,
        1832,
        680,
        1930,
        40499,
        13874,
        955,
        1412,
        8526,
        13874,
        4101,
        72,
        4873,
        680,
        33627,
        36827
      ],
      "temperature": 0,
      "avg_logprob": -0.25812247364791396,
      "compression_ratio": 1.6497695852534562,
      "no_speech_prob": 2.9818668423331474e-8
    },
    {
      "id": 627,
      "seek": 383046,
      "start": 3837.34,
      "end": 3844.86,
      "text": " che è già pensato strutturato e ragiona in un'ottica un po' più diversa quindi il mio",
      "tokens": [
        947,
        4873,
        30469,
        6099,
        2513,
        1056,
        13478,
        374,
        2513,
        308,
        17539,
        21758,
        294,
        517,
        6,
        1521,
        2262,
        517,
        714,
        6,
        10589,
        6111,
        64,
        15727,
        1930,
        29908
      ],
      "temperature": 0,
      "avg_logprob": -0.25812247364791396,
      "compression_ratio": 1.6497695852534562,
      "no_speech_prob": 2.9818668423331474e-8
    },
    {
      "id": 628,
      "seek": 383046,
      "start": 3844.86,
      "end": 3853.06,
      "text": " esempio di serverless function era correlato al fatto di usare probabilmente uno strumento",
      "tokens": [
        33627,
        1026,
        7154,
        1832,
        2445,
        4249,
        13983,
        2513,
        419,
        23228,
        1026,
        505,
        543,
        31959,
        4082,
        8526,
        1056,
        2206,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.25812247364791396,
      "compression_ratio": 1.6497695852534562,
      "no_speech_prob": 2.9818668423331474e-8
    },
    {
      "id": 629,
      "seek": 383046,
      "start": 3853.06,
      "end": 3858.14,
      "text": " nel caso che avevo visto io era utilizzare uno strumento per il quale magari non fittava",
      "tokens": [
        15373,
        9666,
        947,
        3472,
        3080,
        17558,
        19785,
        4249,
        40355,
        543,
        8526,
        1056,
        2206,
        78,
        680,
        1930,
        421,
        1220,
        49932,
        2107,
        48876,
        4061
      ],
      "temperature": 0,
      "avg_logprob": -0.25812247364791396,
      "compression_ratio": 1.6497695852534562,
      "no_speech_prob": 2.9818668423331474e-8
    },
    {
      "id": 630,
      "seek": 385814,
      "start": 3858.14,
      "end": 3870.54,
      "text": " al 100% volevo chiederti anche un'altra cosa interessante in realtà che riguarda proprio",
      "tokens": [
        419,
        2319,
        4,
        49877,
        3080,
        417,
        1091,
        911,
        72,
        11585,
        517,
        6,
        38865,
        10163,
        24372,
        294,
        47512,
        947,
        8329,
        16981,
        64,
        28203
      ],
      "temperature": 0,
      "avg_logprob": -0.24884779793875558,
      "compression_ratio": 1.5555555555555556,
      "no_speech_prob": 7.778710120476262e-9
    },
    {
      "id": 631,
      "seek": 385814,
      "start": 3870.54,
      "end": 3879.42,
      "text": " al concetto sempre di serverless function e riguarda nel fatto che proprio nella parola",
      "tokens": [
        419,
        1588,
        23778,
        9553,
        1026,
        7154,
        1832,
        2445,
        308,
        8329,
        16981,
        64,
        15373,
        23228,
        947,
        28203,
        23878,
        971,
        4711
      ],
      "temperature": 0,
      "avg_logprob": -0.24884779793875558,
      "compression_ratio": 1.5555555555555556,
      "no_speech_prob": 7.778710120476262e-9
    },
    {
      "id": 632,
      "seek": 385814,
      "start": 3879.42,
      "end": 3885.62,
      "text": " no quando si parla di computazione serverless si ragiona in termini di funzione no però",
      "tokens": [
        572,
        7770,
        1511,
        971,
        875,
        1026,
        2807,
        12928,
        7154,
        1832,
        1511,
        17539,
        21758,
        294,
        1433,
        3812,
        1026,
        1019,
        19706,
        572,
        12673
      ],
      "temperature": 0,
      "avg_logprob": -0.24884779793875558,
      "compression_ratio": 1.5555555555555556,
      "no_speech_prob": 7.778710120476262e-9
    },
    {
      "id": 633,
      "seek": 388562,
      "start": 3885.62,
      "end": 3895.66,
      "text": " nel contempo ti trovi degli strumenti che ti buttano un Laravel dentro una serverless",
      "tokens": [
        15373,
        660,
        443,
        2259,
        8757,
        4495,
        4917,
        32079,
        1056,
        2206,
        72,
        947,
        8757,
        6660,
        3730,
        517,
        33935,
        779,
        10856,
        2002,
        7154,
        1832
      ],
      "temperature": 0,
      "avg_logprob": -0.259881676017464,
      "compression_ratio": 1.535294117647059,
      "no_speech_prob": 1.7907608729217372e-9
    },
    {
      "id": 634,
      "seek": 388562,
      "start": 3895.66,
      "end": 3905.38,
      "text": " function come reagisci davanti a questo tipo di uso è un misuso o è un caso d'uso che",
      "tokens": [
        2445,
        808,
        26949,
        271,
        537,
        11753,
        11520,
        257,
        10263,
        9746,
        1026,
        22728,
        4873,
        517,
        3346,
        24431,
        277,
        4873,
        517,
        9666,
        274,
        6,
        24431,
        947
      ],
      "temperature": 0,
      "avg_logprob": -0.259881676017464,
      "compression_ratio": 1.535294117647059,
      "no_speech_prob": 1.7907608729217372e-9
    },
    {
      "id": 635,
      "seek": 388562,
      "start": 3905.38,
      "end": 3912.62,
      "text": " ha anche senso? Io sono all'estate abbastanza contrario anche magari Laravel è un caso",
      "tokens": [
        324,
        11585,
        3151,
        539,
        30,
        19239,
        9259,
        419,
        75,
        6,
        377,
        473,
        16903,
        525,
        20030,
        47642,
        11585,
        49932,
        33935,
        779,
        4873,
        517,
        9666
      ],
      "temperature": 0,
      "avg_logprob": -0.259881676017464,
      "compression_ratio": 1.535294117647059,
      "no_speech_prob": 1.7907608729217372e-9
    },
    {
      "id": 636,
      "seek": 391262,
      "start": 3912.62,
      "end": 3918.06,
      "text": " estremo ma anche Express che è molto più lightweight non lo metterei dentro una lambda",
      "tokens": [
        871,
        44172,
        463,
        11585,
        20212,
        947,
        4873,
        16394,
        10589,
        22052,
        2107,
        450,
        1131,
        391,
        17067,
        10856,
        2002,
        13607
      ],
      "temperature": 0,
      "avg_logprob": -0.26876841534625046,
      "compression_ratio": 1.4705882352941178,
      "no_speech_prob": 8.494594538888123e-8
    },
    {
      "id": 637,
      "seek": 391262,
      "start": 3918.06,
      "end": 3924.6,
      "text": " per fare web server perché secondo me lì c'è proprio un problema di astrazioni che",
      "tokens": [
        680,
        11994,
        3670,
        7154,
        14303,
        41601,
        385,
        287,
        4749,
        269,
        6,
        1462,
        28203,
        517,
        12395,
        1026,
        5357,
        30695,
        15273,
        947
      ],
      "temperature": 0,
      "avg_logprob": -0.26876841534625046,
      "compression_ratio": 1.4705882352941178,
      "no_speech_prob": 8.494594538888123e-8
    },
    {
      "id": 638,
      "seek": 391262,
      "start": 3924.6,
      "end": 3930.4,
      "text": " non matchano al 100% nel senso che se tu prendi questo tipo di web framework tradizionali",
      "tokens": [
        2107,
        2995,
        3730,
        419,
        2319,
        4,
        15373,
        3151,
        539,
        947,
        369,
        2604,
        9866,
        72,
        10263,
        9746,
        1026,
        3670,
        8388,
        2479,
        590,
        1966,
        72
      ],
      "temperature": 0,
      "avg_logprob": -0.26876841534625046,
      "compression_ratio": 1.4705882352941178,
      "no_speech_prob": 8.494594538888123e-8
    },
    {
      "id": 639,
      "seek": 391262,
      "start": 3930.4,
      "end": 3937.8199999999997,
      "text": " sono pensati per girare con una socket TCP che ti gestisce questa connessione HTTP ti",
      "tokens": [
        9259,
        6099,
        6908,
        680,
        14703,
        543,
        416,
        2002,
        19741,
        48965,
        947,
        8757,
        7219,
        49596,
        16540,
        416,
        1287,
        5328,
        33283,
        8757
      ],
      "temperature": 0,
      "avg_logprob": -0.26876841534625046,
      "compression_ratio": 1.4705882352941178,
      "no_speech_prob": 8.494594538888123e-8
    },
    {
      "id": 640,
      "seek": 393782,
      "start": 3937.82,
      "end": 3943.42,
      "text": " arriva una richiesta manda una risposta su questa connessione e il web framework è proprio",
      "tokens": [
        3399,
        2757,
        2002,
        4593,
        38804,
        7411,
        64,
        2002,
        2253,
        79,
        8638,
        459,
        16540,
        416,
        1287,
        5328,
        308,
        1930,
        3670,
        8388,
        4873,
        28203
      ],
      "temperature": 0,
      "avg_logprob": -0.23872012946441884,
      "compression_ratio": 1.806201550387597,
      "no_speech_prob": 5.871679142899211e-9
    },
    {
      "id": 641,
      "seek": 393782,
      "start": 3943.42,
      "end": 3948.38,
      "text": " in controllo di questa connessione può decidere di fare streaming di tagliare questa richiesta",
      "tokens": [
        294,
        1583,
        1913,
        1026,
        16540,
        416,
        1287,
        5328,
        26526,
        21937,
        323,
        1026,
        11994,
        11791,
        1026,
        6162,
        2081,
        543,
        16540,
        4593,
        38804
      ],
      "temperature": 0,
      "avg_logprob": -0.23872012946441884,
      "compression_ratio": 1.806201550387597,
      "no_speech_prob": 5.871679142899211e-9
    },
    {
      "id": 642,
      "seek": 393782,
      "start": 3948.38,
      "end": 3953.78,
      "text": " a metà fare tutta una serie di cose che nel paradigma lambda non esistono perché l'astrazione",
      "tokens": [
        257,
        1131,
        1467,
        11994,
        3672,
        1328,
        2002,
        23030,
        1026,
        30261,
        947,
        15373,
        24709,
        64,
        13607,
        2107,
        785,
        468,
        8957,
        14303,
        287,
        6,
        525,
        424,
        19706
      ],
      "temperature": 0,
      "avg_logprob": -0.23872012946441884,
      "compression_ratio": 1.806201550387597,
      "no_speech_prob": 5.871679142899211e-9
    },
    {
      "id": 643,
      "seek": 393782,
      "start": 3953.78,
      "end": 3960.46,
      "text": " sta dopo cioè nel paradigma lambda c'è un evento e una risposta e entrambi sono dei",
      "tokens": [
        11135,
        35196,
        41827,
        15373,
        13480,
        16150,
        13607,
        269,
        6,
        1462,
        517,
        40655,
        308,
        2002,
        2253,
        79,
        8638,
        308,
        8041,
        2173,
        72,
        9259,
        13874
      ],
      "temperature": 0,
      "avg_logprob": -0.23872012946441884,
      "compression_ratio": 1.806201550387597,
      "no_speech_prob": 5.871679142899211e-9
    },
    {
      "id": 644,
      "seek": 393782,
      "start": 3960.46,
      "end": 3966.6600000000003,
      "text": " json che vengono totalmente bufferizzati in entrate e uscite non c'è nessun tipo di connessione",
      "tokens": [
        361,
        3015,
        947,
        371,
        1501,
        8957,
        30865,
        21762,
        8072,
        6908,
        294,
        948,
        4404,
        308,
        505,
        66,
        642,
        2107,
        269,
        6,
        1462,
        39787,
        409,
        9746,
        1026,
        416,
        1287,
        5328
      ],
      "temperature": 0,
      "avg_logprob": -0.23872012946441884,
      "compression_ratio": 1.806201550387597,
      "no_speech_prob": 5.871679142899211e-9
    },
    {
      "id": 645,
      "seek": 396666,
      "start": 3966.66,
      "end": 3972.94,
      "text": " permanente quindi quello che ci sono degli adapter che trovi per l'arabel per express",
      "tokens": [
        8105,
        1576,
        15727,
        22813,
        947,
        6983,
        9259,
        32079,
        22860,
        947,
        4495,
        4917,
        680,
        287,
        6,
        289,
        455,
        338,
        680,
        5109
      ],
      "temperature": 0,
      "avg_logprob": -0.2855090906124304,
      "compression_ratio": 1.6428571428571428,
      "no_speech_prob": 2.9356538533420462e-8
    },
    {
      "id": 646,
      "seek": 396666,
      "start": 3972.94,
      "end": 3980.8199999999997,
      "text": " che ti permettono di far sì che questi eventi vengono convertiti in diciamo richieste risposte",
      "tokens": [
        947,
        8757,
        20696,
        1756,
        78,
        1026,
        1400,
        49267,
        947,
        29729,
        2280,
        72,
        371,
        1501,
        8957,
        7620,
        8707,
        294,
        14285,
        7415,
        4593,
        6495,
        68,
        2253,
        23744,
        68
      ],
      "temperature": 0,
      "avg_logprob": -0.2855090906124304,
      "compression_ratio": 1.6428571428571428,
      "no_speech_prob": 2.9356538533420462e-8
    },
    {
      "id": 647,
      "seek": 396666,
      "start": 3980.8199999999997,
      "end": 3985.94,
      "text": " finte per dal punto di vista del framework però quello fa sì che tutta una serie di",
      "tokens": [
        283,
        12401,
        680,
        11702,
        14326,
        1026,
        22553,
        1103,
        8388,
        12673,
        22813,
        2050,
        49267,
        947,
        3672,
        1328,
        2002,
        23030,
        1026
      ],
      "temperature": 0,
      "avg_logprob": -0.2855090906124304,
      "compression_ratio": 1.6428571428571428,
      "no_speech_prob": 2.9356538533420462e-8
    },
    {
      "id": 648,
      "seek": 396666,
      "start": 3985.94,
      "end": 3991.3399999999997,
      "text": " cose poi magari non funziona come tu ti aspetteresti banalmente torniamo sempre al discorso dell'app",
      "tokens": [
        30261,
        19260,
        49932,
        2107,
        49345,
        21758,
        808,
        2604,
        8757,
        16817,
        3093,
        323,
        39505,
        5643,
        304,
        4082,
        10885,
        7415,
        9553,
        419,
        2983,
        284,
        539,
        19781,
        6,
        1746
      ],
      "temperature": 0,
      "avg_logprob": -0.2855090906124304,
      "compression_ratio": 1.6428571428571428,
      "no_speech_prob": 2.9356538533420462e-8
    },
    {
      "id": 649,
      "seek": 399134,
      "start": 3991.34,
      "end": 3996.78,
      "text": " lodo del download quindi casi d'uso un po più streaming non non funzioneranno quando",
      "tokens": [
        287,
        17423,
        1103,
        5484,
        15727,
        22567,
        274,
        6,
        24431,
        517,
        714,
        10589,
        11791,
        2107,
        2107,
        49345,
        313,
        260,
        13484,
        7770
      ],
      "temperature": 0,
      "avg_logprob": -0.24006484236036027,
      "compression_ratio": 1.7035573122529644,
      "no_speech_prob": 1.986363429296034e-8
    },
    {
      "id": 650,
      "seek": 399134,
      "start": 3996.78,
      "end": 4003.06,
      "text": " tu li utilizzi nel contesto di diciamo una un deployment di express dentro una lambda",
      "tokens": [
        2604,
        375,
        19906,
        3992,
        15373,
        10287,
        78,
        1026,
        14285,
        7415,
        2002,
        517,
        19317,
        1026,
        5109,
        10856,
        2002,
        13607
      ],
      "temperature": 0,
      "avg_logprob": -0.24006484236036027,
      "compression_ratio": 1.7035573122529644,
      "no_speech_prob": 1.986363429296034e-8
    },
    {
      "id": 651,
      "seek": 399134,
      "start": 4003.06,
      "end": 4007.6200000000003,
      "text": " se tu vai a utilizzare quelle funzioni di streaming non possono mai funzionare come",
      "tokens": [
        369,
        2604,
        4405,
        257,
        40355,
        543,
        29237,
        49345,
        15273,
        1026,
        11791,
        2107,
        43857,
        12698,
        49345,
        313,
        543,
        808
      ],
      "temperature": 0,
      "avg_logprob": -0.24006484236036027,
      "compression_ratio": 1.7035573122529644,
      "no_speech_prob": 1.986363429296034e-8
    },
    {
      "id": 652,
      "seek": 399134,
      "start": 4007.6200000000003,
      "end": 4012.34,
      "text": " funzionerebbero normalmente in un web server quindi secondo me il rischio è sì magari",
      "tokens": [
        49345,
        313,
        323,
        65,
        46659,
        38217,
        294,
        517,
        3670,
        7154,
        15727,
        41601,
        385,
        1930,
        2253,
        31033,
        4873,
        49267,
        49932
      ],
      "temperature": 0,
      "avg_logprob": -0.24006484236036027,
      "compression_ratio": 1.7035573122529644,
      "no_speech_prob": 1.986363429296034e-8
    },
    {
      "id": 653,
      "seek": 399134,
      "start": 4012.34,
      "end": 4018.46,
      "text": " per il 90 per cento dei casi d'uso non vedi la differenza però ci sono un 10 per cento",
      "tokens": [
        680,
        1930,
        4289,
        680,
        1489,
        78,
        13874,
        22567,
        274,
        6,
        24431,
        2107,
        371,
        10323,
        635,
        743,
        23691,
        12673,
        6983,
        9259,
        517,
        1266,
        680,
        1489,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.24006484236036027,
      "compression_ratio": 1.7035573122529644,
      "no_speech_prob": 1.986363429296034e-8
    },
    {
      "id": 654,
      "seek": 401846,
      "start": 4018.46,
      "end": 4022.78,
      "text": " di casi d'uso in cui non funziona proprio e alla fin della fiera ti ritrovi a dover",
      "tokens": [
        1026,
        22567,
        274,
        6,
        24431,
        294,
        22929,
        2107,
        49345,
        21758,
        28203,
        308,
        11591,
        962,
        11618,
        283,
        10609,
        8757,
        11289,
        340,
        4917,
        257,
        360,
        331
      ],
      "temperature": 0,
      "avg_logprob": -0.2126587459019252,
      "compression_ratio": 1.7237354085603114,
      "no_speech_prob": 4.944448850352501e-9
    },
    {
      "id": 655,
      "seek": 401846,
      "start": 4022.78,
      "end": 4028.86,
      "text": " pagare il costo di una strazione che non so che vantaggio ti dà magari l'unico vantaggio",
      "tokens": [
        11812,
        543,
        1930,
        2063,
        78,
        1026,
        2002,
        2148,
        19706,
        947,
        2107,
        370,
        947,
        371,
        394,
        30763,
        8757,
        274,
        1467,
        49932,
        287,
        6,
        409,
        2789,
        371,
        394,
        30763
      ],
      "temperature": 0,
      "avg_logprob": -0.2126587459019252,
      "compression_ratio": 1.7237354085603114,
      "no_speech_prob": 4.944448850352501e-9
    },
    {
      "id": 656,
      "seek": 401846,
      "start": 4028.86,
      "end": 4032.9,
      "text": " che puoi avere la familiarità con quello strumento ma lo stai andando a calare in un",
      "tokens": [
        947,
        2362,
        4869,
        37914,
        635,
        4963,
        12445,
        416,
        22813,
        1056,
        2206,
        78,
        463,
        450,
        342,
        1301,
        293,
        1806,
        257,
        2104,
        543,
        294,
        517
      ],
      "temperature": 0,
      "avg_logprob": -0.2126587459019252,
      "compression_ratio": 1.7237354085603114,
      "no_speech_prob": 4.944448850352501e-9
    },
    {
      "id": 657,
      "seek": 401846,
      "start": 4032.9,
      "end": 4039.14,
      "text": " contesto che non segue al 100 per cento le regole per cui quello strumento è stato pensato",
      "tokens": [
        10287,
        78,
        947,
        2107,
        33850,
        419,
        2319,
        680,
        1489,
        78,
        476,
        1121,
        4812,
        680,
        22929,
        22813,
        1056,
        2206,
        78,
        4873,
        29657,
        6099,
        2513
      ],
      "temperature": 0,
      "avg_logprob": -0.2126587459019252,
      "compression_ratio": 1.7237354085603114,
      "no_speech_prob": 4.944448850352501e-9
    },
    {
      "id": 658,
      "seek": 401846,
      "start": 4039.14,
      "end": 4043.7400000000002,
      "text": " quindi io continuo sempre a sconsigliare quel tipo di approccio poi è vero pure ci possono",
      "tokens": [
        15727,
        19785,
        2993,
        78,
        9553,
        257,
        795,
        892,
        328,
        2081,
        543,
        7178,
        9746,
        1026,
        2075,
        66,
        8529,
        19260,
        4873,
        1306,
        78,
        6075,
        6983,
        43857
      ],
      "temperature": 0,
      "avg_logprob": -0.2126587459019252,
      "compression_ratio": 1.7237354085603114,
      "no_speech_prob": 4.944448850352501e-9
    },
    {
      "id": 659,
      "seek": 404374,
      "start": 4043.74,
      "end": 4048.74,
      "text": " essere delle condizioni molto particolari in cui dici vabbè ma c'è questo codice in",
      "tokens": [
        19799,
        16485,
        2224,
        590,
        15273,
        16394,
        1276,
        401,
        3504,
        294,
        22929,
        274,
        8787,
        371,
        10797,
        1462,
        463,
        269,
        6,
        1462,
        10263,
        17656,
        573,
        294
      ],
      "temperature": 0,
      "avg_logprob": -0.2791725032585711,
      "compression_ratio": 1.7203065134099618,
      "no_speech_prob": 9.988053051301904e-9
    },
    {
      "id": 660,
      "seek": 404374,
      "start": 4048.74,
      "end": 4053.9799999999996,
      "text": " express già scritto è una cosa piccola la prendo e la tiro in una lambda perché comunque",
      "tokens": [
        5109,
        30469,
        5918,
        34924,
        4873,
        2002,
        10163,
        13363,
        66,
        4711,
        635,
        9866,
        78,
        308,
        635,
        44188,
        294,
        2002,
        13607,
        14303,
        45736
      ],
      "temperature": 0,
      "avg_logprob": -0.2791725032585711,
      "compression_ratio": 1.7203065134099618,
      "no_speech_prob": 9.988053051301904e-9
    },
    {
      "id": 661,
      "seek": 404374,
      "start": 4053.9799999999996,
      "end": 4059.8999999999996,
      "text": " voglio andare a fare delle lambda nel breve medio periodo può essere un trade off accettabile",
      "tokens": [
        31273,
        19987,
        42742,
        257,
        11994,
        16485,
        13607,
        15373,
        48517,
        22123,
        2896,
        78,
        26526,
        19799,
        517,
        4923,
        766,
        1317,
        3093,
        33288
      ],
      "temperature": 0,
      "avg_logprob": -0.2791725032585711,
      "compression_ratio": 1.7203065134099618,
      "no_speech_prob": 9.988053051301904e-9
    },
    {
      "id": 662,
      "seek": 404374,
      "start": 4059.8999999999996,
      "end": 4064.9399999999996,
      "text": " se sai esattamente a cosa puoi andare incontro ma non lo farei insomma come best practice",
      "tokens": [
        369,
        32417,
        785,
        1591,
        3439,
        257,
        10163,
        2362,
        4869,
        42742,
        834,
        896,
        340,
        463,
        2107,
        450,
        11994,
        72,
        1028,
        30243,
        808,
        1151,
        3124
      ],
      "temperature": 0,
      "avg_logprob": -0.2791725032585711,
      "compression_ratio": 1.7203065134099618,
      "no_speech_prob": 9.988053051301904e-9
    },
    {
      "id": 663,
      "seek": 404374,
      "start": 4064.9399999999996,
      "end": 4070.3399999999997,
      "text": " anche perché come scorciatoia diciamo anche perché i tempi di boot della lambda e dt",
      "tokens": [
        11585,
        14303,
        808,
        38629,
        537,
        2513,
        654,
        14285,
        7415,
        11585,
        14303,
        741,
        18274,
        72,
        1026,
        11450,
        11618,
        13607,
        308,
        274,
        83
      ],
      "temperature": 0,
      "avg_logprob": -0.2791725032585711,
      "compression_ratio": 1.7203065134099618,
      "no_speech_prob": 9.988053051301904e-9
    },
    {
      "id": 664,
      "seek": 407034,
      "start": 4070.34,
      "end": 4075.58,
      "text": " express dentro la lambda vogliono dire soldi no? Esatto quindi stai andando a pagare quel",
      "tokens": [
        5109,
        10856,
        635,
        13607,
        31273,
        75,
        49020,
        1264,
        3718,
        72,
        572,
        30,
        2313,
        37491,
        15727,
        342,
        1301,
        293,
        1806,
        257,
        11812,
        543,
        7178
      ],
      "temperature": 0,
      "avg_logprob": -0.28921526128595526,
      "compression_ratio": 1.5656108597285068,
      "no_speech_prob": 1.3652061703339768e-8
    },
    {
      "id": 665,
      "seek": 407034,
      "start": 4075.58,
      "end": 4081.2200000000003,
      "text": " tipo di astrazione per non credo avere un tipo di vantaggio pratico se non quello che",
      "tokens": [
        9746,
        1026,
        5357,
        424,
        19706,
        680,
        2107,
        3864,
        78,
        37914,
        517,
        9746,
        1026,
        371,
        394,
        30763,
        33852,
        78,
        369,
        2107,
        22813,
        947
      ],
      "temperature": 0,
      "avg_logprob": -0.28921526128595526,
      "compression_ratio": 1.5656108597285068,
      "no_speech_prob": 1.3652061703339768e-8
    },
    {
      "id": 666,
      "seek": 407034,
      "start": 4081.2200000000003,
      "end": 4086.26,
      "text": " si se magari già ce l'hai scritta così non devi riscriverla in un altro modo. Certo",
      "tokens": [
        1511,
        369,
        49932,
        30469,
        1769,
        287,
        6,
        18230,
        5918,
        21870,
        23278,
        2107,
        31219,
        2253,
        1142,
        331,
        875,
        294,
        517,
        40924,
        16664,
        13,
        383,
        13098
      ],
      "temperature": 0,
      "avg_logprob": -0.28921526128595526,
      "compression_ratio": 1.5656108597285068,
      "no_speech_prob": 1.3652061703339768e-8
    },
    {
      "id": 667,
      "seek": 407034,
      "start": 4086.26,
      "end": 4094.38,
      "text": " ma hai detto prima no che in realtà anzi abbiamo detto che in realtà c'è tutto il",
      "tokens": [
        463,
        21822,
        41031,
        19507,
        572,
        947,
        294,
        47512,
        364,
        3992,
        22815,
        41031,
        947,
        294,
        47512,
        269,
        6,
        1462,
        23048,
        1930
      ],
      "temperature": 0,
      "avg_logprob": -0.28921526128595526,
      "compression_ratio": 1.5656108597285068,
      "no_speech_prob": 1.3652061703339768e-8
    },
    {
      "id": 668,
      "seek": 409438,
      "start": 4094.38,
      "end": 4103.3,
      "text": " mondo tutta la parte di glue code si è spostata talvolta si sposta verso l'architettura l'infrastruttura",
      "tokens": [
        40499,
        3672,
        1328,
        635,
        6975,
        1026,
        8998,
        3089,
        1511,
        4873,
        637,
        555,
        3274,
        4023,
        9646,
        1328,
        1511,
        637,
        8638,
        49786,
        287,
        6,
        1178,
        270,
        3093,
        2991,
        287,
        6,
        19920,
        4148,
        81,
        13478,
        2991
      ],
      "temperature": 0,
      "avg_logprob": -0.20652950343801013,
      "compression_ratio": 1.3943661971830985,
      "no_speech_prob": 3.486167088340153e-8
    },
    {
      "id": 669,
      "seek": 409438,
      "start": 4103.3,
      "end": 4111.66,
      "text": " e tra i servizi di AWS c'è sempre un servizio serverless che ha catturato la mia attenzione",
      "tokens": [
        308,
        944,
        741,
        1658,
        24300,
        1026,
        17650,
        269,
        6,
        1462,
        9553,
        517,
        1658,
        590,
        1004,
        7154,
        1832,
        947,
        324,
        269,
        1591,
        374,
        2513,
        635,
        21290,
        951,
        11368,
        5328
      ],
      "temperature": 0,
      "avg_logprob": -0.20652950343801013,
      "compression_ratio": 1.3943661971830985,
      "no_speech_prob": 3.486167088340153e-8
    },
    {
      "id": 670,
      "seek": 411166,
      "start": 4111.66,
      "end": 4128.5,
      "text": " e che è Upsync che è GraphQL as a service che mettiamola così. Quando Luciano potrebbe",
      "tokens": [
        308,
        947,
        4873,
        624,
        1878,
        34015,
        947,
        4873,
        21884,
        13695,
        382,
        257,
        2643,
        947,
        27812,
        2918,
        4711,
        23278,
        13,
        18725,
        37309,
        3730,
        1847,
        39487
      ],
      "temperature": 0,
      "avg_logprob": -0.3172600710833514,
      "compression_ratio": 1.289855072463768,
      "no_speech_prob": 1.808603755648619e-8
    },
    {
      "id": 671,
      "seek": 411166,
      "start": 4128.5,
      "end": 4135.38,
      "text": " scegliere cioè quali sono le condizioni per le quali tu saresti tentato di andare verso",
      "tokens": [
        262,
        384,
        41443,
        323,
        41827,
        4101,
        72,
        9259,
        476,
        2224,
        590,
        15273,
        680,
        476,
        4101,
        72,
        2604,
        13782,
        21597,
        7054,
        2513,
        1026,
        42742,
        49786
      ],
      "temperature": 0,
      "avg_logprob": -0.3172600710833514,
      "compression_ratio": 1.289855072463768,
      "no_speech_prob": 1.808603755648619e-8
    },
    {
      "id": 672,
      "seek": 413538,
      "start": 4135.38,
      "end": 4145.82,
      "text": " una soluzione gestita come Upsync e quando invece preferiresti tirarti su il tuo buon",
      "tokens": [
        2002,
        1404,
        3334,
        5328,
        7219,
        2786,
        808,
        624,
        1878,
        34015,
        308,
        7770,
        36344,
        4382,
        621,
        39505,
        13807,
        40155,
        459,
        1930,
        45352,
        758,
        266
      ],
      "temperature": 0,
      "avg_logprob": -0.25979810078938803,
      "compression_ratio": 1.4662921348314606,
      "no_speech_prob": 8.67777938395875e-9
    },
    {
      "id": 673,
      "seek": 413538,
      "start": 4145.82,
      "end": 4154.62,
      "text": " appollo che ti chiama i tuoi microservizi davanti magari a un API gateway della situazione?",
      "tokens": [
        724,
        22388,
        947,
        8757,
        13228,
        2404,
        741,
        2604,
        4869,
        15547,
        1978,
        24300,
        11753,
        11520,
        49932,
        257,
        517,
        9362,
        28532,
        11618,
        2054,
        12928,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.25979810078938803,
      "compression_ratio": 1.4662921348314606,
      "no_speech_prob": 8.67777938395875e-9
    },
    {
      "id": 674,
      "seek": 413538,
      "start": 4154.62,
      "end": 4160.54,
      "text": " Allora su questo argomento sono piuttosto ignorante quindi ti do una risposta molto",
      "tokens": [
        1057,
        3252,
        459,
        10263,
        3882,
        298,
        15467,
        9259,
        3895,
        13478,
        22756,
        14698,
        2879,
        15727,
        8757,
        360,
        2002,
        2253,
        79,
        8638,
        16394
      ],
      "temperature": 0,
      "avg_logprob": -0.25979810078938803,
      "compression_ratio": 1.4662921348314606,
      "no_speech_prob": 8.67777938395875e-9
    },
    {
      "id": 675,
      "seek": 416054,
      "start": 4160.54,
      "end": 4166.38,
      "text": " vaga nel senso che ho praticamente quasi mai fatto GraphQL in produzione ho solo fatto",
      "tokens": [
        371,
        9286,
        15373,
        3151,
        539,
        947,
        1106,
        45734,
        20954,
        12698,
        23228,
        21884,
        13695,
        294,
        1082,
        19706,
        1106,
        6944,
        23228
      ],
      "temperature": 0,
      "avg_logprob": -0.24987604200225516,
      "compression_ratio": 1.6,
      "no_speech_prob": 1.2952709482760838e-7
    },
    {
      "id": 676,
      "seek": 416054,
      "start": 4166.38,
      "end": 4174.38,
      "text": " così dei giochini per per conto mio personale quindi non ti saprei dire quanto Upsync effettivamente",
      "tokens": [
        23278,
        13874,
        48508,
        339,
        3812,
        680,
        680,
        660,
        78,
        29908,
        954,
        1220,
        15727,
        2107,
        8757,
        18985,
        10271,
        1264,
        17820,
        624,
        1878,
        34015,
        1244,
        3093,
        23957
      ],
      "temperature": 0,
      "avg_logprob": -0.24987604200225516,
      "compression_ratio": 1.6,
      "no_speech_prob": 1.2952709482760838e-7
    },
    {
      "id": 677,
      "seek": 416054,
      "start": 4174.38,
      "end": 4180.74,
      "text": " a livello proprio di feature è in pari con un Apollo Server mi aspetto conoscendo AWS",
      "tokens": [
        257,
        1621,
        1913,
        28203,
        1026,
        4111,
        4873,
        294,
        971,
        72,
        416,
        517,
        25187,
        25684,
        2752,
        382,
        42801,
        416,
        10466,
        3999,
        17650
      ],
      "temperature": 0,
      "avg_logprob": -0.24987604200225516,
      "compression_ratio": 1.6,
      "no_speech_prob": 1.2952709482760838e-7
    },
    {
      "id": 678,
      "seek": 416054,
      "start": 4180.74,
      "end": 4184.74,
      "text": " che non lo sia nel senso che un Apollo Server magari ti da molta più flessibilità rispetto",
      "tokens": [
        947,
        2107,
        450,
        25176,
        15373,
        3151,
        539,
        947,
        517,
        25187,
        25684,
        49932,
        8757,
        1120,
        48564,
        10589,
        932,
        442,
        11607,
        12445,
        2253,
        42801
      ],
      "temperature": 0,
      "avg_logprob": -0.24987604200225516,
      "compression_ratio": 1.6,
      "no_speech_prob": 1.2952709482760838e-7
    },
    {
      "id": 679,
      "seek": 418474,
      "start": 4184.74,
      "end": 4190.66,
      "text": " ad Upsync e quindi forse il trade off è sempre un po' lo stesso quello di dire ma quanta",
      "tokens": [
        614,
        624,
        1878,
        34015,
        308,
        15727,
        337,
        405,
        1930,
        4923,
        766,
        4873,
        9553,
        517,
        714,
        6,
        450,
        44413,
        22813,
        1026,
        1264,
        463,
        4426,
        64
      ],
      "temperature": 0,
      "avg_logprob": -0.21957927796898818,
      "compression_ratio": 1.655430711610487,
      "no_speech_prob": 1.3574266688465286e-7
    },
    {
      "id": 680,
      "seek": 418474,
      "start": 4190.66,
      "end": 4199.34,
      "text": " voglia c'ho tempo risorse di andarmi a gestire io un container che sia o una macchina virtuale",
      "tokens": [
        31273,
        14218,
        269,
        6,
        1289,
        8972,
        2253,
        18699,
        1026,
        50009,
        3057,
        257,
        7219,
        621,
        19785,
        517,
        10129,
        947,
        25176,
        277,
        2002,
        7912,
        339,
        1426,
        6374,
        68
      ],
      "temperature": 0,
      "avg_logprob": -0.21957927796898818,
      "compression_ratio": 1.655430711610487,
      "no_speech_prob": 1.3574266688465286e-7
    },
    {
      "id": 681,
      "seek": 418474,
      "start": 4199.34,
      "end": 4203.78,
      "text": " rispetto con qualcosa che dico vabbè quando arriva a sta chiamata parte sta lambda che",
      "tokens": [
        2253,
        42801,
        416,
        42400,
        947,
        274,
        2789,
        371,
        10797,
        1462,
        7770,
        3399,
        2757,
        257,
        11135,
        417,
        2918,
        3274,
        6975,
        11135,
        13607,
        947
      ],
      "temperature": 0,
      "avg_logprob": -0.21957927796898818,
      "compression_ratio": 1.655430711610487,
      "no_speech_prob": 1.3574266688465286e-7
    },
    {
      "id": 682,
      "seek": 418474,
      "start": 4203.78,
      "end": 4208.42,
      "text": " già ho scritto e basta e non mi interessa pensare al sistema operativo alle librerie",
      "tokens": [
        30469,
        1106,
        5918,
        34924,
        308,
        45282,
        308,
        2107,
        2752,
        728,
        8391,
        6099,
        543,
        419,
        13245,
        2208,
        18586,
        5430,
        4939,
        17487
      ],
      "temperature": 0,
      "avg_logprob": -0.21957927796898818,
      "compression_ratio": 1.655430711610487,
      "no_speech_prob": 1.3574266688465286e-7
    },
    {
      "id": 683,
      "seek": 418474,
      "start": 4208.42,
      "end": 4213.66,
      "text": " eccetera quindi forse fare questo tipo di ragionamento e dipende dalla complessità",
      "tokens": [
        29613,
        20269,
        15727,
        337,
        405,
        11994,
        10263,
        9746,
        1026,
        17539,
        313,
        8824,
        308,
        10460,
        5445,
        35566,
        1209,
        442,
        12445
      ],
      "temperature": 0,
      "avg_logprob": -0.21957927796898818,
      "compression_ratio": 1.655430711610487,
      "no_speech_prob": 1.3574266688465286e-7
    },
    {
      "id": 684,
      "seek": 421366,
      "start": 4213.66,
      "end": 4217.3,
      "text": " del tipo di applicazione che stiamo andando a scrivere e il tipo di feature che mi servono",
      "tokens": [
        1103,
        9746,
        1026,
        2580,
        12928,
        947,
        342,
        7415,
        293,
        1806,
        257,
        5545,
        5887,
        308,
        1930,
        9746,
        1026,
        4111,
        947,
        2752,
        1658,
        8957
      ],
      "temperature": 0,
      "avg_logprob": -0.22488848876953124,
      "compression_ratio": 1.673003802281369,
      "no_speech_prob": 2.0377424903017527e-7
    },
    {
      "id": 685,
      "seek": 421366,
      "start": 4217.3,
      "end": 4222.099999999999,
      "text": " magari posso decidere vale la pena andare a pagare quel costo aggiuntivo di manutenzione",
      "tokens": [
        49932,
        22501,
        21937,
        323,
        15474,
        635,
        29222,
        42742,
        257,
        11812,
        543,
        7178,
        2063,
        78,
        42254,
        2760,
        6340,
        1026,
        587,
        7886,
        19706
      ],
      "temperature": 0,
      "avg_logprob": -0.22488848876953124,
      "compression_ratio": 1.673003802281369,
      "no_speech_prob": 2.0377424903017527e-7
    },
    {
      "id": 686,
      "seek": 421366,
      "start": 4222.099999999999,
      "end": 4227.099999999999,
      "text": " dell'infrastruttura piuttosto che andare a utilizzare un servizio managed come Upsync",
      "tokens": [
        19781,
        6,
        19920,
        4148,
        81,
        13478,
        2991,
        3895,
        13478,
        22756,
        947,
        42742,
        257,
        40355,
        543,
        517,
        1658,
        590,
        1004,
        6453,
        808,
        624,
        1878,
        34015
      ],
      "temperature": 0,
      "avg_logprob": -0.22488848876953124,
      "compression_ratio": 1.673003802281369,
      "no_speech_prob": 2.0377424903017527e-7
    },
    {
      "id": 687,
      "seek": 421366,
      "start": 4227.099999999999,
      "end": 4232.5,
      "text": " ma ripeto non conoscendo benissimo i dettagli di della tecnologia specifica quello che ho",
      "tokens": [
        463,
        12782,
        19515,
        2107,
        416,
        10466,
        3999,
        3271,
        34966,
        741,
        1141,
        25030,
        2081,
        1026,
        11618,
        44905,
        2685,
        64,
        22813,
        947,
        1106
      ],
      "temperature": 0,
      "avg_logprob": -0.22488848876953124,
      "compression_ratio": 1.673003802281369,
      "no_speech_prob": 2.0377424903017527e-7
    },
    {
      "id": 688,
      "seek": 421366,
      "start": 4232.5,
      "end": 4239.24,
      "text": " detto potrebbe avere più o meno senso. No io ritornando ad Upsync tipo ha catturato",
      "tokens": [
        41031,
        1847,
        39487,
        37914,
        10589,
        277,
        40236,
        3151,
        539,
        13,
        883,
        19785,
        11289,
        1865,
        1806,
        614,
        624,
        1878,
        34015,
        9746,
        324,
        269,
        1591,
        374,
        2513
      ],
      "temperature": 0,
      "avg_logprob": -0.22488848876953124,
      "compression_ratio": 1.673003802281369,
      "no_speech_prob": 2.0377424903017527e-7
    },
    {
      "id": 689,
      "seek": 423924,
      "start": 4239.24,
      "end": 4246.0199999999995,
      "text": " la mia attenzione perché è uno strumento che fa praticamente buona parte di quello",
      "tokens": [
        635,
        21290,
        951,
        11368,
        5328,
        14303,
        4873,
        8526,
        1056,
        2206,
        78,
        947,
        2050,
        45734,
        758,
        4037,
        6975,
        1026,
        22813
      ],
      "temperature": 0,
      "avg_logprob": -0.19167002042134604,
      "compression_ratio": 1.5669642857142858,
      "no_speech_prob": 1.9252482275078364e-8
    },
    {
      "id": 690,
      "seek": 423924,
      "start": 4246.0199999999995,
      "end": 4252.76,
      "text": " che il nostro buon amico Carmine chiamerebbe il crudino della chiesa su GraphQL nel senso",
      "tokens": [
        947,
        1930,
        35779,
        758,
        266,
        669,
        2789,
        44530,
        533,
        417,
        2918,
        323,
        39042,
        1930,
        941,
        532,
        2982,
        11618,
        417,
        530,
        64,
        459,
        21884,
        13695,
        15373,
        3151,
        539
      ],
      "temperature": 0,
      "avg_logprob": -0.19167002042134604,
      "compression_ratio": 1.5669642857142858,
      "no_speech_prob": 1.9252482275078364e-8
    },
    {
      "id": 691,
      "seek": 423924,
      "start": 4252.76,
      "end": 4259.38,
      "text": " che si interfaccia e proprio come buona parte dei prodotti AWS pensato per interfacciarsi",
      "tokens": [
        947,
        1511,
        14510,
        326,
        2755,
        308,
        28203,
        808,
        758,
        4037,
        6975,
        13874,
        15792,
        37514,
        17650,
        6099,
        2513,
        680,
        14510,
        43870,
        32742
      ],
      "temperature": 0,
      "avg_logprob": -0.19167002042134604,
      "compression_ratio": 1.5669642857142858,
      "no_speech_prob": 1.9252482275078364e-8
    },
    {
      "id": 692,
      "seek": 423924,
      "start": 4259.38,
      "end": 4265.42,
      "text": " con gli altri servizi di AWS quindi si ti può chiamare una lambda che possiamo vedere",
      "tokens": [
        416,
        17161,
        33707,
        1658,
        24300,
        1026,
        17650,
        15727,
        1511,
        8757,
        26526,
        417,
        2918,
        543,
        2002,
        13607,
        947,
        44758,
        35373
      ],
      "temperature": 0,
      "avg_logprob": -0.19167002042134604,
      "compression_ratio": 1.5669642857142858,
      "no_speech_prob": 1.9252482275078364e-8
    },
    {
      "id": 693,
      "seek": 426542,
      "start": 4265.42,
      "end": 4273.42,
      "text": " in modo un po' con la zappa come un microservizio ma ti può anche chiamare l'open search della",
      "tokens": [
        294,
        16664,
        517,
        714,
        6,
        416,
        635,
        710,
        25637,
        808,
        517,
        15547,
        1978,
        590,
        1004,
        463,
        8757,
        26526,
        11585,
        417,
        2918,
        543,
        287,
        6,
        15752,
        3164,
        11618
      ],
      "temperature": 0,
      "avg_logprob": -0.25791272884461935,
      "compression_ratio": 1.502824858757062,
      "no_speech_prob": 1.4085423494236693e-8
    },
    {
      "id": 694,
      "seek": 426542,
      "start": 4273.42,
      "end": 4281.22,
      "text": " situazione che è l'omologo di Elasticsearch as a service o puoi andare a scrivere roba",
      "tokens": [
        2054,
        12928,
        947,
        4873,
        287,
        6,
        298,
        1132,
        78,
        1026,
        2699,
        2750,
        405,
        1178,
        382,
        257,
        2643,
        277,
        2362,
        4869,
        42742,
        257,
        5545,
        5887,
        3870,
        64
      ],
      "temperature": 0,
      "avg_logprob": -0.25791272884461935,
      "compression_ratio": 1.502824858757062,
      "no_speech_prob": 1.4085423494236693e-8
    },
    {
      "id": 695,
      "seek": 426542,
      "start": 4281.22,
      "end": 4290.86,
      "text": " su Dynamo o su Aurora anche questi magari serverless e qua io dico vabbè a questo",
      "tokens": [
        459,
        22947,
        78,
        277,
        459,
        40663,
        11585,
        29729,
        49932,
        7154,
        1832,
        308,
        24159,
        19785,
        274,
        2789,
        371,
        10797,
        1462,
        257,
        10263
      ],
      "temperature": 0,
      "avg_logprob": -0.25791272884461935,
      "compression_ratio": 1.502824858757062,
      "no_speech_prob": 1.4085423494236693e-8
    },
    {
      "id": 696,
      "seek": 429086,
      "start": 4290.86,
      "end": 4298.179999999999,
      "text": " punto credimi il po' di lavoro scimmiesco di due sviluppatori te lo sei tirato via perché",
      "tokens": [
        14326,
        3864,
        10121,
        1930,
        714,
        6,
        1026,
        42060,
        795,
        6753,
        530,
        1291,
        1026,
        3462,
        17342,
        388,
        10504,
        39842,
        535,
        450,
        10842,
        13807,
        2513,
        5766,
        14303
      ],
      "temperature": 0,
      "avg_logprob": -0.22978100953278718,
      "compression_ratio": 1.6025641025641026,
      "no_speech_prob": 2.181593217187583e-8
    },
    {
      "id": 697,
      "seek": 429086,
      "start": 4298.179999999999,
      "end": 4305.0199999999995,
      "text": " anche questo dobbiamo dire quindi cioè spostando una parte di responsabilità nell'infrastruttura",
      "tokens": [
        11585,
        10263,
        360,
        6692,
        7415,
        1264,
        15727,
        41827,
        637,
        555,
        1806,
        2002,
        6975,
        1026,
        29829,
        12445,
        44666,
        6,
        19920,
        4148,
        81,
        13478,
        2991
      ],
      "temperature": 0,
      "avg_logprob": -0.22978100953278718,
      "compression_ratio": 1.6025641025641026,
      "no_speech_prob": 2.181593217187583e-8
    },
    {
      "id": 698,
      "seek": 429086,
      "start": 4305.0199999999995,
      "end": 4311.5,
      "text": " stiamo anche andando verso un approccio un pelino più no code o siccome usiamo infrastructure",
      "tokens": [
        342,
        7415,
        11585,
        293,
        1806,
        49786,
        517,
        2075,
        66,
        8529,
        517,
        6178,
        2982,
        10589,
        572,
        3089,
        277,
        33579,
        1102,
        505,
        7415,
        6896
      ],
      "temperature": 0,
      "avg_logprob": -0.22978100953278718,
      "compression_ratio": 1.6025641025641026,
      "no_speech_prob": 2.181593217187583e-8
    },
    {
      "id": 699,
      "seek": 429086,
      "start": 4311.5,
      "end": 4320.74,
      "text": " as a code potremmo dire un po' codeless no? Nel senso scrivere un terraform è sicuramente",
      "tokens": [
        382,
        257,
        3089,
        1847,
        265,
        2174,
        78,
        1264,
        517,
        714,
        6,
        17656,
        4272,
        572,
        30,
        426,
        338,
        3151,
        539,
        5545,
        5887,
        517,
        26298,
        837,
        4873,
        33579,
        374,
        3439
      ],
      "temperature": 0,
      "avg_logprob": -0.22978100953278718,
      "compression_ratio": 1.6025641025641026,
      "no_speech_prob": 2.181593217187583e-8
    },
    {
      "id": 700,
      "seek": 432074,
      "start": 4320.74,
      "end": 4327.26,
      "text": " più conciso poi insomma terraform è abbastanza verboso però scrivere un terraform è sicuramente",
      "tokens": [
        10589,
        1588,
        19227,
        19260,
        1028,
        30243,
        26298,
        837,
        4873,
        16903,
        525,
        20030,
        9595,
        9869,
        12673,
        5545,
        5887,
        517,
        26298,
        837,
        4873,
        33579,
        374,
        3439
      ],
      "temperature": 0,
      "avg_logprob": -0.2738395088597348,
      "compression_ratio": 1.6143497757847534,
      "no_speech_prob": 6.933086638127861e-8
    },
    {
      "id": 701,
      "seek": 432074,
      "start": 4327.26,
      "end": 4334.92,
      "text": " più conciso che fare il servizio GraphQL e i crude a mano nel contempo però ho ne",
      "tokens": [
        10589,
        1588,
        19227,
        947,
        11994,
        1930,
        1658,
        590,
        1004,
        21884,
        13695,
        308,
        741,
        30796,
        257,
        18384,
        15373,
        660,
        443,
        2259,
        12673,
        1106,
        408
      ],
      "temperature": 0,
      "avg_logprob": -0.2738395088597348,
      "compression_ratio": 1.6143497757847534,
      "no_speech_prob": 6.933086638127861e-8
    },
    {
      "id": 702,
      "seek": 432074,
      "start": 4334.92,
      "end": 4341.54,
      "text": " approfittato per introdurre tutto il concetto di database serverless su questi quindi Aurora",
      "tokens": [
        2075,
        69,
        593,
        2513,
        680,
        560,
        11452,
        374,
        265,
        23048,
        1930,
        1588,
        23778,
        1026,
        8149,
        7154,
        1832,
        459,
        29729,
        15727,
        40663
      ],
      "temperature": 0,
      "avg_logprob": -0.2738395088597348,
      "compression_ratio": 1.6143497757847534,
      "no_speech_prob": 6.933086638127861e-8
    },
    {
      "id": 703,
      "seek": 432074,
      "start": 4341.54,
      "end": 4349.139999999999,
      "text": " serverless Dynamo hai già anticipato che hai qualche strong opinion su Dynamo qual",
      "tokens": [
        7154,
        1832,
        22947,
        78,
        21822,
        30469,
        10416,
        2513,
        947,
        21822,
        38737,
        2068,
        4800,
        459,
        22947,
        78,
        4101
      ],
      "temperature": 0,
      "avg_logprob": -0.2738395088597348,
      "compression_ratio": 1.6143497757847534,
      "no_speech_prob": 6.933086638127861e-8
    },
    {
      "id": 704,
      "seek": 434914,
      "start": 4349.14,
      "end": 4355.34,
      "text": " è però la tua visione nel concetto generale no di data storage in termini di dati di questo",
      "tokens": [
        4873,
        12673,
        635,
        33578,
        5201,
        68,
        15373,
        1588,
        23778,
        1337,
        1220,
        572,
        1026,
        1412,
        6725,
        294,
        1433,
        3812,
        1026,
        1137,
        72,
        1026,
        10263
      ],
      "temperature": 0,
      "avg_logprob": -0.23632850646972656,
      "compression_ratio": 1.6017316017316017,
      "no_speech_prob": 5.515932599564621e-9
    },
    {
      "id": 705,
      "seek": 434914,
      "start": 4355.34,
      "end": 4363.860000000001,
      "text": " tipo? Sì diciamo la mia strong opinion rispetto a Dynamo è il fatto che viene un po' venduto",
      "tokens": [
        9746,
        30,
        318,
        4749,
        14285,
        7415,
        635,
        21290,
        2068,
        4800,
        2253,
        42801,
        257,
        22947,
        78,
        4873,
        1930,
        23228,
        947,
        19561,
        517,
        714,
        6,
        10169,
        8262
      ],
      "temperature": 0,
      "avg_logprob": -0.23632850646972656,
      "compression_ratio": 1.6017316017316017,
      "no_speech_prob": 5.515932599564621e-9
    },
    {
      "id": 706,
      "seek": 434914,
      "start": 4363.860000000001,
      "end": 4369.54,
      "text": " come database general purpose quando secondo me lo è relativamente nel senso che è un",
      "tokens": [
        808,
        8149,
        2674,
        4334,
        7770,
        41601,
        385,
        450,
        4873,
        21960,
        3439,
        15373,
        3151,
        539,
        947,
        4873,
        517
      ],
      "temperature": 0,
      "avg_logprob": -0.23632850646972656,
      "compression_ratio": 1.6017316017316017,
      "no_speech_prob": 5.515932599564621e-9
    },
    {
      "id": 707,
      "seek": 434914,
      "start": 4369.54,
      "end": 4376.3,
      "text": " ottimo database quando già sai esattamente tutti gli access pattern ai dati e di conseguenza",
      "tokens": [
        42772,
        6934,
        8149,
        7770,
        30469,
        32417,
        785,
        1591,
        3439,
        19822,
        17161,
        2105,
        5102,
        9783,
        1137,
        72,
        308,
        1026,
        12706,
        23691
      ],
      "temperature": 0,
      "avg_logprob": -0.23632850646972656,
      "compression_ratio": 1.6017316017316017,
      "no_speech_prob": 5.515932599564621e-9
    },
    {
      "id": 708,
      "seek": 437630,
      "start": 4376.3,
      "end": 4380.9800000000005,
      "text": " in quel caso puoi andare a ottimizzare proprio la struttura del database per quegli access",
      "tokens": [
        294,
        7178,
        9666,
        2362,
        4869,
        42742,
        257,
        4337,
        31208,
        8072,
        543,
        28203,
        635,
        1056,
        13478,
        2991,
        1103,
        8149,
        680,
        631,
        41443,
        2105
      ],
      "temperature": 0,
      "avg_logprob": -0.1882912963628769,
      "compression_ratio": 1.68,
      "no_speech_prob": 1.09697362304928e-8
    },
    {
      "id": 709,
      "seek": 437630,
      "start": 4380.9800000000005,
      "end": 4386.06,
      "text": " pattern e c'hai tutta una serie di vantaggi cioè sicuramente un database molto efficiente",
      "tokens": [
        5102,
        308,
        269,
        6,
        18230,
        3672,
        1328,
        2002,
        23030,
        1026,
        371,
        394,
        46893,
        41827,
        33579,
        374,
        3439,
        517,
        8149,
        16394,
        7148,
        68
      ],
      "temperature": 0,
      "avg_logprob": -0.1882912963628769,
      "compression_ratio": 1.68,
      "no_speech_prob": 1.09697362304928e-8
    },
    {
      "id": 710,
      "seek": 437630,
      "start": 4386.06,
      "end": 4391.9400000000005,
      "text": " già distribuito il livello di manutenzione minimo però non è un database molto dinamico",
      "tokens": [
        30469,
        4400,
        22703,
        1930,
        1621,
        1913,
        1026,
        587,
        7886,
        19706,
        4464,
        78,
        12673,
        2107,
        4873,
        517,
        8149,
        16394,
        3791,
        335,
        2789
      ],
      "temperature": 0,
      "avg_logprob": -0.1882912963628769,
      "compression_ratio": 1.68,
      "no_speech_prob": 1.09697362304928e-8
    },
    {
      "id": 711,
      "seek": 437630,
      "start": 4391.9400000000005,
      "end": 4397.38,
      "text": " nel senso che se l'indomani a livello di business ti rendi conto che hai sbagliato qualcosa o",
      "tokens": [
        15373,
        3151,
        539,
        947,
        369,
        287,
        6,
        471,
        298,
        3782,
        257,
        1621,
        1913,
        1026,
        1606,
        8757,
        6125,
        72,
        660,
        78,
        947,
        21822,
        262,
        17282,
        2081,
        2513,
        42400,
        277
      ],
      "temperature": 0,
      "avg_logprob": -0.1882912963628769,
      "compression_ratio": 1.68,
      "no_speech_prob": 1.09697362304928e-8
    },
    {
      "id": 712,
      "seek": 437630,
      "start": 4397.38,
      "end": 4402.9400000000005,
      "text": " ti serve un campo in più o devi modificare un workflow buon divertimento a fare una migrazione",
      "tokens": [
        8757,
        4596,
        517,
        29691,
        294,
        10589,
        277,
        31219,
        1072,
        1089,
        543,
        517,
        20993,
        758,
        266,
        23781,
        10030,
        257,
        11994,
        2002,
        6186,
        424,
        19706
      ],
      "temperature": 0,
      "avg_logprob": -0.1882912963628769,
      "compression_ratio": 1.68,
      "no_speech_prob": 1.09697362304928e-8
    },
    {
      "id": 713,
      "seek": 440294,
      "start": 4402.94,
      "end": 4406.58,
      "text": " dei dati perché non esiste neanche il concetto di migrazione dei dati cioè ti devi andare",
      "tokens": [
        13874,
        1137,
        72,
        14303,
        2107,
        785,
        8375,
        408,
        22806,
        1930,
        1588,
        23778,
        1026,
        6186,
        424,
        19706,
        13874,
        1137,
        72,
        41827,
        8757,
        31219,
        42742
      ],
      "temperature": 0,
      "avg_logprob": -0.21676044590425808,
      "compression_ratio": 1.7442622950819673,
      "no_speech_prob": 2.7577835126635364e-8
    },
    {
      "id": 714,
      "seek": 440294,
      "start": 4406.58,
      "end": 4412.66,
      "text": " a fare tutto tu da solo e mi è capitato di dover fare questa cosa DynamoDB e la complessità",
      "tokens": [
        257,
        11994,
        23048,
        2604,
        1120,
        6944,
        308,
        2752,
        4873,
        33807,
        2513,
        1026,
        360,
        331,
        11994,
        16540,
        10163,
        22947,
        78,
        27735,
        308,
        635,
        1209,
        442,
        12445
      ],
      "temperature": 0,
      "avg_logprob": -0.21676044590425808,
      "compression_ratio": 1.7442622950819673,
      "no_speech_prob": 2.7577835126635364e-8
    },
    {
      "id": 715,
      "seek": 440294,
      "start": 4412.66,
      "end": 4417.099999999999,
      "text": " è assurda cioè quello che tu faresti con un sequel che dici alter table aggiungi un",
      "tokens": [
        4873,
        1256,
        374,
        2675,
        41827,
        22813,
        947,
        2604,
        11994,
        39505,
        416,
        517,
        20622,
        947,
        274,
        8787,
        11337,
        3199,
        42254,
        1063,
        72,
        517
      ],
      "temperature": 0,
      "avg_logprob": -0.21676044590425808,
      "compression_ratio": 1.7442622950819673,
      "no_speech_prob": 2.7577835126635364e-8
    },
    {
      "id": 716,
      "seek": 440294,
      "start": 4417.099999999999,
      "end": 4422.139999999999,
      "text": " nuovo campo e questo campo deve avere il valore del campo precedente moltiplicato per due",
      "tokens": [
        49348,
        29691,
        308,
        10263,
        29691,
        17761,
        37914,
        1930,
        1323,
        418,
        1103,
        29691,
        16969,
        1576,
        10739,
        72,
        4770,
        2513,
        680,
        3462
      ],
      "temperature": 0,
      "avg_logprob": -0.21676044590425808,
      "compression_ratio": 1.7442622950819673,
      "no_speech_prob": 2.7577835126635364e-8
    },
    {
      "id": 717,
      "seek": 440294,
      "start": 4422.139999999999,
      "end": 4426.099999999999,
      "text": " che è una query che ci metti due secondi a scriverla a farla in DynamoDB ci perdi",
      "tokens": [
        947,
        4873,
        2002,
        14581,
        947,
        6983,
        1131,
        7317,
        3462,
        1150,
        72,
        257,
        5545,
        331,
        875,
        257,
        1400,
        875,
        294,
        22947,
        78,
        27735,
        6983,
        680,
        4504
      ],
      "temperature": 0,
      "avg_logprob": -0.21676044590425808,
      "compression_ratio": 1.7442622950819673,
      "no_speech_prob": 2.7577835126635364e-8
    },
    {
      "id": 718,
      "seek": 440294,
      "start": 4426.099999999999,
      "end": 4430.86,
      "text": " le settimane solo a capire come orchestrare un workflow che ti fa lo scan di tutto e ti",
      "tokens": [
        476,
        5584,
        332,
        1929,
        6944,
        257,
        1410,
        621,
        808,
        14161,
        35559,
        517,
        20993,
        947,
        8757,
        2050,
        450,
        11049,
        1026,
        23048,
        308,
        8757
      ],
      "temperature": 0,
      "avg_logprob": -0.21676044590425808,
      "compression_ratio": 1.7442622950819673,
      "no_speech_prob": 2.7577835126635364e-8
    },
    {
      "id": 719,
      "seek": 443086,
      "start": 4430.86,
      "end": 4436.46,
      "text": " aggiorna tutti tutti i record quindi cioè vanno vanno tenute in considerazione queste",
      "tokens": [
        42254,
        1865,
        64,
        19822,
        19822,
        741,
        2136,
        15727,
        41827,
        371,
        13484,
        371,
        13484,
        2064,
        1169,
        294,
        1949,
        12928,
        35455
      ],
      "temperature": 0,
      "avg_logprob": -0.2677553952750513,
      "compression_ratio": 1.6599190283400809,
      "no_speech_prob": 3.950354354742558e-8
    },
    {
      "id": 720,
      "seek": 443086,
      "start": 4436.46,
      "end": 4440.94,
      "text": " cose secondo me a livello di marketing non viene venduto DynamoDB con questo tipo di",
      "tokens": [
        30261,
        41601,
        385,
        257,
        1621,
        1913,
        1026,
        6370,
        2107,
        19561,
        10169,
        8262,
        22947,
        78,
        27735,
        416,
        10263,
        9746,
        1026
      ],
      "temperature": 0,
      "avg_logprob": -0.2677553952750513,
      "compression_ratio": 1.6599190283400809,
      "no_speech_prob": 3.950354354742558e-8
    },
    {
      "id": 721,
      "seek": 443086,
      "start": 4440.94,
      "end": 4445.62,
      "text": " prospettiva ma viene venduto come vabbè se fai serverless usi DynamoDB di default e",
      "tokens": [
        582,
        2763,
        3093,
        5931,
        463,
        19561,
        10169,
        8262,
        808,
        371,
        10797,
        1462,
        369,
        283,
        1301,
        7154,
        1832,
        505,
        72,
        22947,
        78,
        27735,
        1026,
        7576,
        308
      ],
      "temperature": 0,
      "avg_logprob": -0.2677553952750513,
      "compression_ratio": 1.6599190283400809,
      "no_speech_prob": 3.950354354742558e-8
    },
    {
      "id": 722,
      "seek": 443086,
      "start": 4445.62,
      "end": 4448.78,
      "text": " puoi fare tutto addirittura che non è necessariamente vero.",
      "tokens": [
        2362,
        4869,
        11994,
        23048,
        909,
        347,
        593,
        2991,
        947,
        2107,
        4873,
        2688,
        45149,
        1306,
        78,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2677553952750513,
      "compression_ratio": 1.6599190283400809,
      "no_speech_prob": 3.950354354742558e-8
    },
    {
      "id": 723,
      "seek": 443086,
      "start": 4448.78,
      "end": 4455.66,
      "text": " Mi ricordi io ho lavorato poco con DynamoDB ma mentre mi documentavo avevo letto che c'erano",
      "tokens": [
        10204,
        21040,
        765,
        72,
        19785,
        1106,
        29241,
        2513,
        10639,
        416,
        22947,
        78,
        27735,
        463,
        49601,
        2752,
        4166,
        25713,
        3472,
        3080,
        718,
        1353,
        947,
        269,
        6,
        260,
        3730
      ],
      "temperature": 0,
      "avg_logprob": -0.2677553952750513,
      "compression_ratio": 1.6599190283400809,
      "no_speech_prob": 3.950354354742558e-8
    },
    {
      "id": 724,
      "seek": 445566,
      "start": 4455.66,
      "end": 4461.099999999999,
      "text": " anche dei pattern di single table cioè te metti tutte le date nella singola tabella",
      "tokens": [
        11585,
        13874,
        5102,
        1026,
        2167,
        3199,
        41827,
        535,
        1131,
        7317,
        38632,
        476,
        1137,
        68,
        23878,
        1522,
        4711,
        4421,
        9885
      ],
      "temperature": 0,
      "avg_logprob": -0.32043298860875574,
      "compression_ratio": 1.7642276422764227,
      "no_speech_prob": 8.543241669656254e-9
    },
    {
      "id": 725,
      "seek": 445566,
      "start": 4461.099999999999,
      "end": 4466.7,
      "text": " e poi lavori solo sui filtri sui dati che ci sono che per uno che viene da un database",
      "tokens": [
        308,
        19260,
        20923,
        7386,
        6944,
        459,
        72,
        29148,
        470,
        459,
        72,
        1137,
        72,
        947,
        6983,
        9259,
        947,
        680,
        8526,
        947,
        19561,
        1120,
        517,
        8149
      ],
      "temperature": 0,
      "avg_logprob": -0.32043298860875574,
      "compression_ratio": 1.7642276422764227,
      "no_speech_prob": 8.543241669656254e-9
    },
    {
      "id": 726,
      "seek": 445566,
      "start": 4466.7,
      "end": 4470.9,
      "text": " anche documentale ma se no è skew head dice va bene gli utenti li mettono nella tabella",
      "tokens": [
        11585,
        4166,
        1220,
        463,
        369,
        572,
        4873,
        8756,
        86,
        1378,
        10313,
        2773,
        2537,
        17161,
        2839,
        23012,
        375,
        1131,
        1756,
        78,
        23878,
        4421,
        9885
      ],
      "temperature": 0,
      "avg_logprob": -0.32043298860875574,
      "compression_ratio": 1.7642276422764227,
      "no_speech_prob": 8.543241669656254e-9
    },
    {
      "id": 727,
      "seek": 445566,
      "start": 4470.9,
      "end": 4474.7,
      "text": " utenti i prodotti nella tabella prodotti invece lì metti tutto insieme e fai dei filtri",
      "tokens": [
        2839,
        23012,
        741,
        15792,
        37514,
        23878,
        4421,
        9885,
        15792,
        37514,
        36344,
        287,
        4749,
        1131,
        7317,
        23048,
        1028,
        44940,
        308,
        283,
        1301,
        13874,
        29148,
        470
      ],
      "temperature": 0,
      "avg_logprob": -0.32043298860875574,
      "compression_ratio": 1.7642276422764227,
      "no_speech_prob": 8.543241669656254e-9
    },
    {
      "id": 728,
      "seek": 445566,
      "start": 4474.7,
      "end": 4481.0599999999995,
      "text": " per tirare fuori dallo stesso bucket questa cosa che è un po' difficile da intuire.",
      "tokens": [
        680,
        13807,
        543,
        8536,
        7386,
        274,
        37104,
        44413,
        13058,
        16540,
        10163,
        947,
        4873,
        517,
        714,
        6,
        26607,
        1120,
        560,
        43612,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.32043298860875574,
      "compression_ratio": 1.7642276422764227,
      "no_speech_prob": 8.543241669656254e-9
    },
    {
      "id": 729,
      "seek": 448106,
      "start": 4481.06,
      "end": 4488.34,
      "text": " Non concordo assolutamente c'è un libro intero di Alex Debrie che tra l'altro consiglio perché",
      "tokens": [
        8774,
        1588,
        23872,
        1256,
        2308,
        3439,
        269,
        6,
        1462,
        517,
        29354,
        728,
        78,
        1026,
        5202,
        1346,
        1443,
        414,
        947,
        944,
        287,
        6,
        47484,
        40233,
        19987,
        14303
      ],
      "temperature": 0,
      "avg_logprob": -0.2340263335172795,
      "compression_ratio": 1.6853932584269662,
      "no_speech_prob": 2.309069913053463e-7
    },
    {
      "id": 730,
      "seek": 448106,
      "start": 4488.34,
      "end": 4492.620000000001,
      "text": " è un ottimo libro solo per capire come applicare questo tipo di mentalità quindi non è una",
      "tokens": [
        4873,
        517,
        42772,
        6934,
        29354,
        6944,
        680,
        1410,
        621,
        808,
        2580,
        543,
        10263,
        9746,
        1026,
        4973,
        12445,
        15727,
        2107,
        4873,
        2002
      ],
      "temperature": 0,
      "avg_logprob": -0.2340263335172795,
      "compression_ratio": 1.6853932584269662,
      "no_speech_prob": 2.309069913053463e-7
    },
    {
      "id": 731,
      "seek": 448106,
      "start": 4492.620000000001,
      "end": 4497.1,
      "text": " cosa così ovvia cioè non è una cosa che di default ti viene da andare a impostare",
      "tokens": [
        10163,
        23278,
        14187,
        11617,
        41827,
        2107,
        4873,
        2002,
        10163,
        947,
        1026,
        7576,
        8757,
        19561,
        1120,
        42742,
        257,
        47804,
        543
      ],
      "temperature": 0,
      "avg_logprob": -0.2340263335172795,
      "compression_ratio": 1.6853932584269662,
      "no_speech_prob": 2.309069913053463e-7
    },
    {
      "id": 732,
      "seek": 448106,
      "start": 4497.1,
      "end": 4502.780000000001,
      "text": " un database in questo modo e questo tipo di approccio a mia opinione ma forse mi riservo",
      "tokens": [
        517,
        8149,
        294,
        10263,
        16664,
        308,
        10263,
        9746,
        1026,
        2075,
        66,
        8529,
        257,
        21290,
        4800,
        68,
        463,
        337,
        405,
        2752,
        2253,
        1978,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.2340263335172795,
      "compression_ratio": 1.6853932584269662,
      "no_speech_prob": 2.309069913053463e-7
    },
    {
      "id": 733,
      "seek": 448106,
      "start": 4502.780000000001,
      "end": 4507.740000000001,
      "text": " pure il fatto di non aver capito al 100% quello che Alex voleva comunicare con questo",
      "tokens": [
        6075,
        1930,
        23228,
        1026,
        2107,
        18247,
        1410,
        3528,
        419,
        2319,
        4,
        22813,
        947,
        5202,
        49877,
        2757,
        31710,
        543,
        416,
        10263
      ],
      "temperature": 0,
      "avg_logprob": -0.2340263335172795,
      "compression_ratio": 1.6853932584269662,
      "no_speech_prob": 2.309069913053463e-7
    },
    {
      "id": 734,
      "seek": 450774,
      "start": 4507.74,
      "end": 4513.42,
      "text": " suo libro sì magari ti dà un po' di libertà in più nel data modeling di evolvere quel",
      "tokens": [
        34197,
        29354,
        49267,
        49932,
        8757,
        274,
        1467,
        517,
        714,
        6,
        1026,
        18058,
        1467,
        294,
        10589,
        15373,
        1412,
        15983,
        1026,
        7117,
        5887,
        7178
      ],
      "temperature": 0,
      "avg_logprob": -0.2588262015241918,
      "compression_ratio": 1.6702898550724639,
      "no_speech_prob": 1.161072873401281e-7
    },
    {
      "id": 735,
      "seek": 450774,
      "start": 4513.42,
      "end": 4518,
      "text": " data modeling man mano che scopri dei nuovi requisiti o deve implementare le nuove funzionalità",
      "tokens": [
        1412,
        15983,
        587,
        18384,
        947,
        795,
        404,
        470,
        13874,
        37802,
        4917,
        49878,
        8707,
        277,
        17761,
        566,
        43704,
        543,
        476,
        3822,
        1682,
        49345,
        1966,
        12445
      ],
      "temperature": 0,
      "avg_logprob": -0.2588262015241918,
      "compression_ratio": 1.6702898550724639,
      "no_speech_prob": 1.161072873401281e-7
    },
    {
      "id": 736,
      "seek": 450774,
      "start": 4518,
      "end": 4522.46,
      "text": " ma comunque secondo me parte da un presupposto in cui hai già molto più chiaro di quello",
      "tokens": [
        463,
        45736,
        41601,
        385,
        6975,
        1120,
        517,
        1183,
        10504,
        22756,
        294,
        22929,
        21822,
        30469,
        16394,
        10589,
        47454,
        78,
        1026,
        22813
      ],
      "temperature": 0,
      "avg_logprob": -0.2588262015241918,
      "compression_ratio": 1.6702898550724639,
      "no_speech_prob": 1.161072873401281e-7
    },
    {
      "id": 737,
      "seek": 450774,
      "start": 4522.46,
      "end": 4530.9,
      "text": " che avresti magari con un approccio SQL tradizionale quali sono gli access pattern rispetto a",
      "tokens": [
        947,
        1305,
        4149,
        72,
        49932,
        416,
        517,
        2075,
        66,
        8529,
        19200,
        2479,
        590,
        313,
        1220,
        4101,
        72,
        9259,
        17161,
        2105,
        5102,
        2253,
        42801,
        257
      ],
      "temperature": 0,
      "avg_logprob": -0.2588262015241918,
      "compression_ratio": 1.6702898550724639,
      "no_speech_prob": 1.161072873401281e-7
    },
    {
      "id": 738,
      "seek": 450774,
      "start": 4530.9,
      "end": 4535.34,
      "text": " appunto confrontando il modello SQL col modello no SQL secondo me la differenza chiave è",
      "tokens": [
        724,
        24052,
        12422,
        1806,
        1930,
        1072,
        11216,
        19200,
        1173,
        1072,
        11216,
        572,
        19200,
        41601,
        385,
        635,
        743,
        23691,
        45793,
        303,
        4873
      ],
      "temperature": 0,
      "avg_logprob": -0.2588262015241918,
      "compression_ratio": 1.6702898550724639,
      "no_speech_prob": 1.161072873401281e-7
    },
    {
      "id": 739,
      "seek": 453534,
      "start": 4535.34,
      "end": 4541.1,
      "text": " proprio quella che il modello SQL è pensato per dire tu mi dici quali sono i dati io mi",
      "tokens": [
        28203,
        32234,
        947,
        1930,
        1072,
        11216,
        19200,
        4873,
        6099,
        2513,
        680,
        1264,
        2604,
        2752,
        274,
        8787,
        4101,
        72,
        9259,
        741,
        1137,
        72,
        19785,
        2752
      ],
      "temperature": 0,
      "avg_logprob": -0.17933606737442598,
      "compression_ratio": 1.772549019607843,
      "no_speech_prob": 5.964141180925253e-9
    },
    {
      "id": 740,
      "seek": 453534,
      "start": 4541.1,
      "end": 4546.06,
      "text": " vedo tutto il resto e se vuoi cambiare le cose hai tutti gli strumenti per farlo e ti",
      "tokens": [
        14267,
        78,
        23048,
        1930,
        28247,
        308,
        369,
        9732,
        4869,
        19569,
        543,
        476,
        30261,
        21822,
        19822,
        17161,
        1056,
        2206,
        72,
        680,
        1400,
        752,
        308,
        8757
      ],
      "temperature": 0,
      "avg_logprob": -0.17933606737442598,
      "compression_ratio": 1.772549019607843,
      "no_speech_prob": 5.964141180925253e-9
    },
    {
      "id": 741,
      "seek": 453534,
      "start": 4546.06,
      "end": 4551.9800000000005,
      "text": " cerco di diminuire al massimo la duplicazione dei dati il modello no SQL è proprio diametralmente",
      "tokens": [
        10146,
        1291,
        1026,
        15739,
        43612,
        419,
        2758,
        6934,
        635,
        17154,
        12928,
        13874,
        1137,
        72,
        1930,
        1072,
        11216,
        572,
        19200,
        4873,
        28203,
        7484,
        302,
        2155,
        4082
      ],
      "temperature": 0,
      "avg_logprob": -0.17933606737442598,
      "compression_ratio": 1.772549019607843,
      "no_speech_prob": 5.964141180925253e-9
    },
    {
      "id": 742,
      "seek": 453534,
      "start": 4551.9800000000005,
      "end": 4556.9800000000005,
      "text": " opposto cioè io ti ottimizzo per degli access pattern specifici se ne vuoi altri duplica",
      "tokens": [
        1458,
        22756,
        41827,
        19785,
        8757,
        4337,
        31208,
        590,
        4765,
        680,
        32079,
        2105,
        5102,
        2685,
        72,
        369,
        408,
        9732,
        4869,
        33707,
        1581,
        564,
        2262
      ],
      "temperature": 0,
      "avg_logprob": -0.17933606737442598,
      "compression_ratio": 1.772549019607843,
      "no_speech_prob": 5.964141180925253e-9
    },
    {
      "id": 743,
      "seek": 453534,
      "start": 4556.9800000000005,
      "end": 4563.58,
      "text": " i dati e quelli sono ottimizzati pure e questa non è una cosa che viene comunicata bene",
      "tokens": [
        741,
        1137,
        72,
        308,
        631,
        16320,
        9259,
        4337,
        31208,
        8072,
        6908,
        6075,
        308,
        16540,
        2107,
        4873,
        2002,
        10163,
        947,
        19561,
        31710,
        3274,
        2537
      ],
      "temperature": 0,
      "avg_logprob": -0.17933606737442598,
      "compression_ratio": 1.772549019607843,
      "no_speech_prob": 5.964141180925253e-9
    },
    {
      "id": 744,
      "seek": 456358,
      "start": 4563.58,
      "end": 4569.0599999999995,
      "text": " a livello di marketing cioè viene più che altro detto se fai serverless devi usare DynamoDB",
      "tokens": [
        257,
        1621,
        1913,
        1026,
        6370,
        41827,
        19561,
        10589,
        947,
        40924,
        41031,
        369,
        283,
        1301,
        7154,
        1832,
        31219,
        505,
        543,
        22947,
        78,
        27735
      ],
      "temperature": 0,
      "avg_logprob": -0.22232127884059277,
      "compression_ratio": 1.512396694214876,
      "no_speech_prob": 2.3960110340226493e-8
    },
    {
      "id": 745,
      "seek": 456358,
      "start": 4569.0599999999995,
      "end": 4575.0599999999995,
      "text": " se fai applicazioni tradizionali che girano su virtual machine puoi usare SQL quando secondo",
      "tokens": [
        369,
        283,
        1301,
        2580,
        27569,
        2479,
        590,
        1966,
        72,
        947,
        14703,
        3730,
        459,
        6374,
        3479,
        2362,
        4869,
        505,
        543,
        19200,
        7770,
        41601
      ],
      "temperature": 0,
      "avg_logprob": -0.22232127884059277,
      "compression_ratio": 1.512396694214876,
      "no_speech_prob": 2.3960110340226493e-8
    },
    {
      "id": 746,
      "seek": 456358,
      "start": 4575.0599999999995,
      "end": 4581.18,
      "text": " me questa cosa non è cioè l'uno non escude necessariamente l'altro. Eppure sembra strano",
      "tokens": [
        385,
        16540,
        10163,
        2107,
        4873,
        41827,
        287,
        6,
        12638,
        2107,
        4721,
        2303,
        2688,
        45149,
        287,
        6,
        47484,
        13,
        462,
        427,
        540,
        20775,
        424,
        1056,
        3730
      ],
      "temperature": 0,
      "avg_logprob": -0.22232127884059277,
      "compression_ratio": 1.512396694214876,
      "no_speech_prob": 2.3960110340226493e-8
    },
    {
      "id": 747,
      "seek": 456358,
      "start": 4581.18,
      "end": 4587.9,
      "text": " sai perché quello che dici non fa non fa una piega sono tipo d'accordo al 200 per cento",
      "tokens": [
        32417,
        14303,
        22813,
        947,
        274,
        8787,
        2107,
        2050,
        2107,
        2050,
        2002,
        1730,
        3680,
        9259,
        9746,
        274,
        6,
        19947,
        78,
        419,
        2331,
        680,
        1489,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.22232127884059277,
      "compression_ratio": 1.512396694214876,
      "no_speech_prob": 2.3960110340226493e-8
    },
    {
      "id": 748,
      "seek": 458790,
      "start": 4587.9,
      "end": 4595.179999999999,
      "text": " però nella zona B del mio cervello mi è ritornato in mente un mantra che era il mantra ed è",
      "tokens": [
        12673,
        23878,
        24848,
        363,
        1103,
        29908,
        33792,
        1913,
        2752,
        4873,
        11289,
        1865,
        2513,
        294,
        26577,
        517,
        32094,
        947,
        4249,
        1930,
        32094,
        1257,
        4873
      ],
      "temperature": 0,
      "avg_logprob": -0.2875660818976325,
      "compression_ratio": 1.5254237288135593,
      "no_speech_prob": 3.2749547074217844e-8
    },
    {
      "id": 749,
      "seek": 458790,
      "start": 4595.179999999999,
      "end": 4603.259999999999,
      "text": " il mantra di tutto il movimento no SQL no? Cioè tutto ciò che riguarda SQL possiamo",
      "tokens": [
        1930,
        32094,
        1026,
        23048,
        1930,
        40798,
        572,
        19200,
        572,
        30,
        383,
        35983,
        23048,
        6983,
        4293,
        947,
        8329,
        16981,
        64,
        19200,
        44758
      ],
      "temperature": 0,
      "avg_logprob": -0.2875660818976325,
      "compression_ratio": 1.5254237288135593,
      "no_speech_prob": 3.2749547074217844e-8
    },
    {
      "id": 750,
      "seek": 458790,
      "start": 4603.259999999999,
      "end": 4613.179999999999,
      "text": " vederlo con SQL e no SQL sono delle parole di marketing noi potremmo dire schema on write",
      "tokens": [
        371,
        10020,
        752,
        416,
        19200,
        308,
        572,
        19200,
        9259,
        16485,
        26783,
        1026,
        6370,
        22447,
        1847,
        265,
        2174,
        78,
        1264,
        34078,
        322,
        2464
      ],
      "temperature": 0,
      "avg_logprob": -0.2875660818976325,
      "compression_ratio": 1.5254237288135593,
      "no_speech_prob": 3.2749547074217844e-8
    },
    {
      "id": 751,
      "seek": 461318,
      "start": 4613.18,
      "end": 4620.34,
      "text": " per tutto il mondo di SQL e schema on read per tutto il mondo no SQL che però è una",
      "tokens": [
        680,
        23048,
        1930,
        40499,
        1026,
        19200,
        308,
        34078,
        322,
        1401,
        680,
        23048,
        1930,
        40499,
        572,
        19200,
        947,
        12673,
        4873,
        2002
      ],
      "temperature": 0,
      "avg_logprob": -0.25316910696501777,
      "compression_ratio": 1.7259615384615385,
      "no_speech_prob": 1.6990258089322197e-8
    },
    {
      "id": 752,
      "seek": 461318,
      "start": 4620.34,
      "end": 4625.14,
      "text": " cosa che fa conflige in qualche modo con quello che hai appena detto e sul quale sono d'accordo",
      "tokens": [
        10163,
        947,
        2050,
        1497,
        75,
        3969,
        294,
        38737,
        16664,
        416,
        22813,
        947,
        21822,
        724,
        4118,
        41031,
        308,
        459,
        75,
        421,
        1220,
        9259,
        274,
        6,
        19947,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.25316910696501777,
      "compression_ratio": 1.7259615384615385,
      "no_speech_prob": 1.6990258089322197e-8
    },
    {
      "id": 753,
      "seek": 461318,
      "start": 4625.14,
      "end": 4634.46,
      "text": " tra l'altro cioè se io voglio accedere ai dati in modo in modo in modo anche efficiente",
      "tokens": [
        944,
        287,
        6,
        47484,
        41827,
        369,
        19785,
        31273,
        19987,
        696,
        1232,
        323,
        9783,
        1137,
        72,
        294,
        16664,
        294,
        16664,
        294,
        16664,
        11585,
        7148,
        68
      ],
      "temperature": 0,
      "avg_logprob": -0.25316910696501777,
      "compression_ratio": 1.7259615384615385,
      "no_speech_prob": 1.6990258089322197e-8
    },
    {
      "id": 754,
      "seek": 461318,
      "start": 4634.46,
      "end": 4640.58,
      "text": " non deve aver già pensato al motivo per cui voglio accedere questa cosa nella mia testa",
      "tokens": [
        2107,
        17761,
        18247,
        30469,
        6099,
        2513,
        419,
        35804,
        680,
        22929,
        31273,
        19987,
        696,
        1232,
        323,
        16540,
        10163,
        23878,
        21290,
        1500,
        64
      ],
      "temperature": 0,
      "avg_logprob": -0.25316910696501777,
      "compression_ratio": 1.7259615384615385,
      "no_speech_prob": 1.6990258089322197e-8
    },
    {
      "id": 755,
      "seek": 464058,
      "start": 4640.58,
      "end": 4647.0599999999995,
      "text": " sta prendendo a schiaffi col concetto di schema on read perché in realtà nella definizione",
      "tokens": [
        11135,
        9866,
        3999,
        257,
        956,
        654,
        602,
        72,
        1173,
        1588,
        23778,
        1026,
        34078,
        322,
        1401,
        14303,
        294,
        47512,
        23878,
        1561,
        35740
      ],
      "temperature": 0,
      "avg_logprob": -0.21403818791455562,
      "compression_ratio": 1.6930232558139535,
      "no_speech_prob": 5.871678254720791e-9
    },
    {
      "id": 756,
      "seek": 464058,
      "start": 4647.0599999999995,
      "end": 4654.0599999999995,
      "text": " implicita no di schema on read sto dicendo esattamente il contrario cioè definisco lo",
      "tokens": [
        10629,
        2786,
        572,
        1026,
        34078,
        322,
        1401,
        22784,
        14285,
        3999,
        785,
        1591,
        3439,
        1930,
        47642,
        41827,
        1561,
        8610,
        450
      ],
      "temperature": 0,
      "avg_logprob": -0.21403818791455562,
      "compression_ratio": 1.6930232558139535,
      "no_speech_prob": 5.871678254720791e-9
    },
    {
      "id": 757,
      "seek": 464058,
      "start": 4654.0599999999995,
      "end": 4659.7,
      "text": " schema dei dati quando vado a leggerli adesso io non chiedo a nessuno di dare una risposta",
      "tokens": [
        34078,
        13874,
        1137,
        72,
        7770,
        371,
        1573,
        257,
        1676,
        1321,
        2081,
        39552,
        19785,
        2107,
        417,
        36035,
        257,
        39787,
        12638,
        1026,
        8955,
        2002,
        2253,
        79,
        8638
      ],
      "temperature": 0,
      "avg_logprob": -0.21403818791455562,
      "compression_ratio": 1.6930232558139535,
      "no_speech_prob": 5.871678254720791e-9
    },
    {
      "id": 758,
      "seek": 464058,
      "start": 4659.7,
      "end": 4667.1,
      "text": " a questa piccola pazzia però ecco vi chiedo e chiedo anche a tutti gli ascoltati di fermarsi",
      "tokens": [
        257,
        16540,
        13363,
        66,
        4711,
        30032,
        40395,
        12673,
        11437,
        1291,
        1932,
        417,
        36035,
        308,
        417,
        36035,
        11585,
        257,
        19822,
        17161,
        15526,
        4837,
        6908,
        1026,
        26558,
        32742
      ],
      "temperature": 0,
      "avg_logprob": -0.21403818791455562,
      "compression_ratio": 1.6930232558139535,
      "no_speech_prob": 5.871678254720791e-9
    },
    {
      "id": 759,
      "seek": 466710,
      "start": 4667.1,
      "end": 4672.860000000001,
      "text": " un attimo a riflettere su questa contraddizione perché probabilmente c'è una contraddizione",
      "tokens": [
        517,
        951,
        6934,
        257,
        13203,
        32547,
        323,
        459,
        16540,
        15858,
        67,
        35740,
        14303,
        31959,
        4082,
        269,
        6,
        1462,
        2002,
        15858,
        67,
        35740
      ],
      "temperature": 0,
      "avg_logprob": -0.2539573106609407,
      "compression_ratio": 1.693798449612403,
      "no_speech_prob": 4.035542122693414e-9
    },
    {
      "id": 760,
      "seek": 466710,
      "start": 4672.860000000001,
      "end": 4676.700000000001,
      "text": " anche nel modo nel quale noi vediamo queste tecnologie no?",
      "tokens": [
        11585,
        15373,
        16664,
        15373,
        421,
        1220,
        22447,
        14267,
        7415,
        35455,
        20105,
        20121,
        572,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.2539573106609407,
      "compression_ratio": 1.693798449612403,
      "no_speech_prob": 4.035542122693414e-9
    },
    {
      "id": 761,
      "seek": 466710,
      "start": 4676.700000000001,
      "end": 4678.18,
      "text": " Cosa ne dite?",
      "tokens": [
        383,
        6447,
        408,
        274,
        642,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.2539573106609407,
      "compression_ratio": 1.693798449612403,
      "no_speech_prob": 4.035542122693414e-9
    },
    {
      "id": 762,
      "seek": 466710,
      "start": 4678.18,
      "end": 4682.9400000000005,
      "text": " Secondo me c'è pure un'altra dimensione da esplorare che forse viene sempre un po'",
      "tokens": [
        5736,
        78,
        385,
        269,
        6,
        1462,
        6075,
        517,
        6,
        38865,
        10139,
        68,
        1120,
        785,
        564,
        284,
        543,
        947,
        337,
        405,
        19561,
        9553,
        517,
        714,
        6
      ],
      "temperature": 0,
      "avg_logprob": -0.2539573106609407,
      "compression_ratio": 1.693798449612403,
      "no_speech_prob": 4.035542122693414e-9
    },
    {
      "id": 763,
      "seek": 466710,
      "start": 4682.9400000000005,
      "end": 4689.660000000001,
      "text": " messa in secondo piano che è quella proprio dell'architettura di questi due diversi diciamo",
      "tokens": [
        2082,
        64,
        294,
        41601,
        9211,
        947,
        4873,
        32234,
        28203,
        19781,
        6,
        1178,
        270,
        3093,
        2991,
        1026,
        29729,
        3462,
        6111,
        72,
        14285,
        7415
      ],
      "temperature": 0,
      "avg_logprob": -0.2539573106609407,
      "compression_ratio": 1.693798449612403,
      "no_speech_prob": 4.035542122693414e-9
    },
    {
      "id": 764,
      "seek": 466710,
      "start": 4689.660000000001,
      "end": 4697.02,
      "text": " tipologie di database in genere quando prendi SQL si parla sempre o quasi sempre del database",
      "tokens": [
        4125,
        20121,
        1026,
        8149,
        294,
        41553,
        7770,
        9866,
        72,
        19200,
        1511,
        971,
        875,
        9553,
        277,
        20954,
        9553,
        1103,
        8149
      ],
      "temperature": 0,
      "avg_logprob": -0.2539573106609407,
      "compression_ratio": 1.693798449612403,
      "no_speech_prob": 4.035542122693414e-9
    },
    {
      "id": 765,
      "seek": 469702,
      "start": 4697.02,
      "end": 4702.660000000001,
      "text": " monolitico che ti dà tutta una serie di caratteristiche e proprio perché è monolitico tutto sta in",
      "tokens": [
        1108,
        33704,
        2789,
        947,
        8757,
        274,
        1467,
        3672,
        1328,
        2002,
        23030,
        1026,
        1032,
        1161,
        468,
        9304,
        308,
        28203,
        14303,
        4873,
        1108,
        33704,
        2789,
        23048,
        11135,
        294
      ],
      "temperature": 0,
      "avg_logprob": -0.21419427166246388,
      "compression_ratio": 1.804635761589404,
      "no_speech_prob": 3.2241860736803574e-8
    },
    {
      "id": 766,
      "seek": 469702,
      "start": 4702.660000000001,
      "end": 4706.9800000000005,
      "text": " un unico server può fare tutta una serie di cose quando si parla di NoSQL si pensa",
      "tokens": [
        517,
        517,
        2789,
        7154,
        26526,
        11994,
        3672,
        1328,
        2002,
        23030,
        1026,
        30261,
        7770,
        1511,
        971,
        875,
        1026,
        883,
        39934,
        1511,
        46909
      ],
      "temperature": 0,
      "avg_logprob": -0.21419427166246388,
      "compression_ratio": 1.804635761589404,
      "no_speech_prob": 3.2241860736803574e-8
    },
    {
      "id": 767,
      "seek": 469702,
      "start": 4706.9800000000005,
      "end": 4713.18,
      "text": " già a database distribuiti che quindi devono capire già come partizionare i dati e come",
      "tokens": [
        30469,
        257,
        8149,
        4400,
        1983,
        72,
        947,
        15727,
        1905,
        8957,
        1410,
        621,
        30469,
        808,
        644,
        590,
        313,
        543,
        741,
        1137,
        72,
        308,
        808
      ],
      "temperature": 0,
      "avg_logprob": -0.21419427166246388,
      "compression_ratio": 1.804635761589404,
      "no_speech_prob": 3.2241860736803574e-8
    },
    {
      "id": 768,
      "seek": 469702,
      "start": 4713.18,
      "end": 4717.780000000001,
      "text": " conseguenza di ciò ci hanno pure tutta una serie di limitazioni aggiuntive e quindi magari",
      "tokens": [
        12706,
        23691,
        1026,
        6983,
        4293,
        6983,
        26595,
        6075,
        3672,
        1328,
        2002,
        23030,
        1026,
        4948,
        27569,
        42254,
        2760,
        488,
        308,
        15727,
        49932
      ],
      "temperature": 0,
      "avg_logprob": -0.21419427166246388,
      "compression_ratio": 1.804635761589404,
      "no_speech_prob": 3.2241860736803574e-8
    },
    {
      "id": 769,
      "seek": 469702,
      "start": 4717.780000000001,
      "end": 4722.1,
      "text": " si tente di più alla duplicazione dei dati perché quella è diciamo la soluzione più",
      "tokens": [
        1511,
        256,
        1576,
        1026,
        10589,
        11591,
        17154,
        12928,
        13874,
        1137,
        72,
        14303,
        32234,
        4873,
        14285,
        7415,
        635,
        1404,
        3334,
        5328,
        10589
      ],
      "temperature": 0,
      "avg_logprob": -0.21419427166246388,
      "compression_ratio": 1.804635761589404,
      "no_speech_prob": 3.2241860736803574e-8
    },
    {
      "id": 770,
      "seek": 469702,
      "start": 4722.1,
      "end": 4726.900000000001,
      "text": " semplice al problema o a diminuire le capacità di query perché anche quello ti permette",
      "tokens": [
        4361,
        564,
        573,
        419,
        12395,
        277,
        257,
        15739,
        43612,
        476,
        4637,
        12445,
        1026,
        14581,
        14303,
        11585,
        22813,
        8757,
        4784,
        3007
      ],
      "temperature": 0,
      "avg_logprob": -0.21419427166246388,
      "compression_ratio": 1.804635761589404,
      "no_speech_prob": 3.2241860736803574e-8
    },
    {
      "id": 771,
      "seek": 472690,
      "start": 4726.9,
      "end": 4731.62,
      "text": " di fare tutta una serie di cose in più dal punto di vista della distribuzione dei dati",
      "tokens": [
        1026,
        11994,
        3672,
        1328,
        2002,
        23030,
        1026,
        30261,
        294,
        10589,
        11702,
        14326,
        1026,
        22553,
        11618,
        4400,
        3334,
        5328,
        13874,
        1137,
        72
      ],
      "temperature": 0,
      "avg_logprob": -0.23262688254012542,
      "compression_ratio": 1.7913907284768211,
      "no_speech_prob": 1.4993847941013883e-8
    },
    {
      "id": 772,
      "seek": 472690,
      "start": 4731.62,
      "end": 4737.339999999999,
      "text": " e quando fai una query di andare a interrogare più nodi e riaggregare risultati quindi quella",
      "tokens": [
        308,
        7770,
        283,
        1301,
        2002,
        14581,
        1026,
        42742,
        257,
        24871,
        543,
        10589,
        15224,
        72,
        308,
        19739,
        559,
        11027,
        543,
        2253,
        723,
        6908,
        15727,
        32234
      ],
      "temperature": 0,
      "avg_logprob": -0.23262688254012542,
      "compression_ratio": 1.7913907284768211,
      "no_speech_prob": 1.4993847941013883e-8
    },
    {
      "id": 773,
      "seek": 472690,
      "start": 4737.339999999999,
      "end": 4741.82,
      "text": " secondo me è una cosa che viene sempre messo un po' in secondo piano perché raramente",
      "tokens": [
        41601,
        385,
        4873,
        2002,
        10163,
        947,
        19561,
        9553,
        2082,
        78,
        517,
        714,
        6,
        294,
        41601,
        9211,
        14303,
        367,
        289,
        3439
      ],
      "temperature": 0,
      "avg_logprob": -0.23262688254012542,
      "compression_ratio": 1.7913907284768211,
      "no_speech_prob": 1.4993847941013883e-8
    },
    {
      "id": 774,
      "seek": 472690,
      "start": 4741.82,
      "end": 4746.179999999999,
      "text": " si va a guardare l'architettura del database e si pensa più dal punto di vista utente",
      "tokens": [
        1511,
        2773,
        257,
        6290,
        543,
        287,
        6,
        1178,
        270,
        3093,
        2991,
        1103,
        8149,
        308,
        1511,
        46909,
        10589,
        11702,
        14326,
        1026,
        22553,
        2839,
        1576
      ],
      "temperature": 0,
      "avg_logprob": -0.23262688254012542,
      "compression_ratio": 1.7913907284768211,
      "no_speech_prob": 1.4993847941013883e-8
    },
    {
      "id": 775,
      "seek": 472690,
      "start": 4746.179999999999,
      "end": 4751.259999999999,
      "text": " qual è il linguaggio di query e quali sono le capacità che hai però secondo me se ci",
      "tokens": [
        4101,
        4873,
        1930,
        21766,
        30763,
        1026,
        14581,
        308,
        4101,
        72,
        9259,
        476,
        4637,
        12445,
        947,
        21822,
        12673,
        41601,
        385,
        369,
        6983
      ],
      "temperature": 0,
      "avg_logprob": -0.23262688254012542,
      "compression_ratio": 1.7913907284768211,
      "no_speech_prob": 1.4993847941013883e-8
    },
    {
      "id": 776,
      "seek": 472690,
      "start": 4751.259999999999,
      "end": 4756.58,
      "text": " andiamo a leggere ad esempio il paper di DynamoDB che poi quello che ha pure ispirato Cassandra",
      "tokens": [
        293,
        7415,
        257,
        30991,
        323,
        614,
        33627,
        1930,
        3035,
        1026,
        22947,
        78,
        27735,
        947,
        19260,
        22813,
        947,
        324,
        6075,
        307,
        9501,
        2513,
        18208,
        18401
      ],
      "temperature": 0,
      "avg_logprob": -0.23262688254012542,
      "compression_ratio": 1.7913907284768211,
      "no_speech_prob": 1.4993847941013883e-8
    },
    {
      "id": 777,
      "seek": 475658,
      "start": 4756.58,
      "end": 4761.94,
      "text": " si capisce anche il perché DynamoDB o Cassandra che sia siano molto più limitate a un punto",
      "tokens": [
        1511,
        1410,
        49596,
        11585,
        1930,
        14303,
        22947,
        78,
        27735,
        277,
        18208,
        18401,
        947,
        25176,
        262,
        6254,
        16394,
        10589,
        4948,
        473,
        257,
        517,
        14326
      ],
      "temperature": 0,
      "avg_logprob": -0.23873669168223505,
      "compression_ratio": 1.5022222222222221,
      "no_speech_prob": 2.5505404011028077e-8
    },
    {
      "id": 778,
      "seek": 475658,
      "start": 4761.94,
      "end": 4768.0199999999995,
      "text": " di vista di gestione dei dati di quanto sia il classico database SQL monolitico in cui",
      "tokens": [
        1026,
        22553,
        1026,
        7219,
        5328,
        13874,
        1137,
        72,
        1026,
        17820,
        25176,
        1930,
        1508,
        2789,
        8149,
        19200,
        1108,
        33704,
        2789,
        294,
        22929
      ],
      "temperature": 0,
      "avg_logprob": -0.23873669168223505,
      "compression_ratio": 1.5022222222222221,
      "no_speech_prob": 2.5505404011028077e-8
    },
    {
      "id": 779,
      "seek": 475658,
      "start": 4768.0199999999995,
      "end": 4772.58,
      "text": " non hai il problema di dover distribuire dati e aggregare le query.",
      "tokens": [
        2107,
        21822,
        1930,
        12395,
        1026,
        360,
        331,
        4400,
        43612,
        1137,
        72,
        308,
        623,
        33248,
        70,
        543,
        476,
        14581,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.23873669168223505,
      "compression_ratio": 1.5022222222222221,
      "no_speech_prob": 2.5505404011028077e-8
    },
    {
      "id": 780,
      "seek": 475658,
      "start": 4772.58,
      "end": 4779.46,
      "text": " Senza neanche aprire il capitolo transazioni perché a quel punto veramente la diversità",
      "tokens": [
        3862,
        2394,
        408,
        22806,
        1882,
        38920,
        1930,
        33807,
        7902,
        1145,
        27569,
        14303,
        257,
        7178,
        14326,
        50079,
        635,
        6111,
        12445
      ],
      "temperature": 0,
      "avg_logprob": -0.23873669168223505,
      "compression_ratio": 1.5022222222222221,
      "no_speech_prob": 2.5505404011028077e-8
    },
    {
      "id": 781,
      "seek": 477946,
      "start": 4779.46,
      "end": 4786.82,
      "text": " si acuisce e questo dimostra un fatto importante che in buona parte delle nostre applicazioni",
      "tokens": [
        1511,
        696,
        8479,
        384,
        308,
        10263,
        5013,
        555,
        424,
        517,
        23228,
        9416,
        947,
        294,
        758,
        4037,
        6975,
        16485,
        10397,
        265,
        2580,
        27569
      ],
      "temperature": 0,
      "avg_logprob": -0.24136088235037667,
      "compression_ratio": 1.5465116279069768,
      "no_speech_prob": 1.6726847462678052e-8
    },
    {
      "id": 782,
      "seek": 477946,
      "start": 4786.82,
      "end": 4794.34,
      "text": " noi utilizziamo un tool perché il contesto ci spinge, il marketing ci spinge, quando",
      "tokens": [
        22447,
        40355,
        7415,
        517,
        2290,
        14303,
        1930,
        10287,
        78,
        6983,
        637,
        8735,
        11,
        1930,
        6370,
        6983,
        637,
        8735,
        11,
        7770
      ],
      "temperature": 0,
      "avg_logprob": -0.24136088235037667,
      "compression_ratio": 1.5465116279069768,
      "no_speech_prob": 1.6726847462678052e-8
    },
    {
      "id": 783,
      "seek": 477946,
      "start": 4794.34,
      "end": 4799.86,
      "text": " magari fermarci un attimo e leggere un libro che per me è quasi più importante della",
      "tokens": [
        49932,
        26558,
        289,
        537,
        517,
        951,
        6934,
        308,
        30991,
        323,
        517,
        29354,
        947,
        680,
        385,
        4873,
        20954,
        10589,
        9416,
        11618
      ],
      "temperature": 0,
      "avg_logprob": -0.24136088235037667,
      "compression_ratio": 1.5465116279069768,
      "no_speech_prob": 1.6726847462678052e-8
    },
    {
      "id": 784,
      "seek": 479986,
      "start": 4799.86,
      "end": 4809.7,
      "text": " Bibbia tipo Data Intensive Applications che secondo me è veramente un viaggio, cioè",
      "tokens": [
        31520,
        26975,
        9746,
        11888,
        5681,
        2953,
        26519,
        763,
        947,
        41601,
        385,
        4873,
        50079,
        517,
        1932,
        30763,
        11,
        41827
      ],
      "temperature": 0,
      "avg_logprob": -0.18698209524154663,
      "compression_ratio": 1.5057471264367817,
      "no_speech_prob": 1.4307228290988405e-8
    },
    {
      "id": 785,
      "seek": 479986,
      "start": 4809.7,
      "end": 4816.179999999999,
      "text": " a me ha aiutato proprio a sviluppare quel tipo di consapevolezza che spesso dimentico",
      "tokens": [
        257,
        385,
        324,
        9783,
        325,
        2513,
        28203,
        257,
        17342,
        388,
        10504,
        543,
        7178,
        9746,
        1026,
        1014,
        41153,
        3080,
        20336,
        2394,
        947,
        637,
        5557,
        274,
        2328,
        2789
      ],
      "temperature": 0,
      "avg_logprob": -0.18698209524154663,
      "compression_ratio": 1.5057471264367817,
      "no_speech_prob": 1.4307228290988405e-8
    },
    {
      "id": 786,
      "seek": 479986,
      "start": 4816.179999999999,
      "end": 4824.139999999999,
      "text": " ma comunque mi ha aiutato a costruirla per capire che talvolta la scelta non è sul motore",
      "tokens": [
        463,
        45736,
        2752,
        324,
        9783,
        325,
        2513,
        257,
        2063,
        894,
        347,
        875,
        680,
        1410,
        621,
        947,
        4023,
        9646,
        1328,
        635,
        795,
        338,
        1328,
        2107,
        4873,
        17603,
        2184,
        418
      ],
      "temperature": 0,
      "avg_logprob": -0.18698209524154663,
      "compression_ratio": 1.5057471264367817,
      "no_speech_prob": 1.4307228290988405e-8
    },
    {
      "id": 787,
      "seek": 482414,
      "start": 4824.14,
      "end": 4831.54,
      "text": " di query che utilizziamo solo su come andiamo a prendere i dati o a salvare i dati ma quello",
      "tokens": [
        1026,
        14581,
        947,
        40355,
        7415,
        6944,
        459,
        808,
        293,
        7415,
        257,
        9866,
        323,
        741,
        1137,
        72,
        277,
        257,
        26858,
        543,
        741,
        1137,
        72,
        463,
        22813
      ],
      "temperature": 0,
      "avg_logprob": -0.22800523200921252,
      "compression_ratio": 1.5864978902953586,
      "no_speech_prob": 2.672939558578946e-8
    },
    {
      "id": 788,
      "seek": 482414,
      "start": 4831.54,
      "end": 4838.22,
      "text": " che ci sta sotto probabilmente potrà tornarci indietro come un boomerang in un secondo momento.",
      "tokens": [
        947,
        6983,
        11135,
        43754,
        31959,
        4082,
        1847,
        39212,
        41283,
        537,
        1016,
        1684,
        340,
        808,
        517,
        9351,
        260,
        656,
        294,
        517,
        41601,
        9333,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.22800523200921252,
      "compression_ratio": 1.5864978902953586,
      "no_speech_prob": 2.672939558578946e-8
    },
    {
      "id": 789,
      "seek": 482414,
      "start": 4838.22,
      "end": 4844.9400000000005,
      "text": " Io guardavo l'orologio, cioè sembra che abbiamo appena iniziato a registrare, ci stiamo giusto",
      "tokens": [
        19239,
        6290,
        25713,
        287,
        6,
        284,
        1132,
        1004,
        11,
        41827,
        20775,
        424,
        947,
        22815,
        724,
        4118,
        294,
        24300,
        2513,
        257,
        11376,
        35559,
        11,
        6983,
        342,
        7415,
        1735,
        48260
      ],
      "temperature": 0,
      "avg_logprob": -0.22800523200921252,
      "compression_ratio": 1.5864978902953586,
      "no_speech_prob": 2.672939558578946e-8
    },
    {
      "id": 790,
      "seek": 482414,
      "start": 4844.9400000000005,
      "end": 4852.700000000001,
      "text": " riscaldando ed è tipo passata un'ora e venti, quindi io chiedo rapidamente a Luca e a Leo",
      "tokens": [
        2253,
        66,
        3976,
        1806,
        1257,
        4873,
        9746,
        1320,
        3274,
        517,
        6,
        3252,
        308,
        6931,
        72,
        11,
        15727,
        19785,
        417,
        36035,
        7558,
        3439,
        257,
        42076,
        308,
        257,
        19344
      ],
      "temperature": 0,
      "avg_logprob": -0.22800523200921252,
      "compression_ratio": 1.5864978902953586,
      "no_speech_prob": 2.672939558578946e-8
    },
    {
      "id": 791,
      "seek": 485270,
      "start": 4852.7,
      "end": 4862.9,
      "text": " se hanno qualche domanda per Luciano. No, non adesso. No, ma come al solito mi verranno",
      "tokens": [
        369,
        26595,
        38737,
        3285,
        5575,
        680,
        37309,
        3730,
        13,
        883,
        11,
        2107,
        39552,
        13,
        883,
        11,
        463,
        808,
        419,
        1404,
        3528,
        2752,
        45923,
        13484
      ],
      "temperature": 0,
      "avg_logprob": -0.20583431019502527,
      "compression_ratio": 1.4918032786885247,
      "no_speech_prob": 2.6165142230638594e-7
    },
    {
      "id": 792,
      "seek": 485270,
      "start": 4862.9,
      "end": 4872.66,
      "text": " sotto la doccia domani, poi sarà troppo tardi, pazienza lo troverò nel gruppo forse. Io a",
      "tokens": [
        43754,
        635,
        3211,
        2755,
        3285,
        3782,
        11,
        19260,
        41338,
        4495,
        27000,
        21057,
        72,
        11,
        30032,
        42331,
        450,
        4495,
        331,
        4293,
        15373,
        47477,
        78,
        337,
        405,
        13,
        19239,
        257
      ],
      "temperature": 0,
      "avg_logprob": -0.20583431019502527,
      "compression_ratio": 1.4918032786885247,
      "no_speech_prob": 2.6165142230638594e-7
    },
    {
      "id": 793,
      "seek": 485270,
      "start": 4872.66,
      "end": 4879.62,
      "text": " questo punto vorrei chiedere a Luciano, anzi andare insieme a Luciano, Luca e Leo nel momento",
      "tokens": [
        10263,
        14326,
        4245,
        10271,
        417,
        1091,
        323,
        257,
        37309,
        3730,
        11,
        364,
        3992,
        42742,
        1028,
        44940,
        257,
        37309,
        3730,
        11,
        42076,
        308,
        19344,
        15373,
        9333
      ],
      "temperature": 0,
      "avg_logprob": -0.20583431019502527,
      "compression_ratio": 1.4918032786885247,
      "no_speech_prob": 2.6165142230638594e-7
    },
    {
      "id": 794,
      "seek": 487962,
      "start": 4879.62,
      "end": 4887.18,
      "text": " tipico e topico del nostro podcast, il momento il Paese dei Balocchi, il momento in cui i",
      "tokens": [
        4125,
        2789,
        308,
        1192,
        2789,
        1103,
        35779,
        7367,
        11,
        1930,
        9333,
        1930,
        3426,
        1130,
        13874,
        13140,
        905,
        8036,
        11,
        1930,
        9333,
        294,
        22929,
        741
      ],
      "temperature": 0,
      "avg_logprob": -0.23060852873559093,
      "compression_ratio": 1.6153846153846154,
      "no_speech_prob": 1.0407786987798318e-7
    },
    {
      "id": 795,
      "seek": 487962,
      "start": 4887.18,
      "end": 4895.0599999999995,
      "text": " guest e gli host condividono con noi un tool, un libro, un video, una ricetta, qualcosa",
      "tokens": [
        8341,
        308,
        17161,
        3975,
        2224,
        1843,
        8957,
        416,
        22447,
        517,
        2290,
        11,
        517,
        29354,
        11,
        517,
        960,
        11,
        2002,
        21040,
        16593,
        11,
        42400
      ],
      "temperature": 0,
      "avg_logprob": -0.23060852873559093,
      "compression_ratio": 1.6153846153846154,
      "no_speech_prob": 1.0407786987798318e-7
    },
    {
      "id": 796,
      "seek": 487962,
      "start": 4895.0599999999995,
      "end": 4903.599999999999,
      "text": " che abbia in qualche modo colpito particolarmente la loro attenzione. Quindi la prima domanda",
      "tokens": [
        947,
        16903,
        654,
        294,
        38737,
        16664,
        1173,
        79,
        3528,
        1276,
        15276,
        4082,
        635,
        28810,
        951,
        11368,
        5328,
        13,
        32534,
        635,
        19507,
        3285,
        5575
      ],
      "temperature": 0,
      "avg_logprob": -0.23060852873559093,
      "compression_ratio": 1.6153846153846154,
      "no_speech_prob": 1.0407786987798318e-7
    },
    {
      "id": 797,
      "seek": 487962,
      "start": 4903.599999999999,
      "end": 4908.62,
      "text": " va verso Luciano. Luciano c'è qualcosa che vuoi condividere con la nostra community?",
      "tokens": [
        2773,
        49786,
        37309,
        3730,
        13,
        37309,
        3730,
        269,
        6,
        1462,
        42400,
        947,
        9732,
        4869,
        2224,
        1843,
        323,
        416,
        635,
        34311,
        1768,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.23060852873559093,
      "compression_ratio": 1.6153846153846154,
      "no_speech_prob": 1.0407786987798318e-7
    },
    {
      "id": 798,
      "seek": 490862,
      "start": 4908.62,
      "end": 4915.7,
      "text": " E conducono il Paese dei Balocchi. Ah, il Paese dei Balocchi. Allora faccio un velocissimo",
      "tokens": [
        462,
        2224,
        1311,
        8957,
        1930,
        3426,
        1130,
        13874,
        13140,
        905,
        8036,
        13,
        2438,
        11,
        1930,
        3426,
        1130,
        13874,
        13140,
        905,
        8036,
        13,
        1057,
        3252,
        1915,
        8529,
        517,
        7806,
        34966
      ],
      "temperature": 0,
      "avg_logprob": -0.2841657358449656,
      "compression_ratio": 1.5894736842105264,
      "no_speech_prob": 0.000008939454346545972
    },
    {
      "id": 799,
      "seek": 490862,
      "start": 4915.7,
      "end": 4920.46,
      "text": " recap innanzitutto dei link che abbiamo promesso di dare e che poi spero verranno inseriti",
      "tokens": [
        20928,
        7714,
        3910,
        270,
        28698,
        13874,
        2113,
        947,
        22815,
        2234,
        5557,
        1026,
        8955,
        308,
        947,
        19260,
        24152,
        78,
        45923,
        13484,
        1028,
        260,
        8707
      ],
      "temperature": 0,
      "avg_logprob": -0.2841657358449656,
      "compression_ratio": 1.5894736842105264,
      "no_speech_prob": 0.000008939454346545972
    },
    {
      "id": 800,
      "seek": 490862,
      "start": 4920.46,
      "end": 4926.0199999999995,
      "text": " in questa sezione. Uno era il post di Owen Schanachy, il CTO di Fortiorem riguardo al",
      "tokens": [
        294,
        16540,
        369,
        19706,
        13,
        37468,
        4249,
        1930,
        2183,
        1026,
        32867,
        2065,
        282,
        608,
        88,
        11,
        1930,
        383,
        15427,
        1026,
        11002,
        72,
        37956,
        8329,
        84,
        12850,
        419
      ],
      "temperature": 0,
      "avg_logprob": -0.2841657358449656,
      "compression_ratio": 1.5894736842105264,
      "no_speech_prob": 0.000008939454346545972
    },
    {
      "id": 801,
      "seek": 490862,
      "start": 4926.0199999999995,
      "end": 4932.5,
      "text": " prezzo, il confronto di prezzo tra EC2, Fargate e Lambda e quello secondo me è un post ottimo",
      "tokens": [
        659,
        35130,
        11,
        1930,
        1497,
        81,
        7556,
        1026,
        659,
        35130,
        944,
        19081,
        17,
        11,
        9067,
        22514,
        308,
        45691,
        308,
        22813,
        41601,
        385,
        4873,
        517,
        2183,
        42772,
        6934
      ],
      "temperature": 0,
      "avg_logprob": -0.2841657358449656,
      "compression_ratio": 1.5894736842105264,
      "no_speech_prob": 0.000008939454346545972
    },
    {
      "id": 802,
      "seek": 490862,
      "start": 4932.5,
      "end": 4938.34,
      "text": " a qualche anno ma secondo me ad oggi è ancora molto rilevante. L'altro è quel caso d'uso",
      "tokens": [
        257,
        38737,
        46277,
        463,
        41601,
        385,
        614,
        34768,
        4873,
        30656,
        16394,
        367,
        794,
        85,
        2879,
        13,
        441,
        6,
        47484,
        4873,
        7178,
        9666,
        274,
        6,
        24431
      ],
      "temperature": 0,
      "avg_logprob": -0.2841657358449656,
      "compression_ratio": 1.5894736842105264,
      "no_speech_prob": 0.000008939454346545972
    },
    {
      "id": 803,
      "seek": 493834,
      "start": 4938.34,
      "end": 4944.34,
      "text": " che avevo menzionato riguardo a fare big data con serverless ed è un caso d'uso con cui",
      "tokens": [
        947,
        3472,
        3080,
        1706,
        89,
        313,
        2513,
        8329,
        84,
        12850,
        257,
        11994,
        955,
        1412,
        416,
        7154,
        1832,
        1257,
        4873,
        517,
        9666,
        274,
        6,
        24431,
        416,
        22929
      ],
      "temperature": 0,
      "avg_logprob": -0.21001298298207363,
      "compression_ratio": 1.6569343065693432,
      "no_speech_prob": 2.203328932637305e-7
    },
    {
      "id": 804,
      "seek": 493834,
      "start": 4944.34,
      "end": 4948.26,
      "text": " è stato fatto anche un articolo che è stato pubblicato proprio sul blog di AWS quindi",
      "tokens": [
        4873,
        29657,
        23228,
        11585,
        517,
        15228,
        7902,
        947,
        4873,
        29657,
        1535,
        11489,
        2513,
        28203,
        17603,
        6968,
        1026,
        17650,
        15727
      ],
      "temperature": 0,
      "avg_logprob": -0.21001298298207363,
      "compression_ratio": 1.6569343065693432,
      "no_speech_prob": 2.203328932637305e-7
    },
    {
      "id": 805,
      "seek": 493834,
      "start": 4948.26,
      "end": 4953.38,
      "text": " spero che vogliate linkare anche quel blog post per far capire perché in quel caso particolare",
      "tokens": [
        24152,
        78,
        947,
        31273,
        2081,
        473,
        2113,
        543,
        11585,
        7178,
        6968,
        2183,
        680,
        1400,
        1410,
        621,
        14303,
        294,
        7178,
        9666,
        1276,
        43141
      ],
      "temperature": 0,
      "avg_logprob": -0.21001298298207363,
      "compression_ratio": 1.6569343065693432,
      "no_speech_prob": 2.203328932637305e-7
    },
    {
      "id": 806,
      "seek": 493834,
      "start": 4953.38,
      "end": 4961.42,
      "text": " secondo me Lambda ha più senso di altre soluzioni nonostante stiamo parlando di big data. E",
      "tokens": [
        41601,
        385,
        45691,
        324,
        10589,
        3151,
        539,
        1026,
        34983,
        1404,
        3334,
        15273,
        2107,
        555,
        2879,
        342,
        7415,
        971,
        16201,
        1026,
        955,
        1412,
        13,
        462
      ],
      "temperature": 0,
      "avg_logprob": -0.21001298298207363,
      "compression_ratio": 1.6569343065693432,
      "no_speech_prob": 2.203328932637305e-7
    },
    {
      "id": 807,
      "seek": 493834,
      "start": 4961.42,
      "end": 4966.66,
      "text": " un'altra cosa che vorrei menzionare, questo forse è il mio link aggiuntivo, è il fatto",
      "tokens": [
        517,
        6,
        38865,
        10163,
        947,
        4245,
        10271,
        1706,
        89,
        313,
        543,
        11,
        10263,
        337,
        405,
        4873,
        1930,
        29908,
        2113,
        42254,
        2760,
        6340,
        11,
        4873,
        1930,
        23228
      ],
      "temperature": 0,
      "avg_logprob": -0.21001298298207363,
      "compression_ratio": 1.6569343065693432,
      "no_speech_prob": 2.203328932637305e-7
    },
    {
      "id": 808,
      "seek": 496666,
      "start": 4966.66,
      "end": 4971.139999999999,
      "text": " che ultimamente mi sto un po' dilettando con Rust, ne avevamo parlato pure un po' prima",
      "tokens": [
        947,
        3725,
        332,
        3439,
        2752,
        22784,
        517,
        714,
        6,
        11504,
        3093,
        1806,
        416,
        34952,
        11,
        408,
        3472,
        85,
        10502,
        13734,
        2513,
        6075,
        517,
        714,
        6,
        19507
      ],
      "temperature": 0,
      "avg_logprob": -0.22947662060077373,
      "compression_ratio": 1.7007874015748032,
      "no_speech_prob": 2.5759533173186355e-7
    },
    {
      "id": 809,
      "seek": 496666,
      "start": 4971.139999999999,
      "end": 4977.38,
      "text": " della live e quindi ho provato anche un po' a esplorare il discorso di posso scrivere",
      "tokens": [
        11618,
        1621,
        308,
        15727,
        1106,
        1439,
        2513,
        11585,
        517,
        714,
        6,
        257,
        785,
        564,
        284,
        543,
        1930,
        2983,
        284,
        539,
        1026,
        22501,
        5545,
        5887
      ],
      "temperature": 0,
      "avg_logprob": -0.22947662060077373,
      "compression_ratio": 1.7007874015748032,
      "no_speech_prob": 2.5759533173186355e-7
    },
    {
      "id": 810,
      "seek": 496666,
      "start": 4977.38,
      "end": 4982.78,
      "text": " una Lambda in Rust e quali sono i vantaggi e gli svantaggi e la complessità del caso",
      "tokens": [
        2002,
        45691,
        294,
        34952,
        308,
        4101,
        72,
        9259,
        741,
        371,
        394,
        46893,
        308,
        17161,
        262,
        5219,
        46893,
        308,
        635,
        1209,
        442,
        12445,
        1103,
        9666
      ],
      "temperature": 0,
      "avg_logprob": -0.22947662060077373,
      "compression_ratio": 1.7007874015748032,
      "no_speech_prob": 2.5759533173186355e-7
    },
    {
      "id": 811,
      "seek": 496666,
      "start": 4982.78,
      "end": 4986.66,
      "text": " e da una parte ho trovato questo articolo che bilinco di una società che si chiama",
      "tokens": [
        308,
        1120,
        2002,
        6975,
        1106,
        35449,
        2513,
        10263,
        15228,
        7902,
        947,
        8588,
        259,
        1291,
        1026,
        2002,
        14051,
        1467,
        947,
        1511,
        13228,
        2404
      ],
      "temperature": 0,
      "avg_logprob": -0.22947662060077373,
      "compression_ratio": 1.7007874015748032,
      "no_speech_prob": 2.5759533173186355e-7
    },
    {
      "id": 812,
      "seek": 496666,
      "start": 4986.66,
      "end": 4991.62,
      "text": " Scanner che è proprio un how to, cioè come fare a fare la prima Lambda, quali sono gli",
      "tokens": [
        2747,
        9805,
        947,
        4873,
        28203,
        517,
        577,
        281,
        11,
        41827,
        808,
        11994,
        257,
        11994,
        635,
        19507,
        45691,
        11,
        4101,
        72,
        9259,
        17161
      ],
      "temperature": 0,
      "avg_logprob": -0.22947662060077373,
      "compression_ratio": 1.7007874015748032,
      "no_speech_prob": 2.5759533173186355e-7
    },
    {
      "id": 813,
      "seek": 499162,
      "start": 4991.62,
      "end": 4996.58,
      "text": " strumenti ed è fatto molto bene, dall'altro è un argomento che parleremo nella prossima",
      "tokens": [
        1056,
        2206,
        72,
        1257,
        4873,
        23228,
        16394,
        2537,
        11,
        43351,
        6,
        47484,
        4873,
        517,
        3882,
        298,
        15467,
        947,
        13734,
        323,
        3280,
        23878,
        48794,
        4775
      ],
      "temperature": 0,
      "avg_logprob": -0.2412255428455494,
      "compression_ratio": 1.5991189427312775,
      "no_speech_prob": 1.5623938054432074e-7
    },
    {
      "id": 814,
      "seek": 499162,
      "start": 4996.58,
      "end": 5002.78,
      "text": " puntata del podcast di AWSbytes che è un podcast che gestisco insieme a Owen Shanaghi",
      "tokens": [
        18212,
        3274,
        1103,
        7367,
        1026,
        17650,
        2322,
        7269,
        947,
        4873,
        517,
        7367,
        947,
        7219,
        8610,
        1028,
        44940,
        257,
        32867,
        1160,
        282,
        559,
        4954
      ],
      "temperature": 0,
      "avg_logprob": -0.2412255428455494,
      "compression_ratio": 1.5991189427312775,
      "no_speech_prob": 1.5623938054432074e-7
    },
    {
      "id": 815,
      "seek": 499162,
      "start": 5002.78,
      "end": 5007.78,
      "text": " di Fortiorem e appunto parleremo proprio di vantaggi e svantaggi e come fare a scrivere",
      "tokens": [
        1026,
        11002,
        72,
        37956,
        308,
        724,
        24052,
        13734,
        323,
        3280,
        28203,
        1026,
        371,
        394,
        46893,
        308,
        262,
        5219,
        46893,
        308,
        808,
        11994,
        257,
        5545,
        5887
      ],
      "temperature": 0,
      "avg_logprob": -0.2412255428455494,
      "compression_ratio": 1.5991189427312775,
      "no_speech_prob": 1.5623938054432074e-7
    },
    {
      "id": 816,
      "seek": 499162,
      "start": 5007.78,
      "end": 5012.7,
      "text": " la prima Lambda in Rust quindi vi mando pure come riferimento a vedere questa puntata di",
      "tokens": [
        635,
        19507,
        45691,
        294,
        34952,
        15727,
        1932,
        7411,
        78,
        6075,
        808,
        367,
        9361,
        10030,
        257,
        35373,
        16540,
        18212,
        3274,
        1026
      ],
      "temperature": 0,
      "avg_logprob": -0.2412255428455494,
      "compression_ratio": 1.5991189427312775,
      "no_speech_prob": 1.5623938054432074e-7
    },
    {
      "id": 817,
      "seek": 499162,
      "start": 5012.7,
      "end": 5013.7,
      "text": " AWSbytes.",
      "tokens": [
        17650,
        2322,
        7269,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2412255428455494,
      "compression_ratio": 1.5991189427312775,
      "no_speech_prob": 1.5623938054432074e-7
    },
    {
      "id": 818,
      "seek": 501370,
      "start": 5013.7,
      "end": 5023.86,
      "text": " E tra l'altro anche la puntata, anche il link di AWSbytes lo mettiamo nelle note dell'episodio.",
      "tokens": [
        462,
        944,
        287,
        6,
        47484,
        11585,
        635,
        18212,
        3274,
        11,
        11585,
        1930,
        2113,
        1026,
        17650,
        2322,
        7269,
        450,
        27812,
        7415,
        46350,
        3637,
        19781,
        6,
        595,
        271,
        378,
        1004,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2630171022917095,
      "compression_ratio": 1.4223602484472049,
      "no_speech_prob": 6.179364504532714e-7
    },
    {
      "id": 819,
      "seek": 501370,
      "start": 5023.86,
      "end": 5028.22,
      "text": " Leo, Luca cosa avete da condividere con noi?",
      "tokens": [
        19344,
        11,
        42076,
        10163,
        48201,
        1120,
        2224,
        1843,
        323,
        416,
        22447,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.2630171022917095,
      "compression_ratio": 1.4223602484472049,
      "no_speech_prob": 6.179364504532714e-7
    },
    {
      "id": 820,
      "seek": 501370,
      "start": 5028.22,
      "end": 5035.62,
      "text": " Allora io ho due cose velocissime che non centrano nulla con l'argomento come al solito,",
      "tokens": [
        1057,
        3252,
        19785,
        1106,
        3462,
        30261,
        7806,
        891,
        1312,
        947,
        2107,
        1489,
        81,
        3730,
        18184,
        64,
        416,
        287,
        6,
        289,
        30851,
        15467,
        808,
        419,
        1404,
        3528,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.2630171022917095,
      "compression_ratio": 1.4223602484472049,
      "no_speech_prob": 6.179364504532714e-7
    },
    {
      "id": 821,
      "seek": 503562,
      "start": 5035.62,
      "end": 5045.18,
      "text": " la prima è un videogioco che ho sentito come balocco su digitalia che si chiama Vampire",
      "tokens": [
        635,
        19507,
        4873,
        517,
        838,
        27202,
        11198,
        947,
        1106,
        2279,
        3528,
        808,
        3119,
        905,
        1291,
        459,
        4562,
        654,
        947,
        1511,
        13228,
        2404,
        38796,
        621
      ],
      "temperature": 0,
      "avg_logprob": -0.24680893761771067,
      "compression_ratio": 1.5082872928176796,
      "no_speech_prob": 1.3363643347474863e-7
    },
    {
      "id": 822,
      "seek": 503562,
      "start": 5045.18,
      "end": 5051.26,
      "text": " Survivors, è un survivor game, uno dei giochi con il più alto rilascio di endorfine che",
      "tokens": [
        48859,
        830,
        11,
        4873,
        517,
        25953,
        1216,
        11,
        8526,
        13874,
        48508,
        8036,
        416,
        1930,
        10589,
        21275,
        367,
        388,
        296,
        8529,
        1026,
        917,
        28030,
        533,
        947
      ],
      "temperature": 0,
      "avg_logprob": -0.24680893761771067,
      "compression_ratio": 1.5082872928176796,
      "no_speech_prob": 1.3363643347474863e-7
    },
    {
      "id": 823,
      "seek": 503562,
      "start": 5051.26,
      "end": 5060.78,
      "text": " abbia mai trovato, c'è su Steam, c'è anche la versione mobile, è stato fatto da un italiano",
      "tokens": [
        16903,
        654,
        12698,
        35449,
        2513,
        11,
        269,
        6,
        1462,
        459,
        22517,
        11,
        269,
        6,
        1462,
        11585,
        635,
        3037,
        68,
        6013,
        11,
        4873,
        29657,
        23228,
        1120,
        517,
        48486
      ],
      "temperature": 0,
      "avg_logprob": -0.24680893761771067,
      "compression_ratio": 1.5082872928176796,
      "no_speech_prob": 1.3363643347474863e-7
    },
    {
      "id": 824,
      "seek": 506078,
      "start": 5060.78,
      "end": 5067.78,
      "text": " ed è il gioco su Steam fatto da un italiano con più successo, un successo improvviso,",
      "tokens": [
        1257,
        4873,
        1930,
        1735,
        11198,
        459,
        22517,
        23228,
        1120,
        517,
        48486,
        416,
        10589,
        2245,
        78,
        11,
        517,
        2245,
        78,
        29424,
        4938,
        78,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.24993922129398635,
      "compression_ratio": 1.5951417004048583,
      "no_speech_prob": 7.65811059011412e-9
    },
    {
      "id": 825,
      "seek": 506078,
      "start": 5067.78,
      "end": 5072.0199999999995,
      "text": " vi invito anche a leggere le interviste che sono state fatte, molto divertente, non vi",
      "tokens": [
        1932,
        1048,
        3528,
        11585,
        257,
        30991,
        323,
        476,
        728,
        85,
        8375,
        947,
        9259,
        1785,
        4046,
        975,
        11,
        16394,
        23781,
        1576,
        11,
        2107,
        1932
      ],
      "temperature": 0,
      "avg_logprob": -0.24993922129398635,
      "compression_ratio": 1.5951417004048583,
      "no_speech_prob": 7.65811059011412e-9
    },
    {
      "id": 826,
      "seek": 506078,
      "start": 5072.0199999999995,
      "end": 5073.78,
      "text": " dico nulla, andate a provarlo.",
      "tokens": [
        274,
        2789,
        18184,
        64,
        11,
        293,
        473,
        257,
        1439,
        19457,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.24993922129398635,
      "compression_ratio": 1.5951417004048583,
      "no_speech_prob": 7.65811059011412e-9
    },
    {
      "id": 827,
      "seek": 506078,
      "start": 5073.78,
      "end": 5081.98,
      "text": " E l'altro è una serie TV che si chiama Kaleidoscope che si trova su Netflix che ha una cosa particolare",
      "tokens": [
        462,
        287,
        6,
        47484,
        4873,
        2002,
        23030,
        3558,
        947,
        1511,
        13228,
        2404,
        591,
        1220,
        7895,
        13960,
        947,
        1511,
        4495,
        2757,
        459,
        12778,
        947,
        324,
        2002,
        10163,
        1276,
        43141
      ],
      "temperature": 0,
      "avg_logprob": -0.24993922129398635,
      "compression_ratio": 1.5951417004048583,
      "no_speech_prob": 7.65811059011412e-9
    },
    {
      "id": 828,
      "seek": 506078,
      "start": 5081.98,
      "end": 5088.9,
      "text": " perché in pratica gli episodi sono stati fatti per essere visti nell'ordine in cui",
      "tokens": [
        14303,
        294,
        28844,
        2262,
        17161,
        2927,
        30727,
        9259,
        2219,
        72,
        283,
        21515,
        680,
        19799,
        40247,
        72,
        44666,
        6,
        765,
        533,
        294,
        22929
      ],
      "temperature": 0,
      "avg_logprob": -0.24993922129398635,
      "compression_ratio": 1.5951417004048583,
      "no_speech_prob": 7.65811059011412e-9
    },
    {
      "id": 829,
      "seek": 508890,
      "start": 5088.9,
      "end": 5094.299999999999,
      "text": " uno vuole, sono ordinati dall'1 all'8 mi pare la prima stagione, però sono identificati",
      "tokens": [
        8526,
        9732,
        4812,
        11,
        9259,
        25376,
        6908,
        43351,
        6,
        16,
        439,
        6,
        23,
        2752,
        7448,
        635,
        19507,
        342,
        559,
        5328,
        11,
        12673,
        9259,
        49456,
        6908
      ],
      "temperature": 0,
      "avg_logprob": -0.2536160408913552,
      "compression_ratio": 1.5844155844155845,
      "no_speech_prob": 5.5708945012611366e-8
    },
    {
      "id": 830,
      "seek": 508890,
      "start": 5094.299999999999,
      "end": 5102.82,
      "text": " con dei colori, in pratica parla di una grossa rapina che deve essere fatta, però a seconda",
      "tokens": [
        416,
        13874,
        2017,
        72,
        11,
        294,
        28844,
        2262,
        971,
        875,
        1026,
        2002,
        677,
        9978,
        5099,
        1426,
        947,
        17761,
        19799,
        4046,
        1328,
        11,
        12673,
        257,
        1150,
        64
      ],
      "temperature": 0,
      "avg_logprob": -0.2536160408913552,
      "compression_ratio": 1.5844155844155845,
      "no_speech_prob": 5.5708945012611366e-8
    },
    {
      "id": 831,
      "seek": 508890,
      "start": 5102.82,
      "end": 5111.0199999999995,
      "text": " di come uno vede l'ordine degli episodi, prende diverse angolazioni, ho visto due episodi,",
      "tokens": [
        1026,
        808,
        8526,
        371,
        4858,
        287,
        6,
        765,
        533,
        32079,
        2927,
        30727,
        11,
        9866,
        68,
        9521,
        2562,
        401,
        27569,
        11,
        1106,
        17558,
        3462,
        2927,
        30727,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.2536160408913552,
      "compression_ratio": 1.5844155844155845,
      "no_speech_prob": 5.5708945012611366e-8
    },
    {
      "id": 832,
      "seek": 508890,
      "start": 5111.0199999999995,
      "end": 5116.179999999999,
      "text": " il pilot, il primo, il secondo è un flashback di 24 anni prima, quindi più o meno ho capito",
      "tokens": [
        1930,
        9691,
        11,
        1930,
        38671,
        11,
        1930,
        41601,
        4873,
        517,
        7319,
        3207,
        1026,
        4022,
        31164,
        19507,
        11,
        15727,
        10589,
        277,
        40236,
        1106,
        1410,
        3528
      ],
      "temperature": 0,
      "avg_logprob": -0.2536160408913552,
      "compression_ratio": 1.5844155844155845,
      "no_speech_prob": 5.5708945012611366e-8
    },
    {
      "id": 833,
      "seek": 511618,
      "start": 5116.18,
      "end": 5123.58,
      "text": " che viene preso lo stesso argomento da diversi punti del tempo e mi sembra interessante,",
      "tokens": [
        947,
        19561,
        1183,
        78,
        450,
        44413,
        3882,
        298,
        15467,
        1120,
        6111,
        72,
        18212,
        72,
        1103,
        8972,
        308,
        2752,
        20775,
        424,
        24372,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.29680344997308195,
      "compression_ratio": 1.4720496894409938,
      "no_speech_prob": 1.780563785303002e-8
    },
    {
      "id": 834,
      "seek": 511618,
      "start": 5123.58,
      "end": 5129.820000000001,
      "text": " condivido queste due cose, troverete i link nell'episodio.",
      "tokens": [
        2224,
        1843,
        78,
        35455,
        3462,
        30261,
        11,
        4495,
        331,
        3498,
        741,
        2113,
        44666,
        6,
        595,
        271,
        378,
        1004,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.29680344997308195,
      "compression_ratio": 1.4720496894409938,
      "no_speech_prob": 1.780563785303002e-8
    },
    {
      "id": 835,
      "seek": 511618,
      "start": 5129.820000000001,
      "end": 5139.9800000000005,
      "text": " Io balocco anche un'app, un'app per mobile, sapete che mi dedico agli scacchi ogni tanto,",
      "tokens": [
        19239,
        3119,
        905,
        1291,
        11585,
        517,
        6,
        1746,
        11,
        517,
        6,
        1746,
        680,
        6013,
        11,
        18985,
        3498,
        947,
        2752,
        4172,
        2789,
        623,
        2081,
        795,
        326,
        8036,
        33189,
        10331,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.29680344997308195,
      "compression_ratio": 1.4720496894409938,
      "no_speech_prob": 1.780563785303002e-8
    },
    {
      "id": 836,
      "seek": 513998,
      "start": 5139.98,
      "end": 5147.62,
      "text": " sto cercando di imparare a superare un livello quanto meno decente, a parte ovviamente il",
      "tokens": [
        22784,
        36099,
        1806,
        1026,
        704,
        289,
        543,
        257,
        1687,
        543,
        517,
        1621,
        1913,
        17820,
        40236,
        979,
        1576,
        11,
        257,
        6975,
        14187,
        23347,
        1930
      ],
      "temperature": 0,
      "avg_logprob": -0.23810684781114594,
      "compression_ratio": 1.5963302752293578,
      "no_speech_prob": 6.615599801307326e-8
    },
    {
      "id": 837,
      "seek": 513998,
      "start": 5147.62,
      "end": 5155.099999999999,
      "text": " blasonato c'è il scom, c'è il Dr. Wolf che è un vecchio che ti insegna a giocare",
      "tokens": [
        888,
        1258,
        2513,
        269,
        6,
        1462,
        1930,
        795,
        298,
        11,
        269,
        6,
        1462,
        1930,
        2491,
        13,
        16634,
        947,
        4873,
        517,
        42021,
        31033,
        947,
        8757,
        33874,
        70,
        629,
        257,
        48508,
        5685
      ],
      "temperature": 0,
      "avg_logprob": -0.23810684781114594,
      "compression_ratio": 1.5963302752293578,
      "no_speech_prob": 6.615599801307326e-8
    },
    {
      "id": 838,
      "seek": 513998,
      "start": 5155.099999999999,
      "end": 5160.86,
      "text": " a scacchi e ti spiega le mosse, ti fa fare proprio un percorso, ti dice guarda in questa",
      "tokens": [
        257,
        795,
        326,
        8036,
        308,
        8757,
        637,
        414,
        3680,
        476,
        13659,
        405,
        11,
        8757,
        2050,
        11994,
        28203,
        517,
        680,
        19558,
        539,
        11,
        8757,
        10313,
        6290,
        64,
        294,
        16540
      ],
      "temperature": 0,
      "avg_logprob": -0.23810684781114594,
      "compression_ratio": 1.5963302752293578,
      "no_speech_prob": 6.615599801307326e-8
    },
    {
      "id": 839,
      "seek": 513998,
      "start": 5160.86,
      "end": 5166.339999999999,
      "text": " partita scoprirò il mio re, vedi se riesci a farmi scaccomato in questo modo, oppure",
      "tokens": [
        644,
        2786,
        795,
        404,
        10949,
        4293,
        1930,
        29908,
        319,
        11,
        371,
        10323,
        369,
        23932,
        537,
        257,
        1400,
        3057,
        795,
        326,
        1112,
        2513,
        294,
        10263,
        16664,
        11,
        1458,
        540
      ],
      "temperature": 0,
      "avg_logprob": -0.23810684781114594,
      "compression_ratio": 1.5963302752293578,
      "no_speech_prob": 6.615599801307326e-8
    },
    {
      "id": 840,
      "seek": 516634,
      "start": 5166.34,
      "end": 5176.46,
      "text": " farò un errore nel mezzo che ti consentirà di fare un fork, prova a far quello, insomma",
      "tokens": [
        1400,
        4293,
        517,
        45935,
        265,
        15373,
        385,
        35130,
        947,
        8757,
        14546,
        347,
        1467,
        1026,
        11994,
        517,
        17716,
        11,
        28959,
        257,
        1400,
        22813,
        11,
        1028,
        30243
      ],
      "temperature": 0,
      "avg_logprob": -0.29655009568339646,
      "compression_ratio": 1.5203619909502262,
      "no_speech_prob": 1.4307239837307861e-8
    },
    {
      "id": 841,
      "seek": 516634,
      "start": 5176.46,
      "end": 5182.78,
      "text": " ha un approccio divertente che sta, spero, credo, funzionando.",
      "tokens": [
        324,
        517,
        2075,
        66,
        8529,
        23781,
        1576,
        947,
        11135,
        11,
        24152,
        78,
        11,
        3864,
        78,
        11,
        49345,
        313,
        1806,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.29655009568339646,
      "compression_ratio": 1.5203619909502262,
      "no_speech_prob": 1.4307239837307861e-8
    },
    {
      "id": 842,
      "seek": 516634,
      "start": 5182.78,
      "end": 5186.78,
      "text": " Io per adesso non ho ancora fatto partite perché ho l'ansia della prestazione e della",
      "tokens": [
        19239,
        680,
        39552,
        2107,
        1106,
        30656,
        23228,
        644,
        642,
        14303,
        1106,
        287,
        6,
        599,
        654,
        11618,
        16305,
        12928,
        308,
        11618
      ],
      "temperature": 0,
      "avg_logprob": -0.29655009568339646,
      "compression_ratio": 1.5203619909502262,
      "no_speech_prob": 1.4307239837307861e-8
    },
    {
      "id": 843,
      "seek": 516634,
      "start": 5186.78,
      "end": 5194.860000000001,
      "text": " sindrome dell'impostore, però sto aumentando il mio livello almeno virtuale contro il computer,",
      "tokens": [
        3290,
        11505,
        19781,
        6,
        8814,
        555,
        418,
        11,
        12673,
        22784,
        17128,
        1806,
        1930,
        29908,
        1621,
        1913,
        419,
        43232,
        6374,
        68,
        1583,
        1930,
        3820,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.29655009568339646,
      "compression_ratio": 1.5203619909502262,
      "no_speech_prob": 1.4307239837307861e-8
    },
    {
      "id": 844,
      "seek": 519486,
      "start": 5194.86,
      "end": 5199.299999999999,
      "text": " perché se poi una partita ho fatto effettivamente ha funzionato parecchio, ho fatto alcune mosse",
      "tokens": [
        14303,
        369,
        19260,
        2002,
        644,
        2786,
        1106,
        23228,
        1244,
        3093,
        23957,
        324,
        49345,
        313,
        2513,
        7448,
        66,
        31033,
        11,
        1106,
        23228,
        20005,
        2613,
        13659,
        405
      ],
      "temperature": 0,
      "avg_logprob": -0.2736272583007813,
      "compression_ratio": 1.6538461538461537,
      "no_speech_prob": 3.7910417027831045e-9
    },
    {
      "id": 845,
      "seek": 519486,
      "start": 5199.299999999999,
      "end": 5205.98,
      "text": " che erano… ero veramente orgoglioso delle mosse che avevo fatto.",
      "tokens": [
        947,
        1189,
        3730,
        1260,
        1189,
        78,
        50079,
        14045,
        664,
        2081,
        9869,
        16485,
        13659,
        405,
        947,
        3472,
        3080,
        23228,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2736272583007813,
      "compression_ratio": 1.6538461538461537,
      "no_speech_prob": 3.7910417027831045e-9
    },
    {
      "id": 846,
      "seek": 519486,
      "start": 5205.98,
      "end": 5211.42,
      "text": " Il secondo balocco è un piccolo libricino che probabilmente ho già baloccato ma me",
      "tokens": [
        4416,
        41601,
        3119,
        905,
        1291,
        4873,
        517,
        13363,
        46086,
        22854,
        1341,
        2982,
        947,
        31959,
        4082,
        1106,
        30469,
        3119,
        43280,
        2513,
        463,
        385
      ],
      "temperature": 0,
      "avg_logprob": -0.2736272583007813,
      "compression_ratio": 1.6538461538461537,
      "no_speech_prob": 3.7910417027831045e-9
    },
    {
      "id": 847,
      "seek": 519486,
      "start": 5211.42,
      "end": 5216.259999999999,
      "text": " lo trovavo davanti adesso, ho detto perché no, si chiama Mentire con le statistiche di",
      "tokens": [
        450,
        35449,
        25713,
        11753,
        11520,
        39552,
        11,
        1106,
        41031,
        14303,
        572,
        11,
        1511,
        13228,
        2404,
        33140,
        621,
        416,
        476,
        16012,
        9304,
        1026
      ],
      "temperature": 0,
      "avg_logprob": -0.2736272583007813,
      "compression_ratio": 1.6538461538461537,
      "no_speech_prob": 3.7910417027831045e-9
    },
    {
      "id": 848,
      "seek": 519486,
      "start": 5216.259999999999,
      "end": 5224.62,
      "text": " Darrell Huff, lo si trova anche in italiano, appunto insegna come mentire con le statistiche",
      "tokens": [
        7803,
        19771,
        389,
        1245,
        11,
        450,
        1511,
        4495,
        2757,
        11585,
        294,
        48486,
        11,
        724,
        24052,
        33874,
        70,
        629,
        808,
        3074,
        621,
        416,
        476,
        16012,
        9304
      ],
      "temperature": 0,
      "avg_logprob": -0.2736272583007813,
      "compression_ratio": 1.6538461538461537,
      "no_speech_prob": 3.7910417027831045e-9
    },
    {
      "id": 849,
      "seek": 522462,
      "start": 5224.62,
      "end": 5235.0599999999995,
      "text": " in questo caso per difenderti da chi cerca di rifilarti statistiche vere ma false, quindi",
      "tokens": [
        294,
        10263,
        9666,
        680,
        679,
        521,
        911,
        72,
        1120,
        13228,
        26770,
        1026,
        13203,
        388,
        40155,
        16012,
        9304,
        16443,
        463,
        7908,
        11,
        15727
      ],
      "temperature": 0,
      "avg_logprob": -0.23883679269374103,
      "compression_ratio": 1.5309278350515463,
      "no_speech_prob": 3.12498720234089e-8
    },
    {
      "id": 850,
      "seek": 522462,
      "start": 5235.0599999999995,
      "end": 5243.14,
      "text": " statistiche basate su dati veri ma presentati in modo che ti sembrano quello che in realtà",
      "tokens": [
        16012,
        9304,
        987,
        473,
        459,
        1137,
        72,
        1306,
        72,
        463,
        1974,
        6908,
        294,
        16664,
        947,
        8757,
        4361,
        1443,
        3730,
        22813,
        947,
        294,
        47512
      ],
      "temperature": 0,
      "avg_logprob": -0.23883679269374103,
      "compression_ratio": 1.5309278350515463,
      "no_speech_prob": 3.12498720234089e-8
    },
    {
      "id": 851,
      "seek": 522462,
      "start": 5243.14,
      "end": 5244.14,
      "text": " non sono.",
      "tokens": [
        2107,
        9259,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.23883679269374103,
      "compression_ratio": 1.5309278350515463,
      "no_speech_prob": 3.12498720234089e-8
    },
    {
      "id": 852,
      "seek": 522462,
      "start": 5244.14,
      "end": 5250.34,
      "text": " C'è quel famoso esempio che era il film di Nicolas Cage correlato alle morti per annegamento",
      "tokens": [
        383,
        6,
        1462,
        7178,
        49526,
        33627,
        947,
        4249,
        1930,
        2007,
        1026,
        38268,
        48677,
        13983,
        2513,
        5430,
        6599,
        72,
        680,
        22256,
        70,
        8824
      ],
      "temperature": 0,
      "avg_logprob": -0.23883679269374103,
      "compression_ratio": 1.5309278350515463,
      "no_speech_prob": 3.12498720234089e-8
    },
    {
      "id": 853,
      "seek": 522462,
      "start": 5250.34,
      "end": 5251.34,
      "text": " in piscina?",
      "tokens": [
        294,
        280,
        5606,
        1426,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.23883679269374103,
      "compression_ratio": 1.5309278350515463,
      "no_speech_prob": 3.12498720234089e-8
    },
    {
      "id": 854,
      "seek": 525134,
      "start": 5251.34,
      "end": 5258.5,
      "text": " Sì anche quello ma anche come proprio vengono banalmente disegnati i grafici prendendo come",
      "tokens": [
        318,
        4749,
        11585,
        22813,
        463,
        11585,
        808,
        28203,
        371,
        1501,
        8957,
        5643,
        304,
        4082,
        717,
        1146,
        77,
        6908,
        741,
        1295,
        1786,
        72,
        9866,
        3999,
        808
      ],
      "temperature": 0,
      "avg_logprob": -0.21192047812721945,
      "compression_ratio": 1.5172413793103448,
      "no_speech_prob": 6.758260617800715e-9
    },
    {
      "id": 855,
      "seek": 525134,
      "start": 5258.5,
      "end": 5266.18,
      "text": " origine non lo zero ma il punto più alto oppure quando si gioca con le proporzioni",
      "tokens": [
        2349,
        533,
        2107,
        450,
        4018,
        463,
        1930,
        14326,
        10589,
        21275,
        1458,
        540,
        7770,
        1511,
        48508,
        496,
        416,
        476,
        41516,
        89,
        15273
      ],
      "temperature": 0,
      "avg_logprob": -0.21192047812721945,
      "compression_ratio": 1.5172413793103448,
      "no_speech_prob": 6.758260617800715e-9
    },
    {
      "id": 856,
      "seek": 525134,
      "start": 5266.18,
      "end": 5272.62,
      "text": " sui volumi invece che sulle aree, insomma tante cose di questo tipo oppure anche quando",
      "tokens": [
        459,
        72,
        1996,
        17800,
        36344,
        947,
        459,
        2447,
        366,
        68,
        11,
        1028,
        30243,
        256,
        2879,
        30261,
        1026,
        10263,
        9746,
        1458,
        540,
        11585,
        7770
      ],
      "temperature": 0,
      "avg_logprob": -0.21192047812721945,
      "compression_ratio": 1.5172413793103448,
      "no_speech_prob": 6.758260617800715e-9
    },
    {
      "id": 857,
      "seek": 527262,
      "start": 5272.62,
      "end": 5284.5,
      "text": " ti presentano dati, i sondaggi omettendo la base campione e quindi ti spiega proprio su",
      "tokens": [
        8757,
        1974,
        3730,
        1137,
        72,
        11,
        741,
        262,
        684,
        46893,
        3406,
        3093,
        3999,
        635,
        3096,
        2255,
        5328,
        308,
        15727,
        8757,
        637,
        414,
        3680,
        28203,
        459
      ],
      "temperature": 0,
      "avg_logprob": -0.20953716951258042,
      "compression_ratio": 1.65,
      "no_speech_prob": 3.046187080357754e-9
    },
    {
      "id": 858,
      "seek": 527262,
      "start": 5284.5,
      "end": 5292.38,
      "text": " esempi reali, su esempi di giornali negli ultimi anni, in realtà negli ultimi decenni, ti",
      "tokens": [
        32340,
        72,
        957,
        72,
        11,
        459,
        32340,
        72,
        1026,
        36937,
        5103,
        2485,
        2081,
        3725,
        10121,
        31164,
        11,
        294,
        47512,
        2485,
        2081,
        3725,
        10121,
        979,
        1857,
        72,
        11,
        8757
      ],
      "temperature": 0,
      "avg_logprob": -0.20953716951258042,
      "compression_ratio": 1.65,
      "no_speech_prob": 3.046187080357754e-9
    },
    {
      "id": 859,
      "seek": 527262,
      "start": 5292.38,
      "end": 5301.22,
      "text": " apre gli occhi e ti fa leggere la realtà in modo diverso, la realtà che ti vogliono",
      "tokens": [
        1882,
        265,
        17161,
        10409,
        8036,
        308,
        8757,
        2050,
        30991,
        323,
        635,
        47512,
        294,
        16664,
        18558,
        539,
        11,
        635,
        47512,
        947,
        8757,
        31273,
        75,
        49020
      ],
      "temperature": 0,
      "avg_logprob": -0.20953716951258042,
      "compression_ratio": 1.65,
      "no_speech_prob": 3.046187080357754e-9
    },
    {
      "id": 860,
      "seek": 530122,
      "start": 5301.22,
      "end": 5302.780000000001,
      "text": " appropinare in modo diverso.",
      "tokens": [
        724,
        1513,
        259,
        543,
        294,
        16664,
        18558,
        539,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.3808205863025701,
      "compression_ratio": 1.5779816513761469,
      "no_speech_prob": 3.927856084828818e-7
    },
    {
      "id": 861,
      "seek": 530122,
      "start": 5302.780000000001,
      "end": 5309.860000000001,
      "text": " Comunque era carina l'introduzione che hai fatto quando hai detto serve per difendersi,",
      "tokens": [
        2432,
        409,
        1077,
        4249,
        1032,
        1426,
        287,
        6,
        38132,
        19706,
        947,
        21822,
        23228,
        7770,
        21822,
        41031,
        4596,
        680,
        679,
        16292,
        72,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.3808205863025701,
      "compression_ratio": 1.5779816513761469,
      "no_speech_prob": 3.927856084828818e-7
    },
    {
      "id": 862,
      "seek": 530122,
      "start": 5309.860000000001,
      "end": 5314.5,
      "text": " sembrava un po' il disclaimer che c'è in buona parte degli scriptini, degli script",
      "tokens": [
        20775,
        424,
        2757,
        517,
        714,
        6,
        1930,
        40896,
        947,
        269,
        6,
        1462,
        294,
        758,
        4037,
        6975,
        32079,
        5755,
        3812,
        11,
        32079,
        5755
      ],
      "temperature": 0,
      "avg_logprob": -0.3808205863025701,
      "compression_ratio": 1.5779816513761469,
      "no_speech_prob": 3.927856084828818e-7
    },
    {
      "id": 863,
      "seek": 530122,
      "start": 5314.5,
      "end": 5320.5,
      "text": " kiddies che dice questo script è fatto solo a scopo educativo, non utilizzatelo!",
      "tokens": [
        1636,
        22018,
        947,
        10313,
        10263,
        5755,
        4873,
        23228,
        6944,
        257,
        795,
        404,
        78,
        2400,
        18586,
        11,
        2107,
        40355,
        267,
        10590,
        0
      ],
      "temperature": 0,
      "avg_logprob": -0.3808205863025701,
      "compression_ratio": 1.5779816513761469,
      "no_speech_prob": 3.927856084828818e-7
    },
    {
      "id": 864,
      "seek": 530122,
      "start": 5320.5,
      "end": 5323.1,
      "text": " Quante volte l'abbiamo visto?",
      "tokens": [
        2326,
        2879,
        37801,
        287,
        6,
        10797,
        7415,
        17558,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.3808205863025701,
      "compression_ratio": 1.5779816513761469,
      "no_speech_prob": 3.927856084828818e-7
    },
    {
      "id": 865,
      "seek": 530122,
      "start": 5323.1,
      "end": 5326.900000000001,
      "text": " Quante volte l'abbiamo scritto?",
      "tokens": [
        2326,
        2879,
        37801,
        287,
        6,
        10797,
        7415,
        5918,
        34924,
        30
      ],
      "temperature": 0,
      "avg_logprob": -0.3808205863025701,
      "compression_ratio": 1.5779816513761469,
      "no_speech_prob": 3.927856084828818e-7
    },
    {
      "id": 866,
      "seek": 532690,
      "start": 5326.9,
      "end": 5334.86,
      "text": " Questo repository è fatto solo a scopo educativo e magari sono una roba per utilizzare le API",
      "tokens": [
        38167,
        25841,
        4873,
        23228,
        6944,
        257,
        795,
        404,
        78,
        2400,
        18586,
        308,
        49932,
        9259,
        2002,
        3870,
        64,
        680,
        40355,
        543,
        476,
        9362
      ],
      "temperature": 0,
      "avg_logprob": -0.29151729236949575,
      "compression_ratio": 1.5829787234042554,
      "no_speech_prob": 2.4720696600866177e-8
    },
    {
      "id": 867,
      "seek": 532690,
      "start": 5334.86,
      "end": 5341.58,
      "text": " di Grammarly che non sono pubbliche, però è solo a scopo educativo, cito Grammarly",
      "tokens": [
        1026,
        22130,
        6209,
        356,
        947,
        2107,
        9259,
        1535,
        65,
        10185,
        11,
        12673,
        4873,
        6944,
        257,
        795,
        404,
        78,
        2400,
        18586,
        11,
        269,
        3528,
        22130,
        6209,
        356
      ],
      "temperature": 0,
      "avg_logprob": -0.29151729236949575,
      "compression_ratio": 1.5829787234042554,
      "no_speech_prob": 2.4720696600866177e-8
    },
    {
      "id": 868,
      "seek": 532690,
      "start": 5341.58,
      "end": 5345.339999999999,
      "text": " non a caso perché io tipo con le API sono un paio d'anni che le uso e finalmente ce",
      "tokens": [
        2107,
        257,
        9666,
        14303,
        19785,
        9746,
        416,
        476,
        9362,
        9259,
        517,
        2502,
        1004,
        274,
        6,
        35832,
        947,
        476,
        22728,
        308,
        35577,
        1769
      ],
      "temperature": 0,
      "avg_logprob": -0.29151729236949575,
      "compression_ratio": 1.5829787234042554,
      "no_speech_prob": 2.4720696600866177e-8
    },
    {
      "id": 869,
      "seek": 532690,
      "start": 5345.339999999999,
      "end": 5346.339999999999,
      "text": " le hanno aperte.",
      "tokens": [
        476,
        26595,
        43139,
        975,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.29151729236949575,
      "compression_ratio": 1.5829787234042554,
      "no_speech_prob": 2.4720696600866177e-8
    },
    {
      "id": 870,
      "seek": 532690,
      "start": 5346.339999999999,
      "end": 5351.82,
      "text": " E allora proprio così introduco il mio balocco, vi devo dire una cosa, in una settimana e",
      "tokens": [
        462,
        44141,
        28203,
        23278,
        2814,
        1291,
        1930,
        29908,
        3119,
        905,
        1291,
        11,
        1932,
        49717,
        1264,
        2002,
        10163,
        11,
        294,
        2002,
        5584,
        36497,
        308
      ],
      "temperature": 0,
      "avg_logprob": -0.29151729236949575,
      "compression_ratio": 1.5829787234042554,
      "no_speech_prob": 2.4720696600866177e-8
    },
    {
      "id": 871,
      "seek": 535182,
      "start": 5351.82,
      "end": 5357.099999999999,
      "text": " mezzo questo è il quinto episodio che registriamo, quindi potrei essere a corto di balocchi ma",
      "tokens": [
        385,
        35130,
        10263,
        4873,
        1930,
        421,
        17246,
        39200,
        1004,
        947,
        11376,
        470,
        10502,
        11,
        15727,
        1847,
        10271,
        19799,
        257,
        11278,
        78,
        1026,
        3119,
        905,
        8036,
        463
      ],
      "temperature": 0,
      "avg_logprob": -0.2549275515372293,
      "compression_ratio": 1.5217391304347827,
      "no_speech_prob": 1.1496189777915333e-8
    },
    {
      "id": 872,
      "seek": 535182,
      "start": 5357.099999999999,
      "end": 5358.74,
      "text": " ne ho tre!",
      "tokens": [
        408,
        1106,
        2192,
        0
      ],
      "temperature": 0,
      "avg_logprob": -0.2549275515372293,
      "compression_ratio": 1.5217391304347827,
      "no_speech_prob": 1.1496189777915333e-8
    },
    {
      "id": 873,
      "seek": 535182,
      "start": 5358.74,
      "end": 5366.179999999999,
      "text": " Il primo è Grammarly, se non l'avete provato provatelo, se siete delle capre con l'inglese,",
      "tokens": [
        4416,
        38671,
        4873,
        22130,
        6209,
        356,
        11,
        369,
        2107,
        287,
        6,
        706,
        3498,
        1439,
        2513,
        1439,
        267,
        10590,
        11,
        369,
        40719,
        16485,
        1410,
        265,
        416,
        287,
        6,
        278,
        904,
        68,
        11
      ],
      "temperature": 0,
      "avg_logprob": -0.2549275515372293,
      "compression_ratio": 1.5217391304347827,
      "no_speech_prob": 1.1496189777915333e-8
    },
    {
      "id": 874,
      "seek": 535182,
      "start": 5366.179999999999,
      "end": 5371.42,
      "text": " amici miei siete come me, utilizzatelo perché aiuta tantissimo.",
      "tokens": [
        669,
        8787,
        12597,
        72,
        40719,
        808,
        385,
        11,
        40355,
        267,
        10590,
        14303,
        9783,
        12093,
        12095,
        34966,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2549275515372293,
      "compression_ratio": 1.5217391304347827,
      "no_speech_prob": 1.1496189777915333e-8
    },
    {
      "id": 875,
      "seek": 535182,
      "start": 5371.42,
      "end": 5378.86,
      "text": " La cosa veramente figa di Grammarly è che hanno rilasciato da poco le API, quindi se",
      "tokens": [
        2369,
        10163,
        50079,
        2147,
        64,
        1026,
        22130,
        6209,
        356,
        4873,
        947,
        26595,
        367,
        388,
        296,
        537,
        2513,
        1120,
        10639,
        476,
        9362,
        11,
        15727,
        369
      ],
      "temperature": 0,
      "avg_logprob": -0.2549275515372293,
      "compression_ratio": 1.5217391304347827,
      "no_speech_prob": 1.1496189777915333e-8
    },
    {
      "id": 876,
      "seek": 537886,
      "start": 5378.86,
      "end": 5387.5,
      "text": " fate un'iscrizione subscribe pagante che costa attorno ai centinaio di euro l'anno, quindi",
      "tokens": [
        12738,
        517,
        6,
        271,
        1142,
        19706,
        2090,
        8056,
        11812,
        2879,
        947,
        2063,
        64,
        951,
        21998,
        9783,
        1489,
        1426,
        1004,
        1026,
        14206,
        287,
        6,
        13484,
        11,
        15727
      ],
      "temperature": 0,
      "avg_logprob": -0.30360924756085433,
      "compression_ratio": 1.5663716814159292,
      "no_speech_prob": 3.6174367945562835e-9
    },
    {
      "id": 877,
      "seek": 537886,
      "start": 5387.5,
      "end": 5392.0199999999995,
      "text": " poco meno di 10 euro al mese, veramente poco per quello che ti da, cioè ti evita di fare",
      "tokens": [
        10639,
        40236,
        1026,
        1266,
        14206,
        419,
        275,
        1130,
        11,
        50079,
        10639,
        680,
        22813,
        947,
        8757,
        1120,
        11,
        41827,
        8757,
        1073,
        2786,
        1026,
        11994
      ],
      "temperature": 0,
      "avg_logprob": -0.30360924756085433,
      "compression_ratio": 1.5663716814159292,
      "no_speech_prob": 3.6174367945562835e-9
    },
    {
      "id": 878,
      "seek": 537886,
      "start": 5392.0199999999995,
      "end": 5398.219999999999,
      "text": " figure di merda fondamentalmente, è molto utile e la cosa figa è che vi dà tipo c'è",
      "tokens": [
        2573,
        1026,
        3551,
        2675,
        9557,
        44538,
        4082,
        11,
        4873,
        16394,
        2839,
        794,
        308,
        635,
        10163,
        2147,
        64,
        4873,
        947,
        1932,
        274,
        1467,
        9746,
        269,
        6,
        1462
      ],
      "temperature": 0,
      "avg_logprob": -0.30360924756085433,
      "compression_ratio": 1.5663716814159292,
      "no_speech_prob": 3.6174367945562835e-9
    },
    {
      "id": 879,
      "seek": 537886,
      "start": 5398.219999999999,
      "end": 5403.0599999999995,
      "text": " un SDK che vi dà anche il componente React che ha già la correzione grammaticale di",
      "tokens": [
        517,
        37135,
        947,
        1932,
        274,
        1467,
        11585,
        1930,
        4026,
        1576,
        30644,
        947,
        324,
        30469,
        635,
        1181,
        17693,
        5328,
        17570,
        267,
        804,
        68,
        1026
      ],
      "temperature": 0,
      "avg_logprob": -0.30360924756085433,
      "compression_ratio": 1.5663716814159292,
      "no_speech_prob": 3.6174367945562835e-9
    },
    {
      "id": 880,
      "seek": 540306,
      "start": 5403.06,
      "end": 5409.860000000001,
      "text": " Grammarly e la cosa è parecchio figa perché la potete potete fare il vostro text editor",
      "tokens": [
        22130,
        6209,
        356,
        308,
        635,
        10163,
        4873,
        7448,
        66,
        31033,
        2147,
        64,
        14303,
        635,
        1847,
        3498,
        1847,
        3498,
        11994,
        1930,
        28944,
        340,
        2487,
        9839
      ],
      "temperature": 0,
      "avg_logprob": -0.24108979598335598,
      "compression_ratio": 1.5573770491803278,
      "no_speech_prob": 1.0467396727165124e-8
    },
    {
      "id": 881,
      "seek": 540306,
      "start": 5409.860000000001,
      "end": 5414.34,
      "text": " che è un po' quello che sto provando a fare io nel mio poco tempo libero, specifico per",
      "tokens": [
        947,
        4873,
        517,
        714,
        6,
        22813,
        947,
        22784,
        1439,
        1806,
        257,
        11994,
        19785,
        15373,
        29908,
        10639,
        8972,
        6774,
        78,
        11,
        2685,
        78,
        680
      ],
      "temperature": 0,
      "avg_logprob": -0.24108979598335598,
      "compression_ratio": 1.5573770491803278,
      "no_speech_prob": 1.0467396727165124e-8
    },
    {
      "id": 882,
      "seek": 540306,
      "start": 5414.34,
      "end": 5415.900000000001,
      "text": " il vostro caso d'uso.",
      "tokens": [
        1930,
        28944,
        340,
        9666,
        274,
        6,
        24431,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.24108979598335598,
      "compression_ratio": 1.5573770491803278,
      "no_speech_prob": 1.0467396727165124e-8
    },
    {
      "id": 883,
      "seek": 540306,
      "start": 5415.900000000001,
      "end": 5422.9400000000005,
      "text": " Questo è il primo balocco, il secondo balocco colgo l'occasione insomma dell'introduzione",
      "tokens": [
        38167,
        4873,
        1930,
        38671,
        3119,
        905,
        1291,
        11,
        1930,
        41601,
        3119,
        905,
        1291,
        1173,
        1571,
        287,
        6,
        905,
        16369,
        5328,
        1028,
        30243,
        19781,
        6,
        38132,
        19706
      ],
      "temperature": 0,
      "avg_logprob": -0.24108979598335598,
      "compression_ratio": 1.5573770491803278,
      "no_speech_prob": 1.0467396727165124e-8
    },
    {
      "id": 884,
      "seek": 540306,
      "start": 5422.9400000000005,
      "end": 5429.740000000001,
      "text": " che ha fatto Luciano su Rust per dire che io sono abbastanza tonto e quindi sto leggendo",
      "tokens": [
        947,
        324,
        23228,
        37309,
        3730,
        459,
        34952,
        680,
        1264,
        947,
        19785,
        9259,
        16903,
        525,
        20030,
        256,
        7556,
        308,
        15727,
        22784,
        30991,
        3999
      ],
      "temperature": 0,
      "avg_logprob": -0.24108979598335598,
      "compression_ratio": 1.5573770491803278,
      "no_speech_prob": 1.0467396727165124e-8
    },
    {
      "id": 885,
      "seek": 542974,
      "start": 5429.74,
      "end": 5435.46,
      "text": " per la seconda volta Rust in Action, lo sto rileggendo perché secondo me è uno di quei",
      "tokens": [
        680,
        635,
        1150,
        64,
        18765,
        34952,
        294,
        16261,
        11,
        450,
        22784,
        367,
        794,
        1615,
        3999,
        14303,
        41601,
        385,
        4873,
        8526,
        1026,
        631,
        72
      ],
      "temperature": 0,
      "avg_logprob": -0.2635418741326583,
      "compression_ratio": 1.5688622754491017,
      "no_speech_prob": 1.2824916240106177e-8
    },
    {
      "id": 886,
      "seek": 542974,
      "start": 5435.46,
      "end": 5444.139999999999,
      "text": " libri che se lo si legge tutto ad un fiatto va riletto una seconda volta con molta più",
      "tokens": [
        22854,
        470,
        947,
        369,
        450,
        1511,
        1676,
        432,
        23048,
        614,
        517,
        15848,
        37491,
        2773,
        367,
        388,
        23778,
        2002,
        1150,
        64,
        18765,
        416,
        48564,
        10589
      ],
      "temperature": 0,
      "avg_logprob": -0.2635418741326583,
      "compression_ratio": 1.5688622754491017,
      "no_speech_prob": 1.2824916240106177e-8
    },
    {
      "id": 887,
      "seek": 542974,
      "start": 5444.139999999999,
      "end": 5452.7,
      "text": " calma e magari prendendo lo stimolo da là e andando al Rust book per andare poi più",
      "tokens": [
        2104,
        1696,
        308,
        49932,
        9866,
        3999,
        450,
        8983,
        7902,
        1120,
        3684,
        308,
        293,
        1806,
        419,
        34952,
        1446,
        680,
        42742,
        19260,
        10589
      ],
      "temperature": 0,
      "avg_logprob": -0.2635418741326583,
      "compression_ratio": 1.5688622754491017,
      "no_speech_prob": 1.2824916240106177e-8
    },
    {
      "id": 888,
      "seek": 545270,
      "start": 5452.7,
      "end": 5461.42,
      "text": " a fondo su alcuni concetti e sono ricapitato su un esempio, un blocco di codice sul quale",
      "tokens": [
        257,
        38101,
        459,
        20005,
        24307,
        1588,
        12495,
        308,
        9259,
        21040,
        569,
        270,
        2513,
        459,
        517,
        33627,
        11,
        517,
        1749,
        49552,
        1026,
        17656,
        573,
        17603,
        421,
        1220
      ],
      "temperature": 0,
      "avg_logprob": -0.18864899096281632,
      "compression_ratio": 1.5359116022099448,
      "no_speech_prob": 1.4993842611943364e-8
    },
    {
      "id": 889,
      "seek": 545270,
      "start": 5461.42,
      "end": 5470.46,
      "text": " ero andato molto veloce sopra che era la creazione di un grafico di Mandelbrot o Mandelbrot",
      "tokens": [
        1189,
        78,
        293,
        2513,
        16394,
        1241,
        752,
        384,
        370,
        43255,
        947,
        4249,
        635,
        1197,
        12928,
        1026,
        517,
        1295,
        1786,
        78,
        1026,
        15458,
        338,
        1443,
        310,
        277,
        15458,
        338,
        1443,
        310
      ],
      "temperature": 0,
      "avg_logprob": -0.18864899096281632,
      "compression_ratio": 1.5359116022099448,
      "no_speech_prob": 1.4993842611943364e-8
    },
    {
      "id": 890,
      "seek": 545270,
      "start": 5470.46,
      "end": 5478.139999999999,
      "text": " non so come si pronuncia però vedere quell'immagine mi ha riapperto un cassettino e sono andato",
      "tokens": [
        2107,
        370,
        808,
        1511,
        7569,
        409,
        2755,
        12673,
        35373,
        631,
        285,
        6,
        6753,
        10260,
        2752,
        324,
        367,
        654,
        427,
        13098,
        517,
        21943,
        3093,
        2982,
        308,
        9259,
        293,
        2513
      ],
      "temperature": 0,
      "avg_logprob": -0.18864899096281632,
      "compression_ratio": 1.5359116022099448,
      "no_speech_prob": 1.4993842611943364e-8
    },
    {
      "id": 891,
      "seek": 547814,
      "start": 5478.14,
      "end": 5484.62,
      "text": " nella libreria a cercare il libro in questione e il libro è Abbas e Euclide di Pier Giorgio",
      "tokens": [
        23878,
        4939,
        41568,
        257,
        10146,
        5685,
        1930,
        29354,
        294,
        1168,
        68,
        308,
        1930,
        29354,
        4873,
        2847,
        16342,
        308,
        462,
        1311,
        31264,
        1026,
        16676,
        460,
        1973,
        17862
      ],
      "temperature": 0,
      "avg_logprob": -0.2593072780892869,
      "compression_ratio": 1.7175925925925926,
      "no_speech_prob": 2.9356527875279426e-8
    },
    {
      "id": 892,
      "seek": 547814,
      "start": 5484.62,
      "end": 5492.22,
      "text": " Odifreddi che spiega proprio anche tra i vari concetti che spiega c'è proprio il concetto",
      "tokens": [
        422,
        4504,
        47613,
        4504,
        947,
        637,
        414,
        3680,
        28203,
        11585,
        944,
        741,
        3034,
        1588,
        12495,
        947,
        637,
        414,
        3680,
        269,
        6,
        1462,
        28203,
        1930,
        1588,
        23778
      ],
      "temperature": 0,
      "avg_logprob": -0.2593072780892869,
      "compression_ratio": 1.7175925925925926,
      "no_speech_prob": 2.9356527875279426e-8
    },
    {
      "id": 893,
      "seek": 547814,
      "start": 5492.22,
      "end": 5499.46,
      "text": " di Mandelbrot e di quant'altro quindi sono riandato a leggere il capitolino il paragraffetto",
      "tokens": [
        1026,
        15458,
        338,
        1443,
        310,
        308,
        1026,
        4426,
        6,
        47484,
        15727,
        9259,
        367,
        952,
        67,
        2513,
        257,
        30991,
        323,
        1930,
        33807,
        401,
        2982,
        1930,
        17372,
        424,
        602,
        23778
      ],
      "temperature": 0,
      "avg_logprob": -0.2593072780892869,
      "compression_ratio": 1.7175925925925926,
      "no_speech_prob": 2.9356527875279426e-8
    },
    {
      "id": 894,
      "seek": 547814,
      "start": 5499.46,
      "end": 5505.860000000001,
      "text": " di Abbas e Euclide di Odifreddi se non l'avete letto leggetelo giusto per fare una passeggiata",
      "tokens": [
        1026,
        2847,
        16342,
        308,
        462,
        1311,
        31264,
        1026,
        422,
        4504,
        47613,
        4504,
        369,
        2107,
        287,
        6,
        706,
        3498,
        718,
        1353,
        1676,
        847,
        10590,
        1735,
        48260,
        680,
        11994,
        2002,
        14530,
        22771,
        3274
      ],
      "temperature": 0,
      "avg_logprob": -0.2593072780892869,
      "compression_ratio": 1.7175925925925926,
      "no_speech_prob": 2.9356527875279426e-8
    },
    {
      "id": 895,
      "seek": 550586,
      "start": 5505.86,
      "end": 5514.7,
      "text": " in concetti che perlomeno io non avevo alcune idee di cosa potessero essere li vedevo come",
      "tokens": [
        294,
        1588,
        12495,
        947,
        680,
        75,
        4726,
        78,
        19785,
        2107,
        3472,
        3080,
        20005,
        2613,
        49742,
        1026,
        10163,
        1847,
        442,
        2032,
        19799,
        375,
        371,
        4858,
        3080,
        808
      ],
      "temperature": 0,
      "avg_logprob": -0.22508560527454724,
      "compression_ratio": 1.5480225988700564,
      "no_speech_prob": 3.911379664600645e-9
    },
    {
      "id": 896,
      "seek": 550586,
      "start": 5514.7,
      "end": 5523.94,
      "text": " delle robe astruse e Odifreddi nonostante abbia tanti limiti non mi stia troppo simpatico",
      "tokens": [
        16485,
        37213,
        5357,
        894,
        405,
        308,
        422,
        4504,
        47613,
        4504,
        2107,
        555,
        2879,
        16903,
        654,
        256,
        11520,
        4948,
        72,
        2107,
        2752,
        342,
        654,
        4495,
        27000,
        1034,
        79,
        2399,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.22508560527454724,
      "compression_ratio": 1.5480225988700564,
      "no_speech_prob": 3.911379664600645e-9
    },
    {
      "id": 897,
      "seek": 550586,
      "start": 5523.94,
      "end": 5530.82,
      "text": " in cui il libro veramente è riuscito a esprimere concetti abbastanza complessi in modo molto",
      "tokens": [
        294,
        22929,
        1930,
        29354,
        50079,
        4873,
        367,
        4872,
        32030,
        257,
        785,
        1424,
        332,
        323,
        1588,
        12495,
        16903,
        525,
        20030,
        1209,
        442,
        72,
        294,
        16664,
        16394
      ],
      "temperature": 0,
      "avg_logprob": -0.22508560527454724,
      "compression_ratio": 1.5480225988700564,
      "no_speech_prob": 3.911379664600645e-9
    },
    {
      "id": 898,
      "seek": 553082,
      "start": 5530.82,
      "end": 5537.219999999999,
      "text": " molto semplice e questo può essere un insegnamento anche in quello che facciamo all'interno del",
      "tokens": [
        16394,
        4361,
        564,
        573,
        308,
        10263,
        26526,
        19799,
        517,
        33874,
        4568,
        8824,
        11585,
        294,
        22813,
        947,
        1915,
        42052,
        439,
        6,
        5106,
        1771,
        1103
      ],
      "temperature": 0,
      "avg_logprob": -0.23083879947662353,
      "compression_ratio": 1.4972972972972973,
      "no_speech_prob": 1.1142485156767634e-8
    },
    {
      "id": 899,
      "seek": 553082,
      "start": 5537.219999999999,
      "end": 5547.46,
      "text": " podcast. Ultimo balocco è una roba strana dico strana non so ancora se figa o meno perché",
      "tokens": [
        7367,
        13,
        9523,
        6934,
        3119,
        905,
        1291,
        4873,
        2002,
        3870,
        64,
        1056,
        2095,
        274,
        2789,
        1056,
        2095,
        2107,
        370,
        30656,
        369,
        2147,
        64,
        277,
        40236,
        14303
      ],
      "temperature": 0,
      "avg_logprob": -0.23083879947662353,
      "compression_ratio": 1.4972972972972973,
      "no_speech_prob": 1.1142485156767634e-8
    },
    {
      "id": 900,
      "seek": 553082,
      "start": 5547.46,
      "end": 5553.74,
      "text": " oggi nella chat aziendale un collega che cito per nome che penso ci stia sentendo Matteo",
      "tokens": [
        34768,
        23878,
        5081,
        7883,
        1174,
        1220,
        517,
        1263,
        6335,
        947,
        269,
        3528,
        680,
        19003,
        947,
        48005,
        6983,
        342,
        654,
        2279,
        3999,
        47544,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.23083879947662353,
      "compression_ratio": 1.4972972972972973,
      "no_speech_prob": 1.1142485156767634e-8
    },
    {
      "id": 901,
      "seek": 555374,
      "start": 5553.74,
      "end": 5562.94,
      "text": " Pietro ha condiviso un link a un nuovo linguaggio di programmazione o almeno così pare abbastanza",
      "tokens": [
        41970,
        340,
        324,
        2224,
        592,
        19227,
        517,
        2113,
        257,
        517,
        49348,
        21766,
        30763,
        1026,
        37648,
        12928,
        277,
        419,
        43232,
        23278,
        7448,
        16903,
        525,
        20030
      ],
      "temperature": 0,
      "avg_logprob": -0.1704919905889602,
      "compression_ratio": 1.7444933920704846,
      "no_speech_prob": 1.4532544057033192e-8
    },
    {
      "id": 902,
      "seek": 555374,
      "start": 5562.94,
      "end": 5571.34,
      "text": " nuovo visto che ne esce praticamente una settimana si chiama wing ed è un linguaggio di programmazione",
      "tokens": [
        49348,
        17558,
        947,
        408,
        785,
        384,
        45734,
        2002,
        5584,
        36497,
        1511,
        13228,
        2404,
        11162,
        1257,
        4873,
        517,
        21766,
        30763,
        1026,
        37648,
        12928
      ],
      "temperature": 0,
      "avg_logprob": -0.1704919905889602,
      "compression_ratio": 1.7444933920704846,
      "no_speech_prob": 1.4532544057033192e-8
    },
    {
      "id": 903,
      "seek": 555374,
      "start": 5571.34,
      "end": 5579.0199999999995,
      "text": " che in qualche modo si propone di essere un linguaggio pensato per il cloud si sposa abbastanza",
      "tokens": [
        947,
        294,
        38737,
        16664,
        1511,
        2365,
        546,
        1026,
        19799,
        517,
        21766,
        30763,
        6099,
        2513,
        680,
        1930,
        4588,
        1511,
        637,
        6447,
        16903,
        525,
        20030
      ],
      "temperature": 0,
      "avg_logprob": -0.1704919905889602,
      "compression_ratio": 1.7444933920704846,
      "no_speech_prob": 1.4532544057033192e-8
    },
    {
      "id": 904,
      "seek": 555374,
      "start": 5579.0199999999995,
      "end": 5583.54,
      "text": " bene con l'episodio di oggi in realtà perché ci sono tutta una serie di metodi di funzionalità",
      "tokens": [
        2537,
        416,
        287,
        6,
        595,
        271,
        378,
        1004,
        1026,
        34768,
        294,
        47512,
        14303,
        6983,
        9259,
        3672,
        1328,
        2002,
        23030,
        1026,
        1131,
        30727,
        1026,
        49345,
        1966,
        12445
      ],
      "temperature": 0,
      "avg_logprob": -0.1704919905889602,
      "compression_ratio": 1.7444933920704846,
      "no_speech_prob": 1.4532544057033192e-8
    },
    {
      "id": 905,
      "seek": 558354,
      "start": 5583.54,
      "end": 5592.78,
      "text": " che triggerano attivano delle AWS lambda fanno fanno delle robe la cosa veramente particolare",
      "tokens": [
        947,
        7875,
        3730,
        951,
        592,
        3730,
        16485,
        17650,
        13607,
        283,
        13484,
        283,
        13484,
        16485,
        37213,
        635,
        10163,
        50079,
        1276,
        43141
      ],
      "temperature": 0,
      "avg_logprob": -0.23092577012918764,
      "compression_ratio": 1.6331877729257642,
      "no_speech_prob": 1.876701904990341e-9
    },
    {
      "id": 906,
      "seek": 558354,
      "start": 5592.78,
      "end": 5596.98,
      "text": " che ho visto nell'esempio non ci ho dedicato troppo tempo però c'è una cosa che ha catturato",
      "tokens": [
        947,
        1106,
        17558,
        44666,
        6,
        279,
        15970,
        1004,
        2107,
        6983,
        1106,
        37071,
        2513,
        4495,
        27000,
        8972,
        12673,
        269,
        6,
        1462,
        2002,
        10163,
        947,
        324,
        269,
        1591,
        374,
        2513
      ],
      "temperature": 0,
      "avg_logprob": -0.23092577012918764,
      "compression_ratio": 1.6331877729257642,
      "no_speech_prob": 1.876701904990341e-9
    },
    {
      "id": 907,
      "seek": 558354,
      "start": 5596.98,
      "end": 5603.42,
      "text": " la mia attenzione è che in mezzo al codice di infrastruttura immaginiamolo come il codice",
      "tokens": [
        635,
        21290,
        951,
        11368,
        5328,
        4873,
        947,
        294,
        385,
        35130,
        419,
        17656,
        573,
        1026,
        6534,
        81,
        13478,
        2991,
        3397,
        559,
        259,
        2918,
        7902,
        808,
        1930,
        17656,
        573
      ],
      "temperature": 0,
      "avg_logprob": -0.23092577012918764,
      "compression_ratio": 1.6331877729257642,
      "no_speech_prob": 1.876701904990341e-9
    },
    {
      "id": 908,
      "seek": 558354,
      "start": 5603.42,
      "end": 5613.0199999999995,
      "text": " cdk c'è una puntata registrata con leo qualche eone fa dove parlavamo di cdk per immaginatelo",
      "tokens": [
        269,
        67,
        74,
        269,
        6,
        1462,
        2002,
        18212,
        3274,
        11376,
        81,
        3274,
        416,
        476,
        78,
        38737,
        308,
        546,
        2050,
        23287,
        13734,
        706,
        10502,
        1026,
        269,
        67,
        74,
        680,
        3397,
        559,
        259,
        267,
        10590
      ],
      "temperature": 0,
      "avg_logprob": -0.23092577012918764,
      "compression_ratio": 1.6331877729257642,
      "no_speech_prob": 1.876701904990341e-9
    },
    {
      "id": 909,
      "seek": 561302,
      "start": 5613.02,
      "end": 5622.3,
      "text": " come del codice cdk che è una sorta di cloud formation in typescript ma dove dentro c'è",
      "tokens": [
        808,
        1103,
        17656,
        573,
        269,
        67,
        74,
        947,
        4873,
        2002,
        33425,
        1026,
        4588,
        11723,
        294,
        3467,
        5944,
        463,
        23287,
        10856,
        269,
        6,
        1462
      ],
      "temperature": 0,
      "avg_logprob": -0.21636290550231935,
      "compression_ratio": 1.5,
      "no_speech_prob": 2.952465827377182e-9
    },
    {
      "id": 910,
      "seek": 561302,
      "start": 5622.3,
      "end": 5629.42,
      "text": " anche della business logic questa cosa mi ha mandato tipo in buffer overflow e non riesco",
      "tokens": [
        11585,
        11618,
        1606,
        9952,
        16540,
        10163,
        2752,
        324,
        7411,
        2513,
        9746,
        294,
        21762,
        37772,
        308,
        2107,
        23932,
        1291
      ],
      "temperature": 0,
      "avg_logprob": -0.21636290550231935,
      "compression_ratio": 1.5,
      "no_speech_prob": 2.952465827377182e-9
    },
    {
      "id": 911,
      "seek": 561302,
      "start": 5629.42,
      "end": 5638.22,
      "text": " a capire se è una roba fighissima o schifosissima per cui ditemelo voi insomma nel gruppo telegram",
      "tokens": [
        257,
        1410,
        621,
        369,
        4873,
        2002,
        3870,
        64,
        2147,
        71,
        891,
        4775,
        277,
        956,
        351,
        329,
        891,
        4775,
        680,
        22929,
        6176,
        443,
        10590,
        20931,
        1028,
        30243,
        15373,
        47477,
        78,
        4304,
        1342
      ],
      "temperature": 0,
      "avg_logprob": -0.21636290550231935,
      "compression_ratio": 1.5,
      "no_speech_prob": 2.952465827377182e-9
    },
    {
      "id": 912,
      "seek": 563822,
      "start": 5638.22,
      "end": 5644.14,
      "text": " senza dubbio ha senso anche solo per farci questo tipo di domanda buttarci un occhio.",
      "tokens": [
        36208,
        18540,
        65,
        1004,
        324,
        3151,
        539,
        11585,
        6944,
        680,
        1400,
        537,
        10263,
        9746,
        1026,
        3285,
        5575,
        6660,
        289,
        537,
        517,
        10409,
        31033,
        13
      ],
      "temperature": 0,
      "avg_logprob": -0.2212707001028709,
      "compression_ratio": 1.7203791469194314,
      "no_speech_prob": 2.419884026494401e-7
    },
    {
      "id": 913,
      "seek": 563822,
      "start": 5644.14,
      "end": 5653.5,
      "text": " Come sempre ragazzi io non so perché vengo sempre messo in mezzo in questa cosa probabilmente",
      "tokens": [
        2492,
        9553,
        17539,
        33910,
        19785,
        2107,
        370,
        14303,
        371,
        30362,
        9553,
        2082,
        78,
        294,
        385,
        35130,
        294,
        16540,
        10163,
        31959,
        4082
      ],
      "temperature": 0,
      "avg_logprob": -0.2212707001028709,
      "compression_ratio": 1.7203791469194314,
      "no_speech_prob": 2.419884026494401e-7
    },
    {
      "id": 914,
      "seek": 563822,
      "start": 5653.5,
      "end": 5658.3,
      "text": " perché sono l'unico che non si vergogna a parlare di soldi ma non vedo perché vergognarsi",
      "tokens": [
        14303,
        9259,
        287,
        6,
        409,
        2789,
        947,
        2107,
        1511,
        20209,
        664,
        629,
        257,
        13734,
        543,
        1026,
        3718,
        72,
        463,
        2107,
        14267,
        78,
        14303,
        20209,
        2912,
        32742
      ],
      "temperature": 0,
      "avg_logprob": -0.2212707001028709,
      "compression_ratio": 1.7203791469194314,
      "no_speech_prob": 2.419884026494401e-7
    },
    {
      "id": 915,
      "seek": 563822,
      "start": 5658.3,
      "end": 5664.42,
      "text": " è una cosa così bella parlare di soldi perché i soldi sono veramente la cosa più bella",
      "tokens": [
        4873,
        2002,
        10163,
        23278,
        312,
        3505,
        13734,
        543,
        1026,
        3718,
        72,
        14303,
        741,
        3718,
        72,
        9259,
        50079,
        635,
        10163,
        10589,
        312,
        3505
      ],
      "temperature": 0,
      "avg_logprob": -0.2212707001028709,
      "compression_ratio": 1.7203791469194314,
      "no_speech_prob": 2.419884026494401e-7
    },
    {
      "id": 916,
      "seek": 566442,
      "start": 5664.42,
      "end": 5671.26,
      "text": " del mondo quindi donate perché dobbiamo fare cena da massimo bottura con i vostri soldi",
      "tokens": [
        1103,
        40499,
        15727,
        17751,
        14303,
        360,
        6692,
        7415,
        11994,
        41777,
        1120,
        2758,
        6934,
        2274,
        2991,
        416,
        741,
        28944,
        470,
        3718,
        72
      ],
      "temperature": 0,
      "avg_logprob": -0.2208805606789785,
      "compression_ratio": 1.6484848484848484,
      "no_speech_prob": 1.7805648511171057e-8
    },
    {
      "id": 917,
      "seek": 566442,
      "start": 5671.26,
      "end": 5680.78,
      "text": " quindi è una cosa molto importante e siamo molto poveri quindi donate copiosamente veramente",
      "tokens": [
        15727,
        4873,
        2002,
        10163,
        16394,
        9416,
        308,
        33459,
        16394,
        714,
        331,
        72,
        15727,
        17751,
        2971,
        2717,
        3439,
        50079
      ],
      "temperature": 0,
      "avg_logprob": -0.2208805606789785,
      "compression_ratio": 1.6484848484848484,
      "no_speech_prob": 1.7805648511171057e-8
    },
    {
      "id": 918,
      "seek": 566442,
      "start": 5680.78,
      "end": 5688.38,
      "text": " in tantissimi mi raccomando dateci i vostri soldi e noi ne faremo l'uso più responsabile",
      "tokens": [
        294,
        12095,
        891,
        10121,
        2752,
        4129,
        1112,
        1806,
        4002,
        537,
        741,
        28944,
        470,
        3718,
        72,
        308,
        22447,
        408,
        11994,
        3280,
        287,
        6,
        24431,
        10589,
        2914,
        33288
      ],
      "temperature": 0,
      "avg_logprob": -0.2208805606789785,
      "compression_ratio": 1.6484848484848484,
      "no_speech_prob": 1.7805648511171057e-8
    },
    {
      "id": 919,
      "seek": 568838,
      "start": 5688.38,
      "end": 5694.82,
      "text": " che se ne possa fare ovvero metterli su delle crypto uscite da mezz'ora.",
      "tokens": [
        50364,
        947,
        369,
        408,
        41564,
        11994,
        14187,
        39332,
        1131,
        391,
        2081,
        459,
        16485,
        17240,
        505,
        66,
        642,
        1120,
        385,
        4313,
        6,
        3252,
        13,
        50686
      ],
      "temperature": 0,
      "avg_logprob": -0.3415663528442383,
      "compression_ratio": 1.0285714285714285,
      "no_speech_prob": 1.4449780394443223e-7
    },
    {
      "id": 920,
      "seek": 571838,
      "start": 5719.38,
      "end": 5729.1,
      "text": " è il momento di ringraziare i nostri donatori questa settimana abbiamo il primo donatore",
      "tokens": [
        4873,
        1930,
        9333,
        1026,
        4875,
        424,
        3992,
        543,
        741,
        10397,
        470,
        500,
        39842,
        16540,
        5584,
        36497,
        22815,
        1930,
        38671,
        500,
        43148
      ],
      "temperature": 0,
      "avg_logprob": -0.22432071215485874,
      "compression_ratio": 1.5662650602409638,
      "no_speech_prob": 0.4053117334842682
    },
    {
      "id": 921,
      "seek": 571838,
      "start": 5729.1,
      "end": 5736.14,
      "text": " del 2023 che ringraziamo e tra l'altro è anche anonimo anche se noi sappiamo chi è",
      "tokens": [
        1103,
        44377,
        947,
        4875,
        30695,
        7415,
        308,
        944,
        287,
        6,
        47484,
        4873,
        11585,
        364,
        266,
        6934,
        11585,
        369,
        22447,
        46938,
        7415,
        13228,
        4873
      ],
      "temperature": 0,
      "avg_logprob": -0.22432071215485874,
      "compression_ratio": 1.5662650602409638,
      "no_speech_prob": 0.4053117334842682
    },
    {
      "id": 922,
      "seek": 571838,
      "start": 5736.14,
      "end": 5742.82,
      "text": " quindi sappiamo chi sei scherzo grazie per gli interessanti contenuti che ci regalate",
      "tokens": [
        15727,
        46938,
        7415,
        13228,
        10842,
        956,
        260,
        4765,
        1295,
        3283,
        680,
        17161,
        12478,
        11520,
        21795,
        29161,
        947,
        6983,
        1121,
        304,
        473
      ],
      "temperature": 0,
      "avg_logprob": -0.22432071215485874,
      "compression_ratio": 1.5662650602409638,
      "no_speech_prob": 0.4053117334842682
    },
    {
      "id": 923,
      "seek": 574282,
      "start": 5742.82,
      "end": 5749.5,
      "text": " grazie a te caro anonimo anche perché sei il primo donatore di questo nuovo anno che",
      "tokens": [
        1295,
        3283,
        257,
        535,
        1032,
        78,
        364,
        266,
        6934,
        11585,
        14303,
        10842,
        1930,
        38671,
        500,
        43148,
        1026,
        10263,
        49348,
        46277,
        947
      ],
      "temperature": 0,
      "avg_logprob": -0.20685275395711264,
      "compression_ratio": 1.6418604651162791,
      "no_speech_prob": 3.0288415331369833e-8
    },
    {
      "id": 924,
      "seek": 574282,
      "start": 5749.5,
      "end": 5755.86,
      "text": " abbiamo aperto con una decisione anche abbastanza forte che è stata quella di rimuovere le",
      "tokens": [
        22815,
        43139,
        1353,
        416,
        2002,
        3537,
        68,
        11585,
        16903,
        525,
        20030,
        23235,
        947,
        4873,
        49554,
        32234,
        1026,
        15982,
        84,
        5179,
        323,
        476
      ],
      "temperature": 0,
      "avg_logprob": -0.20685275395711264,
      "compression_ratio": 1.6418604651162791,
      "no_speech_prob": 3.0288415331369833e-8
    },
    {
      "id": 925,
      "seek": 574282,
      "start": 5755.86,
      "end": 5763.98,
      "text": " pubblicità quindi adesso insomma è tutto sul nostro groppone vi ricordo che se volete",
      "tokens": [
        1535,
        11489,
        12445,
        15727,
        39552,
        1028,
        30243,
        4873,
        23048,
        17603,
        35779,
        290,
        340,
        427,
        546,
        1932,
        21040,
        23872,
        947,
        369,
        1996,
        3498
      ],
      "temperature": 0,
      "avg_logprob": -0.20685275395711264,
      "compression_ratio": 1.6418604651162791,
      "no_speech_prob": 3.0288415331369833e-8
    },
    {
      "id": 926,
      "seek": 574282,
      "start": 5763.98,
      "end": 5769.0599999999995,
      "text": " sostenerci e non volete fare una donazione diretta che potete comunque fare andando nel",
      "tokens": [
        41585,
        7971,
        537,
        308,
        2107,
        1996,
        3498,
        11994,
        2002,
        500,
        12928,
        48196,
        1328,
        947,
        1847,
        3498,
        45736,
        11994,
        293,
        1806,
        15373
      ],
      "temperature": 0,
      "avg_logprob": -0.20685275395711264,
      "compression_ratio": 1.6418604651162791,
      "no_speech_prob": 3.0288415331369833e-8
    },
    {
      "id": 927,
      "seek": 576906,
      "start": 5769.06,
      "end": 5777.3,
      "text": " sito www.gitbar.it potete tranquillamente cliccare su uno dei link che trovate all'interno",
      "tokens": [
        1394,
        78,
        12520,
        13,
        70,
        270,
        5356,
        13,
        270,
        1847,
        3498,
        17640,
        373,
        3439,
        33661,
        5685,
        459,
        8526,
        13874,
        2113,
        947,
        4495,
        19083,
        439,
        6,
        5106,
        1771
      ],
      "temperature": 0,
      "avg_logprob": -0.21432372367027963,
      "compression_ratio": 1.5609756097560976,
      "no_speech_prob": 6.615596248593647e-8
    },
    {
      "id": 928,
      "seek": 576906,
      "start": 5777.3,
      "end": 5782.580000000001,
      "text": " delle note degli episodi o che puntano ad amazon in quel caso si setta una sessione",
      "tokens": [
        16485,
        3637,
        274,
        1146,
        2081,
        2927,
        30727,
        277,
        947,
        18212,
        3730,
        614,
        47010,
        294,
        7178,
        9666,
        1511,
        992,
        1328,
        2002,
        5481,
        68
      ],
      "temperature": 0,
      "avg_logprob": -0.21432372367027963,
      "compression_ratio": 1.5609756097560976,
      "no_speech_prob": 6.615596248593647e-8
    },
    {
      "id": 929,
      "seek": 576906,
      "start": 5782.580000000001,
      "end": 5787.820000000001,
      "text": " che se non mi sbaglio dura per 30 giorni e pochi centesimi dei vostri acquisti andranno",
      "tokens": [
        947,
        369,
        2107,
        2752,
        262,
        17282,
        19987,
        43416,
        680,
        2217,
        36937,
        72,
        308,
        714,
        8036,
        1489,
        279,
        10121,
        13874,
        28944,
        470,
        6667,
        45308,
        293,
        81,
        13484
      ],
      "temperature": 0,
      "avg_logprob": -0.21432372367027963,
      "compression_ratio": 1.5609756097560976,
      "no_speech_prob": 6.615596248593647e-8
    },
    {
      "id": 930,
      "seek": 576906,
      "start": 5787.820000000001,
      "end": 5791.780000000001,
      "text": " anche al nostro supporto grazie di cuore e grazie anonimo",
      "tokens": [
        11585,
        419,
        35779,
        1406,
        78,
        1295,
        3283,
        1026,
        2702,
        418,
        308,
        1295,
        3283,
        364,
        266,
        6934
      ],
      "temperature": 0,
      "avg_logprob": -0.21432372367027963,
      "compression_ratio": 1.5609756097560976,
      "no_speech_prob": 6.615596248593647e-8
    },
    {
      "id": 931,
      "seek": 579178,
      "start": 5791.78,
      "end": 5804.38,
      "text": " Eccoci qua sono le 10 le 22 e 43 e siamo ancora tutti in piedi belli arzilli",
      "tokens": [
        28993,
        1291,
        537,
        24159,
        9259,
        476,
        1266,
        476,
        5853,
        308,
        17914,
        308,
        33459,
        30656,
        19822,
        294,
        24186,
        72,
        48006,
        594,
        89,
        31922
      ],
      "temperature": 0,
      "avg_logprob": -0.4947572731109987,
      "compression_ratio": 1.377659574468085,
      "no_speech_prob": 5.10139974707613e-9
    },
    {
      "id": 932,
      "seek": 579178,
      "start": 5804.38,
      "end": 5806.38,
      "text": " Bell'arzillo sarebbe... non so che cosa sta succedendo",
      "tokens": [
        11485,
        6,
        49763,
        15831,
        38706,
        39042,
        485,
        2107,
        370,
        947,
        10163,
        11135,
        1965,
        1232,
        3999
      ],
      "temperature": 0,
      "avg_logprob": -0.4947572731109987,
      "compression_ratio": 1.377659574468085,
      "no_speech_prob": 5.10139974707613e-9
    },
    {
      "id": 933,
      "seek": 579178,
      "start": 5806.38,
      "end": 5809.38,
      "text": " Io morire di sonno però vabbè",
      "tokens": [
        19239,
        1896,
        621,
        1026,
        1872,
        1771,
        12673,
        371,
        10797,
        1462
      ],
      "temperature": 0,
      "avg_logprob": -0.4947572731109987,
      "compression_ratio": 1.377659574468085,
      "no_speech_prob": 5.10139974707613e-9
    },
    {
      "id": 934,
      "seek": 579178,
      "start": 5809.38,
      "end": 5817.82,
      "text": " Luciano grazie grazie mille per essere venuti a trovarci ricordiamo rapidamente i tuoi contatti",
      "tokens": [
        37309,
        3730,
        1295,
        3283,
        1295,
        3283,
        1728,
        68,
        680,
        19799,
        6138,
        29161,
        257,
        4495,
        8517,
        537,
        21040,
        765,
        7415,
        7558,
        3439,
        741,
        2604,
        4869,
        660,
        21515
      ],
      "temperature": 0,
      "avg_logprob": -0.4947572731109987,
      "compression_ratio": 1.377659574468085,
      "no_speech_prob": 5.10139974707613e-9
    },
    {
      "id": 935,
      "seek": 581782,
      "start": 5817.82,
      "end": 5823.86,
      "text": " Allora innanzitutto grazie a voi perché è sempre un piacere imparo sempre tantissimo",
      "tokens": [
        1057,
        3252,
        7714,
        3910,
        270,
        28698,
        1295,
        3283,
        257,
        20931,
        14303,
        4873,
        9553,
        517,
        3895,
        326,
        323,
        704,
        9708,
        9553,
        12095,
        34966
      ],
      "temperature": 0,
      "avg_logprob": -0.28022451400756837,
      "compression_ratio": 1.572289156626506,
      "no_speech_prob": 1.8266209167450143e-7
    },
    {
      "id": 936,
      "seek": 581782,
      "start": 5823.86,
      "end": 5835.38,
      "text": " quindi grazie i miei contatti mi trovate su twitter come loige o mi trovate su github",
      "tokens": [
        15727,
        1295,
        3283,
        741,
        12597,
        72,
        660,
        21515,
        2752,
        4495,
        19083,
        459,
        21439,
        808,
        450,
        3969,
        277,
        2752,
        4495,
        19083,
        459,
        290,
        355,
        836
      ],
      "temperature": 0,
      "avg_logprob": -0.28022451400756837,
      "compression_ratio": 1.572289156626506,
      "no_speech_prob": 1.8266209167450143e-7
    },
    {
      "id": 937,
      "seek": 581782,
      "start": 5835.38,
      "end": 5844.179999999999,
      "text": " come lmammino e mi trovate anche su linkedin poi ultimamente mi sto dilettando un po' su",
      "tokens": [
        808,
        287,
        76,
        5136,
        2982,
        308,
        2752,
        4495,
        19083,
        11585,
        459,
        9408,
        259,
        19260,
        3725,
        332,
        3439,
        2752,
        22784,
        11504,
        3093,
        1806,
        517,
        714,
        6,
        459
      ],
      "temperature": 0,
      "avg_logprob": -0.28022451400756837,
      "compression_ratio": 1.572289156626506,
      "no_speech_prob": 1.8266209167450143e-7
    },
    {
      "id": 938,
      "seek": 584418,
      "start": 5844.18,
      "end": 5850.22,
      "text": " twitch a fare dei live stream ogni tanto quindi se vi piace rust e vi piace vedere come io",
      "tokens": [
        34167,
        257,
        11994,
        13874,
        1621,
        4309,
        33189,
        10331,
        15727,
        369,
        1932,
        50062,
        15259,
        308,
        1932,
        50062,
        35373,
        808,
        19785
      ],
      "temperature": 0,
      "avg_logprob": -0.27553295394749316,
      "compression_ratio": 1.6367713004484306,
      "no_speech_prob": 2.0061517602698586e-7
    },
    {
      "id": 939,
      "seek": 584418,
      "start": 5850.22,
      "end": 5854.58,
      "text": " faccio finta di capire rust ma in realtà poi mi scontro col compilatore e finiamo a",
      "tokens": [
        1915,
        8529,
        283,
        16071,
        1026,
        1410,
        621,
        15259,
        463,
        294,
        47512,
        19260,
        2752,
        795,
        896,
        340,
        1173,
        715,
        388,
        43148,
        308,
        962,
        7415,
        257
      ],
      "temperature": 0,
      "avg_logprob": -0.27553295394749316,
      "compression_ratio": 1.6367713004484306,
      "no_speech_prob": 2.0061517602698586e-7
    },
    {
      "id": 940,
      "seek": 584418,
      "start": 5854.58,
      "end": 5861.02,
      "text": " litigare mi trovate su twitch sempre come loige e niente questi penso siano un po' tutti",
      "tokens": [
        7997,
        46956,
        2752,
        4495,
        19083,
        459,
        34167,
        9553,
        808,
        450,
        3969,
        308,
        297,
        8413,
        29729,
        48005,
        262,
        6254,
        517,
        714,
        6,
        19822
      ],
      "temperature": 0,
      "avg_logprob": -0.27553295394749316,
      "compression_ratio": 1.6367713004484306,
      "no_speech_prob": 2.0061517602698586e-7
    },
    {
      "id": 941,
      "seek": 584418,
      "start": 5861.02,
      "end": 5862.02,
      "text": " i miei contatti",
      "tokens": [
        741,
        12597,
        72,
        660,
        21515
      ],
      "temperature": 0,
      "avg_logprob": -0.27553295394749316,
      "compression_ratio": 1.6367713004484306,
      "no_speech_prob": 2.0061517602698586e-7
    },
    {
      "id": 942,
      "seek": 584418,
      "start": 5862.02,
      "end": 5868.18,
      "text": " E in libreria con note.js design pattern dai che ti ci devi comprare la casa al mare",
      "tokens": [
        462,
        294,
        4939,
        41568,
        416,
        3637,
        13,
        25530,
        1715,
        5102,
        38586,
        947,
        8757,
        6983,
        31219,
        715,
        35559,
        635,
        9022,
        419,
        31471
      ],
      "temperature": 0,
      "avg_logprob": -0.27553295394749316,
      "compression_ratio": 1.6367713004484306,
      "no_speech_prob": 2.0061517602698586e-7
    },
    {
      "id": 943,
      "seek": 586818,
      "start": 5868.18,
      "end": 5875.18,
      "text": " quella sì sì grazie metti pure il link anzi mando pure quello",
      "tokens": [
        32234,
        49267,
        49267,
        1295,
        3283,
        1131,
        7317,
        6075,
        1930,
        2113,
        364,
        3992,
        7411,
        78,
        6075,
        22813
      ],
      "temperature": 0,
      "avg_logprob": -0.3403745605832055,
      "compression_ratio": 1.4585635359116023,
      "no_speech_prob": 7.856100836534097e-8
    },
    {
      "id": 944,
      "seek": 586818,
      "start": 5875.18,
      "end": 5880.26,
      "text": " che tra l'altro è una delle pietre miliari non so se l'ho già detto per la programmazione",
      "tokens": [
        947,
        944,
        287,
        6,
        47484,
        4873,
        2002,
        16485,
        280,
        1684,
        265,
        1962,
        72,
        3504,
        2107,
        370,
        369,
        287,
        6,
        1289,
        30469,
        41031,
        680,
        635,
        37648,
        12928
      ],
      "temperature": 0,
      "avg_logprob": -0.3403745605832055,
      "compression_ratio": 1.4585635359116023,
      "no_speech_prob": 7.856100836534097e-8
    },
    {
      "id": 945,
      "seek": 586818,
      "start": 5880.26,
      "end": 5887.38,
      "text": " per chiunque abbia sviluppato un odd un'occhiata deve averla data a quel libro",
      "tokens": [
        680,
        13228,
        409,
        1077,
        16903,
        654,
        17342,
        388,
        10504,
        2513,
        517,
        7401,
        517,
        6,
        905,
        8036,
        3274,
        17761,
        18247,
        875,
        1412,
        257,
        7178,
        29354
      ],
      "temperature": 0,
      "avg_logprob": -0.3403745605832055,
      "compression_ratio": 1.4585635359116023,
      "no_speech_prob": 7.856100836534097e-8
    },
    {
      "id": 946,
      "seek": 586818,
      "start": 5887.38,
      "end": 5894.1,
      "text": " non piratato però compratelo",
      "tokens": [
        2107,
        13528,
        267,
        2513,
        12673,
        715,
        4481,
        10590
      ],
      "temperature": 0,
      "avg_logprob": -0.3403745605832055,
      "compression_ratio": 1.4585635359116023,
      "no_speech_prob": 7.856100836534097e-8
    },
    {
      "id": 947,
      "seek": 589410,
      "start": 5894.1,
      "end": 5905.26,
      "text": " bene leo luca luciano grazie davvero di questa serata super figa è stato veramente un piacere",
      "tokens": [
        2537,
        476,
        78,
        10438,
        496,
        21296,
        6254,
        1295,
        3283,
        11753,
        39332,
        1026,
        16540,
        816,
        3274,
        1687,
        2147,
        64,
        4873,
        29657,
        50079,
        517,
        3895,
        326,
        323
      ],
      "temperature": 0,
      "avg_logprob": -0.24028700795666924,
      "compression_ratio": 1.4360902255639099,
      "no_speech_prob": 1.7529592000187222e-8
    },
    {
      "id": 948,
      "seek": 589410,
      "start": 5905.26,
      "end": 5916.1,
      "text": " ecco riavervi tutti e tre qua sono senza parole cosa devo fare adesso ragazzi luca leo aiutatemi",
      "tokens": [
        11437,
        1291,
        367,
        654,
        331,
        4917,
        19822,
        308,
        2192,
        24159,
        9259,
        36208,
        26783,
        10163,
        49717,
        11994,
        39552,
        17539,
        33910,
        10438,
        496,
        476,
        78,
        9783,
        325,
        267,
        13372
      ],
      "temperature": 0,
      "avg_logprob": -0.24028700795666924,
      "compression_ratio": 1.4360902255639099,
      "no_speech_prob": 1.7529592000187222e-8
    },
    {
      "id": 949,
      "seek": 591610,
      "start": 5916.1,
      "end": 5928.620000000001,
      "text": " vi prego i contatti ecco ecco i contatti dimenticamo mi raccomando",
      "tokens": [
        1932,
        659,
        1571,
        741,
        660,
        21515,
        11437,
        1291,
        11437,
        1291,
        741,
        660,
        21515,
        274,
        2328,
        299,
        335,
        78,
        2752,
        4129,
        1112,
        1806
      ],
      "temperature": 0,
      "avg_logprob": -0.549774169921875,
      "compression_ratio": 1.4306569343065694,
      "no_speech_prob": 1.1253489162754704e-7
    },
    {
      "id": 950,
      "seek": 591610,
      "start": 5928.620000000001,
      "end": 5934.18,
      "text": " questa parte la taglio perché tipo sono andato davvero in buffero per flusso c'è un annulpo",
      "tokens": [
        16540,
        6975,
        635,
        6162,
        19987,
        14303,
        9746,
        9259,
        293,
        2513,
        11753,
        39332,
        294,
        9204,
        2032,
        680,
        932,
        301,
        539,
        269,
        6,
        1462,
        517,
        2324,
        425,
        2259
      ],
      "temperature": 0,
      "avg_logprob": -0.549774169921875,
      "compression_ratio": 1.4306569343065694,
      "no_speech_prob": 1.1253489162754704e-7
    },
    {
      "id": 951,
      "seek": 591610,
      "start": 5934.18,
      "end": 5936.1,
      "text": " intera no è il bello della diretta",
      "tokens": [
        728,
        64,
        572,
        4873,
        1930,
        312,
        1913,
        11618,
        48196,
        1328
      ],
      "temperature": 0,
      "avg_logprob": -0.549774169921875,
      "compression_ratio": 1.4306569343065694,
      "no_speech_prob": 1.1253489162754704e-7
    },
    {
      "id": 952,
      "seek": 593610,
      "start": 5936.1,
      "end": 5950.54,
      "text": " giusto prima di chiudere una piccola cosa mi raccomando se avete un device apple andate",
      "tokens": [
        1735,
        48260,
        19507,
        1026,
        13228,
        532,
        323,
        2002,
        13363,
        66,
        4711,
        10163,
        2752,
        4129,
        1112,
        1806,
        369,
        48201,
        517,
        4302,
        10606,
        293,
        473
      ],
      "temperature": 0,
      "avg_logprob": -0.25916560284503093,
      "compression_ratio": 1.588235294117647,
      "no_speech_prob": 2.8901416371240884e-8
    },
    {
      "id": 953,
      "seek": 593610,
      "start": 5950.54,
      "end": 5957.1,
      "text": " su itunes stellinateci metteteci in cuoricino lasciateci una recensione questo fa in modo",
      "tokens": [
        459,
        309,
        15001,
        342,
        898,
        13923,
        537,
        27812,
        3498,
        537,
        294,
        2702,
        16345,
        2982,
        48451,
        473,
        537,
        2002,
        850,
        3378,
        68,
        10263,
        2050,
        294,
        16664
      ],
      "temperature": 0,
      "avg_logprob": -0.25916560284503093,
      "compression_ratio": 1.588235294117647,
      "no_speech_prob": 2.8901416371240884e-8
    },
    {
      "id": 954,
      "seek": 593610,
      "start": 5957.1,
      "end": 5961.780000000001,
      "text": " di in qualche modo continuare a preservare la nostra posizione all'interno delle classifiche",
      "tokens": [
        1026,
        294,
        38737,
        16664,
        2993,
        543,
        257,
        45905,
        543,
        635,
        34311,
        1366,
        35740,
        439,
        6,
        5106,
        1771,
        16485,
        1508,
        351,
        9304
      ],
      "temperature": 0,
      "avg_logprob": -0.25916560284503093,
      "compression_ratio": 1.588235294117647,
      "no_speech_prob": 2.8901416371240884e-8
    },
    {
      "id": 955,
      "seek": 596178,
      "start": 5961.78,
      "end": 5968.46,
      "text": " di itunes e quindi riuscire a raggiungere nuove orecchie vi ricordiamo rapidamente i",
      "tokens": [
        1026,
        309,
        15001,
        308,
        15727,
        367,
        4872,
        537,
        265,
        257,
        17539,
        7834,
        1063,
        323,
        3822,
        1682,
        277,
        13867,
        339,
        414,
        1932,
        21040,
        765,
        7415,
        7558,
        3439,
        741
      ],
      "temperature": 0,
      "avg_logprob": -0.34274816950526804,
      "compression_ratio": 1.6231884057971016,
      "no_speech_prob": 7.153167302931251e-8
    },
    {
      "id": 956,
      "seek": 596178,
      "start": 5968.46,
      "end": 5976.42,
      "text": " nostri contatti info che sono a github.it e il gruppo telegram che trovate cercando",
      "tokens": [
        10397,
        470,
        660,
        21515,
        13614,
        947,
        9259,
        257,
        290,
        355,
        836,
        13,
        270,
        308,
        1930,
        47477,
        78,
        4304,
        1342,
        947,
        4495,
        19083,
        36099,
        1806
      ],
      "temperature": 0,
      "avg_logprob": -0.34274816950526804,
      "compression_ratio": 1.6231884057971016,
      "no_speech_prob": 7.153167302931251e-8
    },
    {
      "id": 957,
      "seek": 596178,
      "start": 5976.42,
      "end": 5984.0199999999995,
      "text": " github telegram e cliccando sul primo risultato a occhi chiusi perché faremo noi",
      "tokens": [
        290,
        355,
        836,
        4304,
        1342,
        308,
        33661,
        29585,
        17603,
        38671,
        2253,
        723,
        2513,
        257,
        10409,
        8036,
        417,
        4872,
        72,
        14303,
        11994,
        3280,
        22447
      ],
      "temperature": 0,
      "avg_logprob": -0.34274816950526804,
      "compression_ratio": 1.6231884057971016,
      "no_speech_prob": 7.153167302931251e-8
    },
    {
      "id": 958,
      "seek": 596178,
      "start": 5984.0199999999995,
      "end": 5989.66,
      "text": " detto questo io ringrazio nuovamente luciano per essere venuto a trovarci ormai tu lo",
      "tokens": [
        41031,
        10263,
        19785,
        4875,
        30695,
        1004,
        3822,
        5179,
        3439,
        10438,
        537,
        3730,
        680,
        19799,
        6138,
        8262,
        257,
        4495,
        8517,
        537,
        420,
        76,
        1301,
        2604,
        450
      ],
      "temperature": 0,
      "avg_logprob": -0.34274816950526804,
      "compression_ratio": 1.6231884057971016,
      "no_speech_prob": 7.153167302931251e-8
    },
    {
      "id": 959,
      "seek": 598966,
      "start": 5989.66,
      "end": 5999.18,
      "text": " sai no? github è un po' anche casa tua quindi quando hai qualcosa di nuovo quando",
      "tokens": [
        32417,
        572,
        30,
        290,
        355,
        836,
        4873,
        517,
        714,
        6,
        11585,
        9022,
        33578,
        15727,
        7770,
        21822,
        42400,
        1026,
        49348,
        7770
      ],
      "temperature": 0,
      "avg_logprob": -0.2803825774750152,
      "compression_ratio": 1.5748502994011977,
      "no_speech_prob": 4.363460703871169e-9
    },
    {
      "id": 960,
      "seek": 598966,
      "start": 5999.18,
      "end": 6005.139999999999,
      "text": " il compilatore di rust ti dice qualcosa di interessante ecco vieni da noi a raccontarcelo",
      "tokens": [
        1930,
        715,
        388,
        43148,
        1026,
        15259,
        8757,
        10313,
        42400,
        1026,
        24372,
        11437,
        1291,
        371,
        35462,
        1120,
        22447,
        257,
        4129,
        9000,
        289,
        4933,
        78
      ],
      "temperature": 0,
      "avg_logprob": -0.2803825774750152,
      "compression_ratio": 1.5748502994011977,
      "no_speech_prob": 4.363460703871169e-9
    },
    {
      "id": 961,
      "seek": 598966,
      "start": 6005.139999999999,
      "end": 6013.58,
      "text": " perché insomma github è il circolo degli sviluppatori dove hai la tessera è tra l'altro",
      "tokens": [
        14303,
        1028,
        30243,
        290,
        355,
        836,
        4873,
        1930,
        3510,
        7902,
        32079,
        17342,
        388,
        10504,
        39842,
        23287,
        21822,
        635,
        256,
        442,
        1663,
        4873,
        944,
        287,
        6,
        47484
      ],
      "temperature": 0,
      "avg_logprob": -0.2803825774750152,
      "compression_ratio": 1.5748502994011977,
      "no_speech_prob": 4.363460703871169e-9
    },
    {
      "id": 962,
      "seek": 601358,
      "start": 6013.58,
      "end": 6021.46,
      "text": " una delle prime ms quindi ti aspettiamo per il momento il compilatore di rust mi dice",
      "tokens": [
        2002,
        16485,
        5835,
        275,
        82,
        15727,
        8757,
        16817,
        3093,
        7415,
        680,
        1930,
        9333,
        1930,
        715,
        388,
        43148,
        1026,
        15259,
        2752,
        10313
      ],
      "temperature": 0,
      "avg_logprob": -0.3400905529658,
      "compression_ratio": 1.6807511737089202,
      "no_speech_prob": 6.448776179723836e-9
    },
    {
      "id": 963,
      "seek": 601358,
      "start": 6021.46,
      "end": 6026.42,
      "text": " solo vai a zappare quindi quando cambieremo questa storia magari arriverò a parlare di",
      "tokens": [
        6944,
        4405,
        257,
        710,
        1746,
        543,
        15727,
        7770,
        19569,
        323,
        3280,
        16540,
        5967,
        654,
        49932,
        34142,
        4293,
        257,
        13734,
        543,
        1026
      ],
      "temperature": 0,
      "avg_logprob": -0.3400905529658,
      "compression_ratio": 1.6807511737089202,
      "no_speech_prob": 6.448776179723836e-9
    },
    {
      "id": 964,
      "seek": 601358,
      "start": 6026.42,
      "end": 6032.98,
      "text": " rust e devo dire ringraziamo che non ci sono le emoji se no la frustrazione salirebbe ancora",
      "tokens": [
        15259,
        308,
        49717,
        1264,
        4875,
        30695,
        7415,
        947,
        2107,
        6983,
        9259,
        476,
        31595,
        369,
        572,
        635,
        7454,
        424,
        19706,
        1845,
        621,
        39042,
        30656
      ],
      "temperature": 0,
      "avg_logprob": -0.3400905529658,
      "compression_ratio": 1.6807511737089202,
      "no_speech_prob": 6.448776179723836e-9
    },
    {
      "id": 965,
      "seek": 601358,
      "start": 6032.98,
      "end": 6040.66,
      "text": " di più detto questo io vi do appuntamento alla prossima settimana ciao ciao ciao ciao",
      "tokens": [
        1026,
        10589,
        41031,
        10263,
        19785,
        1932,
        360,
        724,
        2760,
        8824,
        11591,
        48794,
        4775,
        5584,
        36497,
        42860,
        42860,
        42860,
        42860
      ],
      "temperature": 0,
      "avg_logprob": -0.3400905529658,
      "compression_ratio": 1.6807511737089202,
      "no_speech_prob": 6.448776179723836e-9
    },
    {
      "id": 966,
      "seek": 604066,
      "start": 6040.66,
      "end": 6046.38,
      "text": " ciao",
      "tokens": [
        42860
      ],
      "temperature": 0,
      "avg_logprob": -0.31296790087664567,
      "compression_ratio": 1.4523809523809523,
      "no_speech_prob": 0.0000038448865780083
    },
    {
      "id": 967,
      "seek": 604066,
      "start": 6046.38,
      "end": 6051.18,
      "text": " git bar il circolo dei full stack developer una volta a settimana ci troviamo davanti",
      "tokens": [
        18331,
        2159,
        1930,
        3510,
        7902,
        13874,
        1577,
        8630,
        10754,
        2002,
        18765,
        257,
        5584,
        36497,
        6983,
        35449,
        7415,
        11753,
        11520
      ],
      "temperature": 0,
      "avg_logprob": -0.31296790087664567,
      "compression_ratio": 1.4523809523809523,
      "no_speech_prob": 0.0000038448865780083
    },
    {
      "id": 968,
      "seek": 604066,
      "start": 6051.18,
      "end": 6057.099999999999,
      "text": " a due birre e con brain repo parliamo di linguaggi e tecniche di sviluppo web di metodologie",
      "tokens": [
        257,
        3462,
        1904,
        265,
        308,
        416,
        3567,
        49040,
        971,
        49926,
        1026,
        21766,
        46893,
        308,
        20105,
        9304,
        1026,
        17342,
        388,
        10504,
        78,
        3670,
        1026,
        1131,
        378,
        20121
      ],
      "temperature": 0,
      "avg_logprob": -0.31296790087664567,
      "compression_ratio": 1.4523809523809523,
      "no_speech_prob": 0.0000038448865780083
    },
    {
      "id": 969,
      "seek": 605710,
      "start": 6057.1,
      "end": 6070.700000000001,
      "text": " ed strumenti immancabili nella cassetta degli attrezzi dei full stack dev",
      "tokens": [
        50364,
        1257,
        1056,
        2206,
        72,
        566,
        1601,
        66,
        455,
        2312,
        23878,
        21943,
        16593,
        32079,
        951,
        17693,
        3992,
        13874,
        1577,
        8630,
        1905,
        51044
      ],
      "temperature": 0,
      "avg_logprob": -0.3187553778938625,
      "compression_ratio": 1.0735294117647058,
      "no_speech_prob": 2.616515928366425e-7
    }
  ],
  "language": "it"
}